{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-10T08:02:32.913831Z",
     "end_time": "2023-05-10T08:02:33.586132Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import _gradient_boosting\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from imblearn.over_sampling import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from helper_functions_KP import *\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Instructions for the pipeline Requires two inputs for training: - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration) - NetsurfP and Biopython data that has been precalculated - X characteristics to predict\n",
    "pipeline Take mass spec spreadsheet Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration Merge with Proteome data to get file that has Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence Calculate protein features using biopython Merge with NSP data to get all protein features\n",
    "Split into X and Y dataset with Entries as labels\n",
    "In this pipeline (look at synth dataset and generate validation and prediction datasets out of original dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Tests to perform#\n",
    "##For RFR and RFC##\n",
    "#RFECV control abundance and no control abundance\n",
    "#RFE Curve -> performance curve relative to number of features selected#\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2\n",
      "Recursive Feature Elimination with Correlated Features ran successfully\n",
      "Scorer ran successfully\n",
      "neg_mean_squared_error\n",
      "Recursive Feature Elimination with Correlated Features ran successfully\n",
      "Scorer ran successfully\n",
      "explained_variance\n",
      "Recursive Feature Elimination with Correlated Features ran successfully\n",
      "Scorer ran successfully\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Run RFECV on synth database to see what features it sees as important and how many are important- Vary scoring methods##\n",
    "in_dir='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "\n",
    "df = pd.read_excel(in_dir, header=0)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "#Drop zero values#\n",
    "Min_Control=df['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "ids=['r2','neg_mean_squared_error','explained_variance']\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "for identifier in ids:\n",
    "    print(identifier)\n",
    "    df = pd.read_excel(in_dir, header=0)\n",
    "    df=df[df['Abundance']>=Min_Control]\n",
    "    labels_df= df['Abundance'].copy()\n",
    "    id_col= df['NPUNID'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    label_abund=np.log2(label_abund)\n",
    "    # df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID','Abundance_Controls'])\n",
    "    # df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID'])\n",
    "    if identifier=='NoCA':\n",
    "        df=df.drop(columns='Abundance_Controls')\n",
    "    df=df.drop(columns=['Abundance','NPUNID','NPID','Entry','Sequence','Sample_num', 'Raw_FileID','Ligands'])\n",
    "    step = 1\n",
    "    selector = RFE(model, n_features_to_select=75, step=step)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df = df[feat_list].copy()\n",
    "\n",
    "\n",
    "    min_feats = 1\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    selector = RFECV(estimator=model, cv=cv, min_features_to_select=min_feats,\n",
    "                     step=step,scoring=identifier)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    feat_list2 = selector.get_feature_names_out()\n",
    "    selected_features = df.columns[selector.support_]\n",
    "    df = df[feat_list2]\n",
    "    # df.to_excel(\"Input_data/Save_files/df_RFECV\"+id+id2+\".xlsx\")\n",
    "    rfecv_df=pd.DataFrame(selector.cv_results_)\n",
    "    rfecv_df.to_excel(\"Output_data/RFECV_resultsRFR\"+identifier+\".xlsx\",index=False)\n",
    "    df=RFECV_plot(df,label_abund,model,identifier,10,1)\n",
    "    tmp2,tmp3=scorer(df, label_abund, model, identifier=identifier, folds=10)\n",
    "    summary_tmp.append(tmp2)\n",
    "    feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFECV_log2_synth_RFR.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFECV_log2_synth_RFR.xlsx', index=False)\n",
    "print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T16:02:00.936669800Z",
     "start_time": "2023-05-09T15:10:48.634949100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 16>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m summary_tmp\u001B[38;5;241m=\u001B[39m[]\n\u001B[0;32m     15\u001B[0m feats\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m---> 16\u001B[0m df_a\u001B[38;5;241m=\u001B[39m\u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     17\u001B[0m thresh\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m identifier \u001B[38;5;129;01min\u001B[39;00m ids:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##Run RFECV for classification test multiple scoring methods keep control abundance since it is dropped anyways##\n",
    "in_dir='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "#Drop zero values#\n",
    "\n",
    "# df = df.replace(np.inf,10)\n",
    "model=RandomForestClassifier()\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "# featnums=[75,60,50,40,30,25,20,18,15,12,10,8,5,4,3,2]\n",
    "featnums=np.arange(75,5,-1).tolist()\n",
    "ids=['f1','accuracy','precision','recall','roc_auc']\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "# df_a=df.copy()\n",
    "thresh=1\n",
    "\n",
    "\n",
    "for identifier in ids:\n",
    "    df = pd.read_excel(in_dir, header=0)\n",
    "    #drop zeros\n",
    "    # Min_Control=df['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    # df=df[df['Abundance']>=Min_Control]\n",
    "    #\n",
    "\n",
    "    Min_Abund=df['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    df['Abundance_Controls'].replace(0,Min_Abund,inplace=True)\n",
    "    df['Enrich']= np.log2(df['Abundance']/df['Abundance_Controls'])\n",
    "    df['binary_target']= df['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "    if identifier=='NoCA':\n",
    "        df=df.drop(columns='Abundance_Controls')\n",
    "    labels_df = df['binary_target'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    df=df.drop(columns=['Abundance','NPUNID','Entry','Sequence','Sample_num', 'Raw_FileID','Ligands','Enrich','binary_target','NPID'])\n",
    "\n",
    "    identity=identifier\n",
    "    step = 1\n",
    "\n",
    "    min_feats = 1\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    selector = RFECV(estimator=model, cv=cv, min_features_to_select=min_feats,\n",
    "                     step=step, scoring=identifier)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    feat_list2 = selector.get_feature_names_out()\n",
    "    selected_features = df.columns[selector.support_]\n",
    "    df = df[feat_list2]\n",
    "    # df.to_excel(\"Input_data/Save_files/df_RFECV\"+id+id2+\".xlsx\")\n",
    "    rfecv_df=pd.DataFrame(selector.cv_results_)\n",
    "    rfecv_df.to_excel(\"Output_data/RFECV_resultsRFC\"+identifier+\".xlsx\",index=False)\n",
    "    tmp2,tmp3=scorer_RFC(df, label_abund, model, identity, 10)\n",
    "    summary_tmp.append(tmp2)\n",
    "    feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFEcv_RFC.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFEcv_RFC.xlsx', index=False)\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:07:37.518647Z",
     "end_time": "2023-05-03T22:19:41.414288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-08T11:33:50.087608Z",
     "end_time": "2023-05-08T11:34:23.960089Z"
    }
   },
   "outputs": [],
   "source": [
    "##Testing Each NP independently--RFR ## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[1,20,19,16,7,31,34,43,44]\n",
    "NPUNID_list=df_a['NPUNID'].unique().tolist()\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFR=['Abundance_Controls','Length','frac_aa_A','frac_aa_D','frac_aa_F','frac_aa_N','fraction_exposed_polar_total','rsa_std','fraction_exposed_exposed_C','fraction_exposed_exposed_E','fraction_exposed_exposed_H','nsp_secondary_structure_coil',\t'nsp_secondary_structure_sheet','Zeta Potential','Dh_functionalized','NP_incubation Concentration (mg/mL)','Incubation Concentration (mg/ml)']\n",
    "\n",
    "Min_Control=df_a['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a= df_a[df_a['Abundance']>=Min_Control].copy()\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each ID in the list\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df=df_a.copy()\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "    removed_row = df.loc[df['NPUNID'] == NPID].copy()\n",
    "    df = df.loc[df['NPUNID'] != NPID].copy()\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df[feat_list_RFR].copy()\n",
    "    X_test = removed_row[feat_list_RFR].copy()\n",
    "    y_train = np.ravel(df['Abundance'])\n",
    "    y_train = np.log2(y_train)\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "    X_test = removed_row[X_train.columns]\n",
    "    y_true = removed_row['Abundance']\n",
    "    y_true= np.ravel(y_true)\n",
    "    y_true= np.log2(y_true)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    pearson_scores.append(pearson)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mse_score)\n",
    "    # plot the scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.set_xlabel('True Abundance Value log2')\n",
    "    ax.set_ylabel('Predicted Abundance log2')\n",
    "\n",
    "\n",
    "    # add the metrics box to the plot\n",
    "    box_text = f\"MSE: {mse_score:.2f}\\nR2: {r2:.2f}\\nPearson: {pearson:.2f}\"\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.65, 0.95, box_text, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "    plt.savefig('Output_data/NPtest_synth_' + str(NPID) + '.png', bbox_inches='tight')\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'Abundandce Filter': Min_Control,\n",
    "                              'NPUNID':NPID,\n",
    "                              'MSE':mse_score,\n",
    "                              'R2':r2,\n",
    "                              'Pearson':pearson},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "    # create a DataFrame to store the current iteration's results\n",
    "    current_df = pd.DataFrame({\n",
    "        f\"true_{NPID}\": y_true,\n",
    "        f\"predict_{NPID}\": y_pred\n",
    "    })\n",
    "\n",
    "    # append the current DataFrame to the results DataFrame\n",
    "    results_df = pd.concat([results_df, current_df], axis=1)\n",
    "\n",
    "# export the results DataFrame to a CSV file\n",
    "results_df.to_csv(\"Output_data/NPID_InternalPrediction_results.xlsx\", index=False)\n",
    "\n",
    "eval_df.to_excel('Output_data/RFR_NPID_testing.xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##External Validation--RFR## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[1,20,19,16,7,31,34,43,44]\n",
    "prediction_filepath ='Input_data/Save_files/df_4_HS.xlsx'\n",
    "df_pred = pd.read_excel(prediction_filepath, header=0)\n",
    "NPUNID_list=df_pred['NPUNID'].unique().tolist()\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFR=['Abundance_Controls','Mass','frac_aa_A','frac_aa_D','frac_aa_F','frac_aa_N','fraction_exposed_polar_total','rsa_std','fraction_exposed_exposed_C','fraction_exposed_exposed_E','fraction_exposed_exposed_H','nsp_secondary_structure_coil',\t'nsp_secondary_structure_sheet','Zeta Potential','Dh_functionalized','NP_incubation Concentration (mg/mL)','Incubation Concentration (mg/ml)']\n",
    "\n",
    "Min_Control=df_a['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a= df_a[df_a['Abundance']>=Min_Control].copy()\n",
    "Min_Control=df_pred['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_pred= df_pred[df_pred['Abundance']>=Min_Control].copy()\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df_b=df_pred[df_pred['NPUNID']==NPID].copy()\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df_a[feat_list_RFR].copy()\n",
    "    X_test = df_b[feat_list_RFR].copy()\n",
    "    y_train = np.ravel(df_a['Abundance'])\n",
    "    y_train = np.log2(y_train)\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "\n",
    "    y_true = df_b['Abundance']\n",
    "    y_true= np.ravel(y_true)\n",
    "    y_true= np.log2(y_true)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    pearson_scores.append(pearson)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mse_score)\n",
    "    # plot the scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.set_xlabel('True Abundance Value log2')\n",
    "    ax.set_ylabel('Predicted Abundance log2')\n",
    "\n",
    "\n",
    "    # add the metrics box to the plot\n",
    "    box_text = f\"MSE: {mse_score:.2f}\\nR2: {r2:.2f}\\nPearson: {pearson:.2f}\"\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.65, 0.95, box_text, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "    plt.savefig('Output_data/NPtest_HS_' + str(NPID) + '.png', bbox_inches='tight')\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'Abundandce Filter': Min_Control,\n",
    "                              'NPUNID':NPID,\n",
    "                              'MSE':mse_score,\n",
    "                              'R2':r2,\n",
    "                              'Pearson':pearson},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/PredictingHS_Samples.xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T23:22:23.787940Z",
     "end_time": "2023-05-03T23:22:56.235015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##External Validation--RFC## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[2,16,7,8,9,10,11,12]\n",
    "prediction_filepath ='Input_data/Save_files/df_4_HS.xlsx'\n",
    "df_pred = pd.read_excel(prediction_filepath, header=0)\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "\n",
    "Min_Abund=df_a['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a['Abundance_Controls'].replace(0,Min_Abund,inplace=True)\n",
    "df_a['Enrich']= np.log2(df_a['Abundance']/df_a['Abundance_Controls'])\n",
    "df_a['binary_target']= df_a['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "labels_df = df_a['binary_target'].copy()\n",
    "label_abund=np.ravel(labels_df)\n",
    "\n",
    "\n",
    "NPUNID_list=df_pred['NPUNID'].unique().tolist()\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "# f1 = []\n",
    "# auroc = []\n",
    "# accuracy = []\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "eval_df = pd.DataFrame(columns=['NPUNID', 'f1', 'AUROC', 'Accuracy','precision','recall'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFC=['Zeta Potential','Dh_functionalized','Surface_Ligand','secondary_structure_fraction_sheet','frac_aa_R','isoelectric_point','Dtem','fraction_exposed_nonpolar_exposed','Incubation Concentration (mg/ml)','Mass','frac_aa_A','frac_aa_I','fraction_exposed_exposed_P','flexibility_min','fraction_buried','fraction_exposed']\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df_b=df_pred[df_pred['NPUNID']==NPID].copy()\n",
    "    Min_Abund=df_pred['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    df_b['Abundance_Controls'].replace(0,Min_Abund,inplace=True)\n",
    "    df_b['Enrich']= np.log2(df_b['Abundance']/df_b['Abundance_Controls'])\n",
    "    df_b['binary_target']= df_b['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "    labels_df = df_b['binary_target'].copy()\n",
    "    label_target=np.ravel(labels_df)\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df_a[feat_list_RFC].copy()\n",
    "    X_test = df_b[feat_list_RFC].copy()\n",
    "    y_train = label_abund\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "\n",
    "    y_true = label_target\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'NPUNID':NPID,'f1':f1,'AUROC':auroc,'Accuracy':accuracy,'precision':precision,'recall':recall},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/Predicting_HS_Samples_RFC.xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T06:31:57.683690Z",
     "end_time": "2023-05-04T06:32:18.412163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T06:21:26.998828Z",
     "end_time": "2023-05-04T06:21:27.022449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##External Validation on RFC Methods#\n",
    "##External Validation--RFC## Which ones are hard to predict and which ones are easy?\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "\n",
    "\n",
    "NPUNID_list=[2,16,7,8,9,10,11,12]\n",
    "prediction_filepath ='Input_data/Save_files/df_1_all.xlsx'\n",
    "df_pred = pd.read_excel(prediction_filepath, header=0)\n",
    "\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFC=['Zeta Potential','Dh_functionalized','Surface_Ligand','secondary_structure_fraction_sheet','frac_aa_R','isoelectric_point','Dtem','fraction_exposed_nonpolar_exposed','Incubation Concentration (mg/ml)','Mass','frac_aa_A','frac_aa_I','fraction_exposed_exposed_P','flexibility_min','fraction_buried','fraction_exposed']\n",
    "\n",
    "Min_Control=df_a['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a= df_a[df_a['Abundance']>=Min_Control].copy()\n",
    "Min_Control=df_pred['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_pred= df_pred[df_pred['Abundance']>=Min_Control].copy()\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df_b=df_pred[df_pred['NPUNID']==NPID].copy()\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df_a[feat_list_RFC].copy()\n",
    "    X_test = df_b[feat_list_RFC].copy()\n",
    "    y_train = np.ravel(df_a['Abundance'])\n",
    "    y_train = np.log2(y_train)\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "\n",
    "    y_true = df_b['Abundance']\n",
    "    y_true= np.ravel(y_true)\n",
    "    y_true= np.log2(y_true)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    pearson_scores.append(pearson)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mse_score)\n",
    "    # plot the scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.set_xlabel('True Abundance Value log2')\n",
    "    ax.set_ylabel('Predicted Abundance log2')\n",
    "\n",
    "\n",
    "    # add the metrics box to the plot\n",
    "    box_text = f\"MSE: {mse_score:.2f}\\nR2: {r2:.2f}\\nPearson: {pearson:.2f}\"\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.65, 0.95, box_text, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "    plt.savefig('Output_data/NPtest_HS_' + str(NPID) + '.png', bbox_inches='tight')\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'Abundandce Filter': Min_Control,\n",
    "                              'NPUNID':NPID,\n",
    "                              'MSE':mse_score,\n",
    "                              'R2':r2,\n",
    "                              'Pearson':pearson},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/PredictingBALF_FBS_Samples.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Feature Elimination with Correlated Features ran successfully\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m df_a\u001B[38;5;241m=\u001B[39mdf_a\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundance\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNPUNID\u001B[39m\u001B[38;5;124m'\u001B[39m],axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     11\u001B[0m df_a\u001B[38;5;241m=\u001B[39mRFECV_plot(df_a,label_abund,model,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m,folds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m scram_score(\u001B[43mdf\u001B[49m, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m     13\u001B[0m feat_drop(df, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##Run Quality Control on df to get a look at important features and such##\n",
    "df_filepath = 'Input_data/Save_files/df_1_all_RFE50_RFR.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "labels= df_a['Abundance'].copy()\n",
    "id_col= df_a['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels)\n",
    "\n",
    "\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "df_a=df_a.drop(columns=['Abundance','NPUNID'],axis=1).copy()\n",
    "df_a=RFECV_plot(df_a,label_abund,model,'b',folds=5,step=2)\n",
    "scram_score(df, label_abund, model, id, 0.2)\n",
    "feat_drop(df, label_abund, model, id, 0.2)\n",
    "# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\n",
    "tmp2=scorer(df, label_abund, model, id, 10)\n",
    "zeros=(raw_MS_data['Abundance']==0).sum()\n",
    "percent_zeros=zeros/raw_MS_data.shape[0]\n",
    "tmp2['TotalZeros']=zeros\n",
    "tmp2['Percent_zeros']=percent_zeros\n",
    "summary_tmp.append(tmp2)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run Histogram of each Feature###\n",
    "# Get total number of rows\n",
    "df=df_a\n",
    "total_count = len(df)\n",
    "df = df.rename(columns=lambda x: x.replace('/', ''))\n",
    "# Loop over each column of the dataframe\n",
    "for col in df.columns:\n",
    "    # Create a histogram of the current column, with bins=10\n",
    "    data=df[col]\n",
    "    plt.hist(data, weights=np.ones_like(data) / len(data))\n",
    "\n",
    "    # Set the title of the histogram to the column name and percent of total population\n",
    "    plt.title(str(col))\n",
    "    plt.savefig('Output_data/{}.png'.format(str(col)))\n",
    "    plt.close()\n",
    "    # Show the histogram\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

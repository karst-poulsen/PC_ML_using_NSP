{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import *\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Instructions for the pipeline\n",
    "Requires four inputs:\n",
    "    - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration)\n",
    "    - Proteome data from uniprot (Mass, length, sequence, GO for later analysis)\n",
    "    - NetsurfP data for the proteins that are to be searched\n",
    "    - X characteristics to predict\n",
    "\n",
    "pipeline\n",
    "Take mass spec spreadsheet\n",
    "Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration\n",
    "Merge with Proteome data to get file that has\n",
    "Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence\n",
    "Calculate protein features using biopython\n",
    "Merge with NSP data to get all protein features\n",
    "\n",
    "Split into X and Y dataset with Entries as labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### New Data workup for RFG\n",
    "\n",
    "# Pull together Proteomic data\n",
    "in_dir=\"Input_data/Proteomic data/abundance/\"\n",
    "#Mass Spec data input in one excel spreadsheet - Entry - Abundance labeled by NP Unique ID\n",
    "#Abundance as a percent\n",
    "files= os.listdir(in_dir)\n",
    "for i,f in enumerate(files):\n",
    "    if i==0:\n",
    "        raw_MS_data=pd.read_excel(in_dir+f,header=0)\n",
    "    else:\n",
    "        temp = pd.read_excel(in_dir+f,header=0)\n",
    "        raw_MS_data=raw_MS_data.merge(temp,how='outer',on='Entry')\n",
    "# melt to make it an accession number, NPID, Abundance dataset\n",
    "raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'],var_name='NPUNID', value_name='Abundance')\n",
    "#remove prots that were added due to merge\n",
    "raw_MS_data=raw_MS_data.dropna()\n",
    "#bring in controls (MS data for serums)\n",
    "controls=pd.read_excel('Input_data/Proteomic data/controls.xlsx',header=0)\n",
    "MS_data_controls = pd.merge(raw_MS_data,controls,how='inner', on='Entry')\n",
    "#Bring in Uniprot_data,NSPdata and NP data\n",
    "uniprot_filepath='UniProt/Bovine_Mouse_proteome.xlsx'\n",
    "uniprot_dat=pd.read_excel(uniprot_filepath,header=0)\n",
    "NSPfilePath='NetsurfP_Proteomes/Bovine_Mouse_Proteome.xlsx'\n",
    "NSP_data=pd.read_excel(NSPfilePath)\n",
    "NP_filepath='Input_data/NPs/NP_Database.xlsx'\n",
    "NPUNdata=pd.read_excel(NP_filepath,header=0,sheet_name='NPUNID')\n",
    "NPprop=pd.read_excel(NP_filepath,header=0,sheet_name='NP_Props')\n",
    "NPdata=pd.merge(NPUNdata,NPprop,how=\"left\",on='NPID')\n",
    "\n",
    "#calculate Enrichment\n",
    "#####MAYBE add binning here to to keep negative results and improve capapbilities######\n",
    "MS_data_controls['Enrichment']= np.log2(MS_data_controls['Abundance']/MS_data_controls['Abundance_Controls'])\n",
    "MS_data=MS_data_controls.drop(columns=['Abundance','Abundance_Controls'])\n",
    "raw_prop_data=pd.merge(MS_data, uniprot_dat, how='left',on='Entry')\n",
    "\n",
    "#clean up and calculate % protein abundance and enrichment, function found in data_prep_functions line 470\n",
    "\n",
    "MS_data_clean = raw_MS_data.copy()\n",
    "Accesions_IDs = MS_data_clean[\"Entry\"].to_frame()\n",
    "# clean up protein data, function found in data_prep_functions.py line 367\n",
    "col_list=['Entry','NPUNID', 'Sequence', 'Length', 'Mass'] #list of columns kept during clean_up_data_biopy\n",
    "PROT_cleaned_data = clean_up_data_biopy(raw_prop_data, Accesions_IDs,col_list) #calculates biopython features from protein sequences, and removes proteins removed during mass spec clean up\n",
    "PROT_cleaned_data = normalize_mass_length_1DF(PROT_cleaned_data) #function found in data_prep_functions line 167, normalizes mass, length and mw by dividing all values by the max in the column\n",
    "Protein_data_complete = pd.merge(PROT_cleaned_data, NSP_data, left_on='Entry', right_on='Entry') #merges netsurfp features and biopython features\n",
    "#creates new column called asa_sum_normalized which is the asa_sum value divide by the mass of the protein\n",
    "for df in [Protein_data_complete]:\n",
    "    for col in ['asa_sum']:\n",
    "        df[col+'_normalized'] = df[col] / df['Mass']\n",
    "\n",
    "data_complete= pd.merge(Protein_data_complete,NPdata,how='left', on='NPUNID')\n",
    "data_complete.drop(columns=['notes','Notes,'BET','NPUNID'],inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_complete.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels=MS_data_clean.drop(['Entry'], axis=1)\n",
    "labels=np.ravel(labels)\n",
    "df=data_complete.drop(['Entry','Sequence'],axis=1)\n",
    "\n",
    "print(labels)\n",
    "# print(labels)\n",
    "# print(df)\n",
    "first_frame = True #starting dataframe for saving metrics\n",
    "correctness_frame = pd.DataFrame()\n",
    "metrics_frame = pd.DataFrame()\n",
    "print_metrics = 1 #0, doesn't show metrics while runnning for each model, 1 does show metrics\n",
    "trials = 100\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,labels, test_size = 0.33, random_state=42)\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=2016)\n",
    "# for train_index, test_index in sss.split(df, labels):\n",
    "# x_train = df.iloc[train_index]\n",
    "# X_test = df.iloc[test_index]\n",
    "# y_train = labels.iloc[train_index]\n",
    "# y_test = labels.iloc[test_index]\n",
    "\n",
    "rfg=RandomForestRegressor(n_estimators=100)\n",
    "rfg.fit(x_train,y_train)\n",
    "print(rfg.score(x_test,y_test))\n",
    "print(rfg.feature_importances_)\n",
    "# metrics_dict = {'AUC':metrics.roc_auc_score(y_test, rfg.predict_proba(x_test)[:, 1]),\n",
    "#             'Accuracy':rfg.score(x_test, y_test), 'Recall':recall_score(y_test, rfg.predict(x_test)),\n",
    "#             'Precision':precision_score(y_test, rfg.predict(x_test), zero_division=0), 'F1':f1_score(y_test, rfg.predict(x_test))}\n",
    "# metrics_frame = pd.DataFrame.from_dict(data=metrics_dict,orient='index').transpose()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
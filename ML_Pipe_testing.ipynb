{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import *\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Instructions for the pipeline\n",
    "Requires four inputs:\n",
    "    - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration)\n",
    "    - Proteome data from uniprot (Mass, length, sequence, GO for later analysis)\n",
    "    - NetsurfP data for the proteins that are to be searched\n",
    "    - X characteristics to predict\n",
    "\n",
    "pipeline\n",
    "Take mass spec spreadsheet\n",
    "Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration\n",
    "Merge with Proteome data to get file that has\n",
    "Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence\n",
    "Calculate protein features using biopython\n",
    "Merge with NSP data to get all protein features\n",
    "\n",
    "Split into X and Y dataset with Entries as labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 2)\n",
      "(72, 7)\n",
      "(71, 39)\n",
      "(71, 41)\n",
      "Index(['Entry', 'Sequence', 'Length', 'Mass', 'frac_aa_A', 'frac_aa_C',\n",
      "       'frac_aa_D', 'frac_aa_E', 'frac_aa_F', 'frac_aa_G', 'frac_aa_H',\n",
      "       'frac_aa_I', 'frac_aa_K', 'frac_aa_L', 'frac_aa_M', 'frac_aa_N',\n",
      "       'frac_aa_P', 'frac_aa_Q', 'frac_aa_R', 'frac_aa_S', 'frac_aa_T',\n",
      "       'frac_aa_V', 'frac_aa_W', 'frac_aa_Y', 'molecular_weight',\n",
      "       'aromaticity', 'instability_index', 'flexibility_mean',\n",
      "       'flexibility_std', 'flexibility_var', 'flexibility_max',\n",
      "       'flexibility_min', 'flexibility_median', 'isoelectric_point',\n",
      "       'secondary_structure_fraction_helix',\n",
      "       'secondary_structure_fraction_turn',\n",
      "       'secondary_structure_fraction_sheet',\n",
      "       'secondary_structure_fraction_disordered', 'gravy', 'length', 'mass',\n",
      "       'Unnamed: 0', 'fraction_exposed', 'fraction_buried',\n",
      "       'fraction_exposed_nonpolar_total', 'fraction_exposed_nonpolar_exposed',\n",
      "       'fraction_exposed_polar_total', 'fraction_exposed_polar_exposed',\n",
      "       'rsa_mean', 'rsa_median', 'rsa_std', 'asa_sum',\n",
      "       'fraction_total_exposed_A', 'fraction_total_exposed_C',\n",
      "       'fraction_total_exposed_D', 'fraction_total_exposed_E',\n",
      "       'fraction_total_exposed_F', 'fraction_total_exposed_G',\n",
      "       'fraction_total_exposed_H', 'fraction_total_exposed_I',\n",
      "       'fraction_total_exposed_K', 'fraction_total_exposed_L',\n",
      "       'fraction_total_exposed_M', 'fraction_total_exposed_N',\n",
      "       'fraction_total_exposed_P', 'fraction_total_exposed_Q',\n",
      "       'fraction_total_exposed_R', 'fraction_total_exposed_S',\n",
      "       'fraction_total_exposed_T', 'fraction_total_exposed_V',\n",
      "       'fraction_total_exposed_W', 'fraction_total_exposed_Y',\n",
      "       'fraction_exposed_exposed_A', 'fraction_exposed_exposed_C',\n",
      "       'fraction_exposed_exposed_D', 'fraction_exposed_exposed_E',\n",
      "       'fraction_exposed_exposed_F', 'fraction_exposed_exposed_G',\n",
      "       'fraction_exposed_exposed_H', 'fraction_exposed_exposed_I',\n",
      "       'fraction_exposed_exposed_K', 'fraction_exposed_exposed_L',\n",
      "       'fraction_exposed_exposed_M', 'fraction_exposed_exposed_N',\n",
      "       'fraction_exposed_exposed_P', 'fraction_exposed_exposed_Q',\n",
      "       'fraction_exposed_exposed_R', 'fraction_exposed_exposed_S',\n",
      "       'fraction_exposed_exposed_T', 'fraction_exposed_exposed_V',\n",
      "       'fraction_exposed_exposed_W', 'fraction_exposed_exposed_Y',\n",
      "       'nsp_secondary_structure_coil', 'nsp_secondary_structure_sheet',\n",
      "       'nsp_secondary_structure_helix', 'nsp_disordered',\n",
      "       'asa_sum_normalized'],\n",
      "      dtype='object')\n",
      "     Entry  Enrichment\n",
      "0   P02769   -2.768846\n",
      "1   P00735    6.352583\n",
      "2   Q9N2I2    6.606206\n",
      "3   Q28085    6.430654\n",
      "4   P01044    4.083944\n",
      "..     ...         ...\n",
      "56  G3MYZ3   -1.207773\n",
      "57  O02659    3.694238\n",
      "58  Q29RQ1    0.610974\n",
      "59  P56651    1.687743\n",
      "60  Q32PJ2    1.511005\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "in_dir=\"Input_data/Proteomic data/\"\n",
    "out_dir=\"Output_data/\"\n",
    "NSP_dir=\"NetsurfP_Proteomes/\"\n",
    "uniprot_dir=\"UniProt/\"\n",
    "\n",
    "datfile='test1a.xlsx'\n",
    "\n",
    "#netsurfp data file\n",
    "NSPfilePath=NSP_dir+'Bovine_Proteome.xlsx'\n",
    "NSP_data=pd.read_excel(NSPfilePath)\n",
    "#Uniprot_data file\n",
    "uniprot_filepath=uniprot_dir+'Bovine_Proteome_082322.xlsx'\n",
    "uniprot_dat=pd.read_excel(uniprot_filepath,header=0)\n",
    "\n",
    "raw_MS_data=pd.read_excel(in_dir+datfile,header=0)\n",
    "print(raw_MS_data.shape)\n",
    "raw_prop_data=pd.merge(raw_MS_data, uniprot_dat, left_on='Entry', right_on='Entry')\n",
    "print(raw_prop_data.shape)\n",
    "# print(raw_prop_data.columns)\n",
    "# raw_prop_data=raw_prop_data[['Entry','Enrichment','Length','Mass','Sequence']]\n",
    "# print(raw_prop_data)\n",
    "# MS_data_clean = clean_up_data_mass_spec(raw_MS_data)\n",
    "Accesions_IDs = raw_prop_data[\"Entry\"].to_frame()\n",
    "# print(Accesions_IDs)\n",
    "\n",
    "# print(raw_prop_data['Accession'])\n",
    "#replace Xs and Cs\n",
    "# raw_prop_data=raw_prop_data[['Entry','Length','Mass','Sequence']]\n",
    "PROT_cleaned_data = clean_up_data_biopy(raw_prop_data, Accesions_IDs) #calculates biopython features from protein sequences, and removes proteins removed during mass spec clean up\n",
    "print(PROT_cleaned_data.shape)\n",
    "#\n",
    "PROT_cleaned_data = normalize_mass_length_1DF(PROT_cleaned_data) #function found in data_prep_functions line 167, normalizes mass, length and mw by dividing all values by the max in the column\n",
    "#\n",
    "Protein_data_complete = pd.merge(PROT_cleaned_data, NSP_data, left_on='Entry', right_on='Entry') #merges netsurfp features and biopython features\n",
    "#\n",
    "#\n",
    "# #creates new column called asa_sum_normalized which is the asa_sum value divide by the mass of the protein\n",
    "for df in [Protein_data_complete]:\n",
    "    for col in ['asa_sum']:\n",
    "        df[col+'_normalized'] = df[col] / df['Mass']\n",
    "print(PROT_cleaned_data.shape)\n",
    "print(Protein_data_complete.columns)\n",
    "Accesions_IDs = Protein_data_complete[\"Entry\"].to_frame()\n",
    "MS_clean=Accesions_IDs.merge(raw_MS_data,left_on='Entry',right_on='Entry')\n",
    "print(MS_clean)\n",
    "#eventually merge NP and Experimental data with protein data to make X_data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 97)\n"
     ]
    }
   ],
   "source": [
    "print(Protein_data_complete.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels=MS_clean.drop(['Entry'], axis=1)\n",
    "labels=np.ravel(labels)\n",
    "df=Protein_data_complete.drop(['Entry','Sequence'],axis=1)\n",
    "\n",
    "print(labels)\n",
    "# print(labels)\n",
    "# print(df)\n",
    "first_frame = True #starting dataframe for saving metrics\n",
    "correctness_frame = pd.DataFrame()\n",
    "metrics_frame = pd.DataFrame()\n",
    "print_metrics = 1 #0, doesn't show metrics while runnning for each model, 1 does show metrics\n",
    "trials = 100\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,labels, test_size = 0.33, random_state=42)\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=2016)\n",
    "# for train_index, test_index in sss.split(df, labels):\n",
    "# x_train = df.iloc[train_index]\n",
    "# X_test = df.iloc[test_index]\n",
    "# y_train = labels.iloc[train_index]\n",
    "# y_test = labels.iloc[test_index]\n",
    "\n",
    "rfg=RandomForestRegressor(n_estimators=100)\n",
    "rfg.fit(x_train,y_train)\n",
    "print(rfg.score(x_test,y_test))\n",
    "print(rfg.feature_importances_)\n",
    "# metrics_dict = {'AUC':metrics.roc_auc_score(y_test, rfg.predict_proba(x_test)[:, 1]),\n",
    "#             'Accuracy':rfg.score(x_test, y_test), 'Recall':recall_score(y_test, rfg.predict(x_test)),\n",
    "#             'Precision':precision_score(y_test, rfg.predict(x_test), zero_division=0), 'F1':f1_score(y_test, rfg.predict(x_test))}\n",
    "# metrics_frame = pd.DataFrame.from_dict(data=metrics_dict,orient='index').transpose()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 2)\n",
      "(72, 7)\n",
      "(71, 39)\n",
      "(71, 41)\n",
      "(61, 97)\n",
      "     Entry  Enrichment\n",
      "0   P02769   -2.768846\n",
      "1   P00735    6.352583\n",
      "2   Q9N2I2    6.606206\n",
      "3   Q28085    6.430654\n",
      "4   P01044    4.083944\n",
      "..     ...         ...\n",
      "56  G3MYZ3   -1.207773\n",
      "57  O02659    3.694238\n",
      "58  Q29RQ1    0.610974\n",
      "59  P56651    1.687743\n",
      "60  Q32PJ2    1.511005\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "in_dir=\"Input_data/Proteomic data/\"\n",
    "out_dir=\"Output_data/\"\n",
    "NSP_dir=\"NetsurfP_Proteomes/\"\n",
    "uniprot_dir=\"UniProt/\"\n",
    "\n",
    "#Mass Spec data input in one excel spreadsheet\n",
    "datfile='test_withNPID.xlsx'\n",
    "uniprot_filepath=uniprot_dir+'Bovine_Proteome_082322.xlsx'\n",
    "uniprot_dat=pd.read_excel(uniprot_filepath,header=0)\n",
    "# Protein data input in one excel spreadsheet with two sheets\n",
    "\n",
    "datfile='test_withNPID.xlsx'\n",
    "# prot_prop = 'Protein Properties'\n",
    "# mass_spec = 'Mass Sped Details'\n",
    "\n",
    "\n",
    "\n",
    "#netsurfp data file\n",
    "NSPfilePath=NSP_dir+'Bovine_Proteome.xlsx'\n",
    "\n",
    "#NP data file\n",
    "NPdata=pd.read_excel(in_dir+\"NP_Database.xlsx\",header=0)\n",
    "\n",
    "raw_MS_data=pd.read_excel(in_dir+datfile,header=0)\n",
    "raw_prop_data=pd.merge(raw_MS_data, uniprot_dat, left_on='Entry', right_on='Entry')\n",
    "print(raw_prop_data)\n",
    "NSP_data=pd.read_excel(NSPfilePath)\n",
    "#\n",
    "# #clean up and calculate % protein abundance and enrichment, function found in data_prep_functions line 470\n",
    "#\n",
    "MS_data_clean = raw_MS_data.copy()\n",
    "Accesions_IDs = MS_data_clean[\"Entry\"].to_frame()\n",
    "\n",
    "\n",
    "# clean up protein data, function found in data_prep_functions.py line 367\n",
    "\n",
    "PROT_cleaned_data = clean_up_data_biopy(raw_prop_data, Accesions_IDs) #calculates biopython features from protein sequences, and removes proteins removed during mass spec clean up\n",
    "\n",
    "PROT_cleaned_data = normalize_mass_length_1DF(PROT_cleaned_data) #function found in data_prep_functions line 167, normalizes mass, length and mw by dividing all values by the max in the column\n",
    "\n",
    "Protein_data_complete = pd.merge(PROT_cleaned_data, NSP_data, left_on='Entry', right_on='Entry') #merges netsurfp features and biopython features\n",
    "\n",
    "\n",
    "#creates new column called asa_sum_normalized which is the asa_sum value divide by the mass of the protein\n",
    "for df in [Protein_data_complete]:\n",
    "    for col in ['asa_sum']:\n",
    "        df[col+'_normalized'] = df[col] / df['Mass']\n",
    "# print(Protein_data_complete.columns)\n",
    "# print(NPdata)\n",
    "\n",
    "data_complete= pd.merge(Protein_data_complete,NPdata,how='left', on='NPID')\n",
    "print(data_complete.columns)\n",
    "data_complete.drop(labels=['notes','NPID'],inplace=True,axis=1)\n",
    "\n",
    "print(data_complete.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Entry  Enrichment\n",
      "0   P02769   -2.768846\n",
      "1   P41361    4.335954\n",
      "2   P00735    6.352583\n",
      "3   Q9N2I2    6.606206\n",
      "4   P12763   -1.479128\n",
      "..     ...         ...\n",
      "67  O02659    3.694238\n",
      "68  Q29RQ1    0.610974\n",
      "69  P56651    1.687743\n",
      "70  P07224    0.241398\n",
      "71  Q32PJ2    1.511005\n",
      "\n",
      "[72 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(raw_MS_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.76884625  6.35258301  6.60620628  6.43065406  4.08394386  4.40732889\n",
      " -1.30000425 11.46009002  5.60916061  7.46149993  7.56458367  8.53955573\n",
      "  4.32444503  4.46284158  3.34860284  5.56321463  9.48529466 -0.76584813\n",
      " 11.93067379  9.18919046  3.87285529 10.93767607  2.81087734  6.6379646\n",
      " -0.75827398 10.69164752 -1.07751603 -4.66042685  7.28418398 -0.49704936\n",
      " -1.46081005 -2.58848542  0.05016747 -1.18140954  3.07292054  4.44220764\n",
      "  0.09845458 -0.8624439  -0.60080095  1.47094187 -0.76131074  4.78269676\n",
      " -2.54348802  3.83456732 -1.50702277  3.70222029  0.2279234   4.03626105\n",
      "  2.32670862 -0.8420308   0.05758126  0.08919988  4.83971541  4.58869108\n",
      "  2.77213737 -2.43876775 -1.20777339  3.69423846  0.61097355  1.68774307\n",
      "  1.51100458]\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor()",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=MS_clean.drop(['Entry'], axis=1)\n",
    "labels=np.ravel(labels)\n",
    "df=Protein_data_complete.drop(['Entry','Sequence'],axis=1)\n",
    "\n",
    "print(labels)\n",
    "# print(labels)\n",
    "# print(df)\n",
    "first_frame = True #starting dataframe for saving metrics\n",
    "correctness_frame = pd.DataFrame()\n",
    "metrics_frame = pd.DataFrame()\n",
    "print_metrics = 1 #0, doesn't show metrics while runnning for each model, 1 does show metrics\n",
    "trials = 100\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,labels, test_size = 0.33, random_state=42)\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=2016)\n",
    "# for train_index, test_index in sss.split(df, labels):\n",
    "# x_train = df.iloc[train_index]\n",
    "# X_test = df.iloc[test_index]\n",
    "# y_train = labels.iloc[train_index]\n",
    "# y_test = labels.iloc[test_index]\n",
    "\n",
    "rfg=RandomForestRegressor(n_estimators=100)\n",
    "rfg.fit(x_train,y_train)\n",
    "\n",
    "metrics_dict = {'AUC':metrics.roc_auc_score(y_test, rfg.predict_proba(x_test)[:, 1]),\n",
    "            'Accuracy':rfg.score(x_test, y_test), 'Recall':recall_score(y_test, rfg.predict(x_test)),\n",
    "            'Precision':precision_score(y_test, rfg.predict(x_test), zero_division=0), 'F1':f1_score(y_test, rfg.predict(x_test))}\n",
    "metrics_frame = pd.DataFrame.from_dict(data=metrics_dict,orient='index').transpose()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15560164896493955\n",
      "[0.00513707 0.00350741 0.00797886 0.01333913 0.00534708 0.02983831\n",
      " 0.02573964 0.01215556 0.00451627 0.00397026 0.00190447 0.0050219\n",
      " 0.00775726 0.00167601 0.00209276 0.01449517 0.0276024  0.00197442\n",
      " 0.00876043 0.00210115 0.0152543  0.00307915 0.00235378 0.00199087\n",
      " 0.00801014 0.00564767 0.00364288 0.00581822 0.01020752 0.00519147\n",
      " 0.00938884 0.02548748 0.02545685 0.00129803 0.01520308 0.00332034\n",
      " 0.02192912 0.00248955 0.00355795 0.00732782 0.00295544 0.00286757\n",
      " 0.00068237 0.00151711 0.00221792 0.00332085 0.00108479 0.00093347\n",
      " 0.00818404 0.00294311 0.00283465 0.0031595  0.00093302 0.01143347\n",
      " 0.00340068 0.00720392 0.01865518 0.0781181  0.00323711 0.02558677\n",
      " 0.04585004 0.00293531 0.00275345 0.00374175 0.02810957 0.00307741\n",
      " 0.00872537 0.00595159 0.00411879 0.04666915 0.00196165 0.00170326\n",
      " 0.01437289 0.00689167 0.00139472 0.00178564 0.00257786 0.0531542\n",
      " 0.02220144 0.06271009 0.02218767 0.0051249  0.00291569 0.00548969\n",
      " 0.01041776 0.00450503 0.01455326 0.00284474 0.0023277  0.00522648\n",
      " 0.03894787 0.00542074 0.00672791 0.00283233 0.00695268]\n"
     ]
    }
   ],
   "source": [
    "print(rfg.score(x_test,y_test))\n",
    "print(rfg.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import *\n",
    "from helper_functions_KP import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Instructions for the pipeline Requires two inputs for training: - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration) - NetsurfP and Biopython data that has been precalculated - X characteristics to predict\n",
    "pipeline Take mass spec spreadsheet Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration Merge with Proteome data to get file that has Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence Calculate protein features using biopython Merge with NSP data to get all protein features\n",
    "Split into X and Y dataset with Entries as labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmp95\\Anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Pull together Proteomic data\n",
    "in_dir=\"Input_data/Proteomic data/abundance/\"\n",
    "all_file='Input_data/Proteomic data/abundance/Intensity _all20230202.xlsx'\n",
    "#combine Mass Spec data input into one excel spreadsheet - Entry - Abundance labeled by NP Unique ID\n",
    "#Abundance as a percent\n",
    "#take files in_dir and combine then into one pandas df (raw_MS_data)\n",
    "# files = os.listdir(in_dir)\n",
    "# for i,f in enumerate(files):\n",
    "#     if i==0:\n",
    "#         raw_MS_data=pd.read_excel(in_dir+f,header=0)\n",
    "#     else:\n",
    "#         temp = pd.read_excel(in_dir+f,header=0)\n",
    "#         raw_MS_data=raw_MS_data.merge(temp,how='outer',on='Entry')\n",
    "raw_MS_data=pd.read_excel(all_file,header=0)\n",
    "# melt the df to make it an accession number, NPUNID, Abundance dataset\n",
    "raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'],var_name='Sample_num', value_name='Abundance')\n",
    "#remove prots that were added due to merge\n",
    "raw_MS_data=raw_MS_data.dropna()\n",
    "###Bring in controls (MS data for serums)##\n",
    "controls=pd.read_excel('Input_data/Proteomic data/controls_combined.xlsx',header=0)\n",
    "MS_data_controls = pd.merge(raw_MS_data,controls,how='left', on='Entry')\n",
    "###Bring in Uniprot_data,NSPdata and NP data##\n",
    "uniprot_filepath='Input_data/BioPython_data/Combined_biopyCalcs.xlsx'\n",
    "uniprot_dat=pd.read_excel(uniprot_filepath,header=0)\n",
    "NSPfilePath='Input_data/NetSurfP_data/Combined.xlsx'\n",
    "NSP_data=pd.read_excel(NSPfilePath)\n",
    "###Bring in NP data and merge to get complete NP dataset###\n",
    "NP_filepath='Input_data/NPs/NP_Database.xlsx'\n",
    "NPUNdata=pd.read_excel(NP_filepath,header=0,sheet_name='NPUNID')\n",
    "NPprop=pd.read_excel(NP_filepath,header=0,sheet_name='NP_Props')\n",
    "NPdata=pd.merge(NPUNdata,NPprop,how=\"left\",on='NPID')\n",
    "NPdata.dropna(inplace=True)\n",
    "#calculate Enrichment\n",
    "#####MAYBE add binning here to to keep negative results and improve capapbilities######\n",
    "MS_data_controls['Enrichment']= np.log2(MS_data_controls['Abundance']/MS_data_controls['Abundance_Controls'])\n",
    "MS_data=MS_data_controls.drop(columns=['Abundance','Abundance_Controls'])\n",
    "raw_prop_data=pd.merge(MS_data, uniprot_dat.drop_duplicates(subset=['Entry']), how='left',on='Entry')\n",
    "\n",
    "Protein_data_complete = pd.merge(raw_prop_data, NSP_data.drop_duplicates(subset=['Entry']),how='left', on='Entry') #merges netsurfp features and biopython features\n",
    "Protein_data_complete.fillna(0,inplace=True)\n",
    "#creates new column called asa_sum_normalized which is the asa_sum value divide by the mass of the protein\n",
    "for df in [Protein_data_complete]:\n",
    "    for col in ['asa_sum']:\n",
    "        df[col+'_normalized'] = df[col] / df['Mass']\n",
    "\n",
    "data_complete= pd.merge(Protein_data_complete,NPdata,how='inner', on='Sample_num')\n",
    "data_complete.drop(columns=['notes','Notes','NPUNID'],inplace=True)\n",
    "data_complete.fillna(0,inplace=True)\n",
    "data_complete= data_complete.replace([-np.inf],'-12')\n",
    "data_complete=data_complete.replace([np.inf],'12')\n",
    "data_complete2=pd.get_dummies(data_complete, columns=['Core Material','Surface_Ligand'])\n",
    "\n",
    "\n",
    "#set labels (what we are trying to predict) as Enrichment column\n",
    "labels=data_complete2['Enrichment'].copy()\n",
    "#make it one dimenisional\n",
    "labels=np.ravel(labels)\n",
    "#drop qualitative, not neccessary, and label columns\n",
    "df=data_complete2.drop(['Entry','Sequence','NPID','Enrichment','Ligands','Protein Source','Sample_num','Unnamed: 5','Raw_FileID'],axis=1)\n",
    "#create df without bonus NSP columns (remove total_exposed)\n",
    "df_NSP_drop=df.copy()\n",
    "to_drop=df_NSP_drop.filter(like='total_exposed_')\n",
    "df_NSP_drop.drop(columns=to_drop,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length\n",
      "Mass\n",
      "frac_aa_A\n",
      "frac_aa_C\n",
      "frac_aa_D\n",
      "frac_aa_E\n",
      "frac_aa_F\n",
      "frac_aa_G\n",
      "frac_aa_H\n",
      "frac_aa_I\n",
      "frac_aa_K\n",
      "frac_aa_L\n",
      "frac_aa_M\n",
      "frac_aa_N\n",
      "frac_aa_P\n",
      "frac_aa_Q\n",
      "frac_aa_R\n",
      "frac_aa_S\n",
      "frac_aa_T\n",
      "frac_aa_V\n",
      "frac_aa_W\n",
      "frac_aa_Y\n",
      "molecular_weight\n",
      "aromaticity\n",
      "instability_index\n",
      "flexibility_mean\n",
      "flexibility_std\n",
      "flexibility_var\n",
      "flexibility_max\n",
      "flexibility_min\n",
      "flexibility_median\n",
      "isoelectric_point\n",
      "secondary_structure_fraction_helix\n",
      "secondary_structure_fraction_turn\n",
      "secondary_structure_fraction_sheet\n",
      "secondary_structure_fraction_disordered\n",
      "gravy\n",
      "fraction_exposed\n",
      "fraction_buried\n",
      "fraction_exposed_nonpolar_total\n",
      "fraction_exposed_nonpolar_exposed\n",
      "fraction_exposed_polar_total\n",
      "fraction_exposed_polar_exposed\n",
      "rsa_mean\n",
      "rsa_median\n",
      "rsa_std\n",
      "asa_sum\n",
      "fraction_total_exposed_A\n",
      "fraction_total_exposed_C\n",
      "fraction_total_exposed_D\n",
      "fraction_total_exposed_E\n",
      "fraction_total_exposed_F\n",
      "fraction_total_exposed_G\n",
      "fraction_total_exposed_H\n",
      "fraction_total_exposed_I\n",
      "fraction_total_exposed_K\n",
      "fraction_total_exposed_L\n",
      "fraction_total_exposed_M\n",
      "fraction_total_exposed_N\n",
      "fraction_total_exposed_P\n",
      "fraction_total_exposed_Q\n",
      "fraction_total_exposed_R\n",
      "fraction_total_exposed_S\n",
      "fraction_total_exposed_T\n",
      "fraction_total_exposed_V\n",
      "fraction_total_exposed_W\n",
      "fraction_total_exposed_Y\n",
      "fraction_exposed_exposed_A\n",
      "fraction_exposed_exposed_C\n",
      "fraction_exposed_exposed_D\n",
      "fraction_exposed_exposed_E\n",
      "fraction_exposed_exposed_F\n",
      "fraction_exposed_exposed_G\n",
      "fraction_exposed_exposed_H\n",
      "fraction_exposed_exposed_I\n",
      "fraction_exposed_exposed_K\n",
      "fraction_exposed_exposed_L\n",
      "fraction_exposed_exposed_M\n",
      "fraction_exposed_exposed_N\n",
      "fraction_exposed_exposed_P\n",
      "fraction_exposed_exposed_Q\n",
      "fraction_exposed_exposed_R\n",
      "fraction_exposed_exposed_S\n",
      "fraction_exposed_exposed_T\n",
      "fraction_exposed_exposed_V\n",
      "fraction_exposed_exposed_W\n",
      "fraction_exposed_exposed_Y\n",
      "nsp_secondary_structure_coil\n",
      "nsp_secondary_structure_sheet\n",
      "nsp_secondary_structure_helix\n",
      "nsp_disordered\n",
      "BatchID\n",
      "Zeta Potential\n",
      "Ligand_Carboxylate\n",
      "Ligand_BSA\n",
      "Ligand_Amine\n",
      "Ligand_Citrate\n",
      "Ligand_PEG\n",
      "Ligand_PEI\n",
      "Ligand_PVP\n",
      "Ligand_Au\n",
      "Dtem\n",
      "Dh_core\n",
      "Dh_functionalized\n",
      "Shaken\n",
      "Centrifuged\n",
      "NP_incubation Concentration (mg/mL)\n",
      "Incubation Concentration (mg/ml)\n",
      "Incubation Time (minutes)\n",
      "Temperature\n",
      "Core Material_Iron Oxide\n",
      "Core Material_Polystyrene\n",
      "Surface_Ligand_Carboxylate\n",
      "Surface_Ligand_Carboxylate BSA\n",
      "Surface_Ligand_Citrate\n",
      "Surface_Ligand_PEG2k\n",
      "Surface_Ligand_PEG5k\n",
      "Surface_Ligand_PEI\n",
      "Surface_Ligand_PVP\n"
     ]
    }
   ],
   "source": [
    "#create normalized dataframe\n",
    "df_norm=df.copy()\n",
    "for col in df_norm.columns:\n",
    "    if col == 'asa_sum_normalized':\n",
    "        continue\n",
    "    df_norm[col]=df_norm[col]/df_norm[col].max()\n",
    "    print(col)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_norm.fillna(0,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_list=[df,df_norm,df_NSP_drop]\n",
    "out_name=['df','norm','nspdrop']\n",
    "df_listnew=[]\n",
    "x=0\n",
    "for i in df_list:\n",
    "    df_listnew.append(feat_elim_rand(i,labels,out_name[x],20,250,3))\n",
    "    x+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90\n",
      "  95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180\n",
      " 185 190 195 200 205 210 215 220 225 230 235 240 245 250 255 260 265 270\n",
      " 275 280 285 290 295 300 305 310 315 320 325 330 335 340 345 350 355 360\n",
      " 365 370 375 380 385 390 395 400 405 410 415 420 425 430 435 440 445 450\n",
      " 455 460 465 470 475 480 485 490 495 500 505 510 515 520 525 530 535 540\n",
      " 545 550 555 560 565 570 575 580 585 590 595 600 605 610 615 620 625 630\n",
      " 635 640 645 650 655 660 665 670 675 680 685 690 695 700 705 710 715 720\n",
      " 725 730 735 740 745 750 755 760 765 770 775 780 785 790 795 800 805 810\n",
      " 815 820 825 830 835 840 845 850 855 860 865 870 875 880 885 890 895 900\n",
      " 905 910 915 920 925 930 935 940 945 950 955 960 965 970 975 980 985 990\n",
      " 995]\n"
     ]
    }
   ],
   "source": [
    "estimators=np.arange(5,1000,5)\n",
    "out_name=np.arange(5,1000,5)\n",
    "print(out_name)\n",
    "out_list=[0]*200\n",
    "for i in range(len(estimators)):\n",
    "    out_list[i]=rand_forest_reg_fit(df_listnew[2],labels,out_name[i],0.20,estimators[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# print(out_list[2])\n",
    "a=pd.DataFrame(list(zip(estimators,out_list)), columns=['number of estimators','accuracy'])\n",
    "a.to_excel(\"Output_data/estimatorandaccuracy_20feats.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot distrubition of (feat) with -labels and dsitrubition with positive values\n",
    "# frac_aa_E,K,R, flexibility_min, Isoelectric Point, gravy, fraction_exposed_L,M,R,S,T,Y, zeta potential\n",
    "#plot PCA of features and labels after RFE\n",
    "#plot loss of features after RFE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
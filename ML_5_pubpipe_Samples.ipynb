{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T11:53:14.062503Z",
     "end_time": "2023-04-27T11:53:15.037392Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import _gradient_boosting\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from helper_functions_KP import *\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Instructions for the pipeline Requires two inputs for training: - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration) - NetsurfP and Biopython data that has been precalculated - X characteristics to predict\n",
    "pipeline Take mass spec spreadsheet Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration Merge with Proteome data to get file that has Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence Calculate protein features using biopython Merge with NSP data to get all protein features\n",
    "Split into X and Y dataset with Entries as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T11:22:00.378115Z",
     "end_time": "2023-04-24T11:24:19.942047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before dropping rows (474, 14)\n",
      "shape after dropping rows (7, 14)\n",
      "shape before dropping rows (91, 3)\n",
      "shape after dropping rows (91, 3)\n",
      "final shape after melt (3061, 3)\n",
      "number of zeros in the dataset: 65\n",
      "shape before dropping rows (474, 14)\n",
      "shape after dropping rows (13, 14)\n",
      "shape before dropping rows (169, 3)\n",
      "shape after dropping rows (169, 3)\n",
      "final shape after melt (4844, 3)\n",
      "number of zeros in the dataset: 298\n",
      "shape before dropping rows (474, 14)\n",
      "shape after dropping rows (27, 14)\n",
      "shape before dropping rows (351, 3)\n",
      "shape after dropping rows (351, 3)\n",
      "final shape after melt (6841, 3)\n",
      "number of zeros in the dataset: 752\n",
      "shape before dropping rows (474, 14)\n",
      "shape after dropping rows (52, 14)\n",
      "shape before dropping rows (676, 3)\n",
      "shape after dropping rows (676, 3)\n",
      "final shape after melt (10191, 3)\n",
      "number of zeros in the dataset: 2066\n"
     ]
    }
   ],
   "source": [
    "### Make 3 DFs### Load saved DFs instead of running this cell\n",
    "#DF 1 All_ files combined\n",
    "#DF 2 Synth Files ( the 19 UniqueNPs that I ran with my synthesized NPs+some PS NPs)\n",
    "#DF 3 All_files 30% zeros\n",
    "multi_files = True  #set to false if you just want to set one  prot_abund_file\n",
    "in_dir = \"Input_data/Proteomic data/Abundance2/\"\n",
    "prot_abund_file = 'Input_data/Proteomic data/abundance/Norm_Intensity_Bovsynth022123.xlsx'\n",
    "NP_filepath = 'Input_data/NPs/NP_Database2.xlsx'\n",
    "controls_file = 'Input_data/Proteomic data/controls_combined.xlsx'\n",
    "uniprot_filepath = 'Input_data/BioPython_data/Combined_biopyCalcs.xlsx'\n",
    "NSPfilePath = 'Input_data/NetSurfP_data/Combined.xlsx'\n",
    "cutoff_vals=[0.1,0.2,0.3,0.5]\n",
    "files = os.listdir(in_dir)\n",
    "for zerosperrow in cutoff_vals:\n",
    "    if multi_files == True:\n",
    "        for i, f in enumerate(files):\n",
    "            if i == 0:\n",
    "                raw_MS_data = pd.read_excel(in_dir + f, header=0)\n",
    "                cols = raw_MS_data.shape[1]\n",
    "                cutoff = int(zerosperrow * cols)\n",
    "                print('shape before dropping rows', raw_MS_data.shape)\n",
    "                raw_MS_data = raw_MS_data.drop(raw_MS_data[(raw_MS_data == 0).sum(axis=1) >= cutoff].index)\n",
    "                print('shape after dropping rows', raw_MS_data.shape)\n",
    "                # print(raw_MS_data)\n",
    "                raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "\n",
    "            else:\n",
    "\n",
    "                temp = pd.read_excel(in_dir + f, header=0)\n",
    "                cols = temp.shape[1]\n",
    "                cutoff = int(zerosperrow * cols)\n",
    "                print('shape before dropping rows', raw_MS_data.shape)\n",
    "                temp = temp.drop(temp[(temp == 0).sum(axis=1) >= cutoff].index)\n",
    "                print('shape after dropping rows', raw_MS_data.shape)\n",
    "                temp = pd.melt(temp, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "\n",
    "                raw_MS_data = pd.concat([raw_MS_data, temp])\n",
    "                print('final shape after melt', raw_MS_data.shape)\n",
    "                print('number of zeros in the dataset:',(raw_MS_data == 0).sum().sum())\n",
    "\n",
    "\n",
    "    else:\n",
    "        raw_MS_data = pd.read_excel(prot_abund_file, header=0)\n",
    "        cols = raw_MS_data.shape[1]\n",
    "        cutoff = int(zerosperrow * cols)\n",
    "        print('shape beofre dropping rows', raw_MS_data.shape)\n",
    "        raw_MS_data = raw_MS_data.drop(raw_MS_data[(raw_MS_data == 0).sum(axis=1) >= cutoff].index)\n",
    "        print('shape after dropping rows', raw_MS_data.shape)\n",
    "        raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "    #remove prots that were added due to merge\n",
    "    raw_MS_data = raw_MS_data.dropna()\n",
    "    ###Bring in controls (MS data for serums)##\n",
    "    controls = pd.read_excel(controls_file, header=0)\n",
    "    MS_data_controls = pd.merge(raw_MS_data, controls, how='left', on='Entry')\n",
    "    ###Bring in Uniprot_data,NSPdata and NP data##\n",
    "    uniprot_dat = pd.read_excel(uniprot_filepath, header=0)\n",
    "    NSP_data = pd.read_excel(NSPfilePath)\n",
    "    ###Bring in NP data and merge to get complete NP dataset###\n",
    "    NPUNdata = pd.read_excel(NP_filepath, header=0, sheet_name='NPUNID')\n",
    "    NPprop = pd.read_excel(NP_filepath, header=0, sheet_name='NP_Props')\n",
    "    NPdata = pd.merge(NPUNdata, NPprop, how=\"left\", on='NPID')\n",
    "    # NPdata.dropna(inplace=True)\n",
    "    #calculate Enrichment\n",
    "    #####MAYBE add binning here to keep negative results and improve capapbilities######\n",
    "    # MS_data_controls['Enrichment']= np.log2(MS_data_controls['Abundance']/MS_data_controls['Abundance_Controls'])\n",
    "    # MS_data=MS_data_controls.drop(columns=['Abundance','Abundance_Controls'])\n",
    "    raw_prop_data = pd.merge(MS_data_controls, uniprot_dat.drop_duplicates(subset=['Entry']), how='left', on='Entry')\n",
    "    Protein_data_complete = pd.merge(raw_prop_data, NSP_data.drop_duplicates(subset=['Entry']), how='left',\n",
    "                                 on='Entry')\n",
    "    #merges netsurfp features and biopython features\n",
    "    Protein_data_complete.fillna(0, inplace=True)\n",
    "    # print('Sample Nums in Protein Data',Protein_data_complete['Sample_num'])\n",
    "    data_complete = pd.merge(Protein_data_complete, NPdata, how='inner', on='Sample_num')\n",
    "    data_complete.fillna(0, inplace=True)\n",
    "    #create ordinal variables for the core materials and surface ligands\n",
    "    le = LabelEncoder()\n",
    "    data_complete['Core Material'] = le.fit_transform(data_complete['Core Material'])\n",
    "    data_complete['Surface_Ligand'] = le.fit_transform(data_complete['Surface_Ligand'])\n",
    "    #shuffle data using sample\n",
    "    data_complete = data_complete.sample(frac=1)\n",
    "\n",
    "    data_complete.drop(columns=['notes', 'Notes'], inplace=True)\n",
    "\n",
    "    data_complete.to_excel(\"Input_data/Save_files/df_3_all_\"+str(int(zerosperrow*100))+\"%zeros.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large OG Pipeline # Move lower #\n",
    "\n",
    "#Editable Variables\n",
    "#list of test filters\n",
    "# zerosperrow = 0.3\n",
    "# multi_files = True  #set to false if you just want to set one  prot_abund_file\n",
    "# rfecv_ = True  #True_runs RFECV\n",
    "# rfe_ = False     #True runs Recursive feature elimination\n",
    "# abund_controls = True # True keeps the serum as an input feature\n",
    "# splits = 10     #number of splits for cross validation across QC methods and feature selection methods\n",
    "# in_dir = \"Input_data/Proteomic data/Abundance2/\"\n",
    "# prot_abund_file = 'Input_data/Proteomic data/Abundance2/Norm_Intensity _all20230403.xlsx'\n",
    "# NP_filepath = 'Input_data/NPs/NP_Database.xlsx'\n",
    "# controls_file = 'Input_data/Proteomic data/controls_combined.xlsx'\n",
    "# uniprot_filepath = 'Input_data/BioPython_data/Combined_biopyCalcs.xlsx'\n",
    "# NSPfilePath = 'Input_data/NetSurfP_data/Combined.xlsx'\n",
    "#\n",
    "# scorings=['r2','neg_mean_squared_error','mean_absolute_error']\n",
    "# RFE_Feats = 40\n",
    "# model = RandomForestRegressor(n_estimators=80)\n",
    "# # model=XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, objective='reg:squarederror')\n",
    "# summary_tmp=[]\n",
    "# for z in scorings:\n",
    "#     id = 'Con_drop_' +str(z)+ '_30' + '%zeros'\n",
    "#     # take files in_dir and combine then into a pandas df (raw_MS_data) ###USE when combining multiple datasets####\n",
    "#     # melt the df to make it an accession number, NPUNID, Abundance dataset before combining\n",
    "#     files = os.listdir(in_dir)\n",
    "#     if multi_files == True:\n",
    "#         for i, f in enumerate(files):\n",
    "#             if i == 0:\n",
    "#                 raw_MS_data = pd.read_excel(in_dir + f, header=0)\n",
    "#                 cols = raw_MS_data.shape[1]\n",
    "#                 cutoff = int(zerosperrow * cols)\n",
    "#                 print('shape before dropping rows', raw_MS_data.shape)\n",
    "#                 raw_MS_data = raw_MS_data.drop(raw_MS_data[(raw_MS_data == 0).sum(axis=1) >= cutoff].index)\n",
    "#                 print('shape after dropping rows', raw_MS_data.shape)\n",
    "#                 # print(raw_MS_data)\n",
    "#                 raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "#\n",
    "#             else:\n",
    "#\n",
    "#                 temp = pd.read_excel(in_dir + f, header=0)\n",
    "#                 cols = temp.shape[1]\n",
    "#                 cutoff = int(zerosperrow * cols)\n",
    "#                 print('shape before dropping rows', raw_MS_data.shape)\n",
    "#                 temp = temp.drop(temp[(temp == 0).sum(axis=1) >= cutoff].index)\n",
    "#                 print('shape after dropping rows', raw_MS_data.shape)\n",
    "#                 temp = pd.melt(temp, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "#\n",
    "#                 raw_MS_data = pd.concat([raw_MS_data, temp])\n",
    "#                 print('final shape after melt', raw_MS_data.shape)\n",
    "#                 print('number of zeros in the dataset:',(raw_MS_data == 0).sum().sum())\n",
    "#\n",
    "#\n",
    "#     else:\n",
    "#         raw_MS_data = pd.read_excel(prot_abund_file, header=0)\n",
    "#         cols = raw_MS_data.shape[1]\n",
    "#         cutoff = int(zerosperrow * cols)\n",
    "#         print('shape beofre dropping rows', raw_MS_data.shape)\n",
    "#         raw_MS_data = raw_MS_data.drop(raw_MS_data[(raw_MS_data == 0).sum(axis=1) >= cutoff].index)\n",
    "#         print('shape after dropping rows', raw_MS_data.shape)\n",
    "#         raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "#     #remove prots that were added due to merge\n",
    "#     raw_MS_data = raw_MS_data.dropna()\n",
    "#     ###Bring in controls (MS data for serums)##\n",
    "#     controls = pd.read_excel(controls_file, header=0)\n",
    "#     MS_data_controls = pd.merge(raw_MS_data, controls, how='left', on='Entry')\n",
    "#     ###Bring in Uniprot_data,NSPdata and NP data##\n",
    "#     uniprot_dat = pd.read_excel(uniprot_filepath, header=0)\n",
    "#     NSP_data = pd.read_excel(NSPfilePath)\n",
    "#     ###Bring in NP data and merge to get complete NP dataset###\n",
    "#     NPUNdata = pd.read_excel(NP_filepath, header=0, sheet_name='NPUNID')\n",
    "#     NPprop = pd.read_excel(NP_filepath, header=0, sheet_name='NP_Props')\n",
    "#     NPdata = pd.merge(NPUNdata, NPprop, how=\"left\", on='NPID')\n",
    "#     NPdata.dropna(inplace=True)\n",
    "#     #calculate Enrichment\n",
    "#     #####MAYBE add binning here to keep negative results and improve capapbilities######\n",
    "#     # MS_data_controls['Enrichment']= np.log2(MS_data_controls['Abundance']/MS_data_controls['Abundance_Controls'])\n",
    "#     # MS_data=MS_data_controls.drop(columns=['Abundance','Abundance_Controls'])\n",
    "#     raw_prop_data = pd.merge(MS_data_controls, uniprot_dat.drop_duplicates(subset=['Entry']), how='left', on='Entry')\n",
    "#     Protein_data_complete = pd.merge(raw_prop_data, NSP_data.drop_duplicates(subset=['Entry']), how='left',\n",
    "#                                      on='Entry')\n",
    "#     #merges netsurfp features and biopython features\n",
    "#     Protein_data_complete.fillna(0, inplace=True)\n",
    "#     data_complete = pd.merge(Protein_data_complete, NPdata, how='inner', on='Sample_num')\n",
    "#     data_complete.fillna(0, inplace=True)\n",
    "#     #create ordinal variables for the core materials and surface ligands\n",
    "#     le = LabelEncoder()\n",
    "#     data_complete['Core Material'] = le.fit_transform(data_complete['Core Material'])\n",
    "#     data_complete['Surface_Ligand'] = le.fit_transform(data_complete['Surface_Ligand'])\n",
    "#     #shuffle data using sample\n",
    "#     data_complete = data_complete.sample(frac=1)\n",
    "#     #set labels (what we are trying to predict) as Abundance\n",
    "#     label_abund_df = data_complete['Abundance'].copy()\n",
    "#     label_abund = np.ravel(label_abund_df)\n",
    "#     NPIDs=data_complete['NPUNID'].copy()\n",
    "#     data_complete.drop(columns=['notes', 'Notes', 'NPUNID'], inplace=True)\n",
    "#\n",
    "#     #make it one dimenisional\n",
    "#     #drop qualitative, not neccessary, and label columns\n",
    "#     #create df without bonus NSP columns (remove total_exposed) There are too sets of features total_exposed and exposed_exposed\n",
    "#     to_drop = data_complete.filter(like='total_exposed_')\n",
    "#     data_complete.drop(columns=to_drop, inplace=True)\n",
    "#     df = data_complete.drop(\n",
    "#         ['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5',\n",
    "#          'Raw_FileID'], axis=1)\n",
    "#     if abund_controls == False:\n",
    "#         df.drop(columns=['Abundance_Controls'], inplace=True)\n",
    "#\n",
    "#     df_out=pd.concat([df, NPIDs,label_abund_df],axis=1)\n",
    "#     df_out.to_excel(\"Input_data/Save_files/df_whole_\"+id+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-22T16:11:40.892094Z",
     "start_time": "2023-04-22T16:11:19.779507Z"
    }
   },
   "outputs": [],
   "source": [
    "#Sample code for loading saved DF and dropping appropriate columns before running### Also For running RFECV and saving the reduced df\n",
    "df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "id='04232023'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "labels_df= df['Abundance'].copy()\n",
    "id_col= df['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels_df)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "splits=10\n",
    "scoring='neg_mean_squared_error'\n",
    "df=df.drop(columns=['Entry', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID'])\n",
    "import math\n",
    "\n",
    "start = 0.0001\n",
    "stop = 1\n",
    "num_points = 10\n",
    "# Calculate the common difference between consecutive terms in the series\n",
    "common_diff = (math.log(stop) - math.log(start)) / (num_points - 1)\n",
    "# Generate the logarithmic series as a list\n",
    "Abund_filter = [start * math.exp(i * common_diff) for i in range(num_points)]\n",
    "# model = RandomForestRegressor(n_estimators=80)\n",
    "# summary_tmp=[]\n",
    "for i in Abund_filter:\n",
    "    df_out= df[df['Abundance']>=i].copy()\n",
    "# df = RFECV_plot(df,label_abund,model,id,folds=splits,step=2,scoring=scoring)\n",
    "\n",
    "    df_out.to_excel(\"Input_data/Save_files/Abund_Filters/df_1_all\"+str(i)+\".xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       Entry  Sample_num  Abundance  Abundance_Controls  Unnamed: 5  \\\n0     Q3SWW8          46   0.000000            0.004931           0   \n1     P13213          31   0.000000            0.000000           0   \n2     Q2KJF1          46   0.119162            0.802977           0   \n3     P10103          39   0.000000            0.000000           0   \n4     P13135          49   0.004763            0.000000           0   \n...      ...         ...        ...                 ...         ...   \n7557  P01252          37   0.000000            0.000000           0   \n7558  P81644          32   0.133251            0.004621           0   \n7559  P02070          40   0.004355            0.000583           0   \n7560  Q3MHL7          32   0.002787            0.000000           0   \n7561  Q0VCX1          33   0.031326            0.000000           0   \n\n                                               Sequence  Length    Mass  \\\n0     MLAPRGATFLLLHLALQPWLGAGAQATPQVFDLLPSASQRLNPSVL...     961  105974   \n1     MRAWIFFLLCLAGRALAAPQQEALPDETEVVEETVAEVAEVPVGAN...     303   34613   \n2     MSAWAALLLLWGLSLSPVTEQATFFDPRPSLWAEAGSPLAPWADVT...     503   53554   \n3     MGKGDPKKPRGKMSSYAFFVQTCREEHKKKHPDASVNFSEFSKKCS...     215   24908   \n4     MFLVNSFLKGGGGGGGGGGLGGGLGNVLGGLISGAGGGGGGGGGGG...     263   27931   \n...                                                 ...     ...     ...   \n7557  MSDAAVDTSSEITTKDLKEKKEVVEEAENGREAPANGNANEENGEQ...     110   12072   \n7558  MKLLALTVLLLTICGLEGALVRRQAEESNLQSLVSQYFQTVADYGK...     100   11202   \n7559  MLTAEEKAAVTAFWGKVKVDEVGGEALGRLLVVYPWTQRFFESFGD...     145   15954   \n7560  MAAVKTLNPKAEVARAQAALAVNISAARGLQDVLRTNLGPKGTMKM...     531   57956   \n7561  MWCIVLFSLVAWVYAEPTMYGEILSPNYPQVYPNEVEKSWDIEVPA...     689   76609   \n\n      frac_aa_A  frac_aa_C  ...  Dh_core  Dh_functionalized  Shaken  \\\n0      0.050989   0.048907  ...      229                291       1   \n1      0.062706   0.049505  ...      221                221       1   \n2      0.109344   0.019881  ...      229                291       1   \n3      0.088372   0.013953  ...      149                271       1   \n4      0.064639   0.007605  ...      221                266       1   \n...         ...        ...  ...      ...                ...     ...   \n7557   0.109091   0.000000  ...      229                316       1   \n7558   0.090000   0.010000  ...      221                221       1   \n7559   0.110345   0.006897  ...      229                218       1   \n7560   0.101695   0.015066  ...      221                221       1   \n7561   0.046444   0.040639  ...      149                149       1   \n\n      Centrifuged  ProteinID  Protein Source  \\\n0               0          1             FBS   \n1               1          1             FBS   \n2               0          1             FBS   \n3               0          1             FBS   \n4               1          1             FBS   \n...           ...        ...             ...   \n7557            0          1             FBS   \n7558            1          1             FBS   \n7559            0          1             FBS   \n7560            1          1             FBS   \n7561            0          1             FBS   \n\n      NP_incubation Concentration (mg/mL)  Incubation Concentration (mg/ml)  \\\n0                                     5.0                                40   \n1                                     4.0                                 4   \n2                                     5.0                                40   \n3                                     5.0                                40   \n4                                     2.4                                40   \n...                                   ...                               ...   \n7557                                  5.0                                40   \n7558                                  4.0                                40   \n7559                                  5.0                                40   \n7560                                  4.0                                40   \n7561                                  5.0                                 4   \n\n      Incubation Time (minutes)  Temperature  \n0                            30           25  \n1                            30           25  \n2                            30           25  \n3                            30           25  \n4                            30           25  \n...                         ...          ...  \n7557                         30           25  \n7558                         30           25  \n7559                         30           25  \n7560                         30           25  \n7561                         30           25  \n\n[7562 rows x 124 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Sample_num</th>\n      <th>Abundance</th>\n      <th>Abundance_Controls</th>\n      <th>Unnamed: 5</th>\n      <th>Sequence</th>\n      <th>Length</th>\n      <th>Mass</th>\n      <th>frac_aa_A</th>\n      <th>frac_aa_C</th>\n      <th>...</th>\n      <th>Dh_core</th>\n      <th>Dh_functionalized</th>\n      <th>Shaken</th>\n      <th>Centrifuged</th>\n      <th>ProteinID</th>\n      <th>Protein Source</th>\n      <th>NP_incubation Concentration (mg/mL)</th>\n      <th>Incubation Concentration (mg/ml)</th>\n      <th>Incubation Time (minutes)</th>\n      <th>Temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q3SWW8</td>\n      <td>46</td>\n      <td>0.000000</td>\n      <td>0.004931</td>\n      <td>0</td>\n      <td>MLAPRGATFLLLHLALQPWLGAGAQATPQVFDLLPSASQRLNPSVL...</td>\n      <td>961</td>\n      <td>105974</td>\n      <td>0.050989</td>\n      <td>0.048907</td>\n      <td>...</td>\n      <td>229</td>\n      <td>291</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P13213</td>\n      <td>31</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>MRAWIFFLLCLAGRALAAPQQEALPDETEVVEETVAEVAEVPVGAN...</td>\n      <td>303</td>\n      <td>34613</td>\n      <td>0.062706</td>\n      <td>0.049505</td>\n      <td>...</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q2KJF1</td>\n      <td>46</td>\n      <td>0.119162</td>\n      <td>0.802977</td>\n      <td>0</td>\n      <td>MSAWAALLLLWGLSLSPVTEQATFFDPRPSLWAEAGSPLAPWADVT...</td>\n      <td>503</td>\n      <td>53554</td>\n      <td>0.109344</td>\n      <td>0.019881</td>\n      <td>...</td>\n      <td>229</td>\n      <td>291</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P10103</td>\n      <td>39</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>MGKGDPKKPRGKMSSYAFFVQTCREEHKKKHPDASVNFSEFSKKCS...</td>\n      <td>215</td>\n      <td>24908</td>\n      <td>0.088372</td>\n      <td>0.013953</td>\n      <td>...</td>\n      <td>149</td>\n      <td>271</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P13135</td>\n      <td>49</td>\n      <td>0.004763</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>MFLVNSFLKGGGGGGGGGGLGGGLGNVLGGLISGAGGGGGGGGGGG...</td>\n      <td>263</td>\n      <td>27931</td>\n      <td>0.064639</td>\n      <td>0.007605</td>\n      <td>...</td>\n      <td>221</td>\n      <td>266</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>2.4</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7557</th>\n      <td>P01252</td>\n      <td>37</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>MSDAAVDTSSEITTKDLKEKKEVVEEAENGREAPANGNANEENGEQ...</td>\n      <td>110</td>\n      <td>12072</td>\n      <td>0.109091</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>229</td>\n      <td>316</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7558</th>\n      <td>P81644</td>\n      <td>32</td>\n      <td>0.133251</td>\n      <td>0.004621</td>\n      <td>0</td>\n      <td>MKLLALTVLLLTICGLEGALVRRQAEESNLQSLVSQYFQTVADYGK...</td>\n      <td>100</td>\n      <td>11202</td>\n      <td>0.090000</td>\n      <td>0.010000</td>\n      <td>...</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7559</th>\n      <td>P02070</td>\n      <td>40</td>\n      <td>0.004355</td>\n      <td>0.000583</td>\n      <td>0</td>\n      <td>MLTAEEKAAVTAFWGKVKVDEVGGEALGRLLVVYPWTQRFFESFGD...</td>\n      <td>145</td>\n      <td>15954</td>\n      <td>0.110345</td>\n      <td>0.006897</td>\n      <td>...</td>\n      <td>229</td>\n      <td>218</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7560</th>\n      <td>Q3MHL7</td>\n      <td>32</td>\n      <td>0.002787</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>MAAVKTLNPKAEVARAQAALAVNISAARGLQDVLRTNLGPKGTMKM...</td>\n      <td>531</td>\n      <td>57956</td>\n      <td>0.101695</td>\n      <td>0.015066</td>\n      <td>...</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7561</th>\n      <td>Q0VCX1</td>\n      <td>33</td>\n      <td>0.031326</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>MWCIVLFSLVAWVYAEPTMYGEILSPNYPQVYPNEVEKSWDIEVPA...</td>\n      <td>689</td>\n      <td>76609</td>\n      <td>0.046444</td>\n      <td>0.040639</td>\n      <td>...</td>\n      <td>149</td>\n      <td>149</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>FBS</td>\n      <td>5.0</td>\n      <td>4</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n<p>7562 rows × 124 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filepath='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:54:10.041106Z",
     "end_time": "2023-04-27T11:54:24.694063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([32, 17, 25, 35, 34, 21, 18, 29, 26, 28, 20, 24, 33, 23, 27, 31, 19,\n       30, 22], dtype=int64)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NPUNID'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T11:54:55.291732Z",
     "end_time": "2023-04-27T11:54:55.311861Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Run RFECV through each different condition (zeros and abund filters)##\n",
    "\n",
    "in_dir='Input_data/Save_files/ZerosReduced/'\n",
    "files=os.listdir(in_dir)\n",
    "files\n",
    "for file in files:\n",
    "    filepath=in_dir+file\n",
    "    id=file[:-10]\n",
    "    # print(id)\n",
    "    # print(filepath)\n",
    "    df= pd.read_excel(filepath,header=0)\n",
    "    labels_df= df['Abundance'].copy()\n",
    "    id_col= df['NPUNID'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    model=RandomForestRegressor(n_estimators=100)\n",
    "    splits=5\n",
    "    df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID','Abundance_Controls'])\n",
    "    df = RFECV_plot(df,label_abund,model,id,folds=splits,step=2)\n",
    "    df_out=pd.concat([df, id_col,labels_df], axis=1)\n",
    "    df_out.to_excel(in_dir+id+'RFECV.xlsx',index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T11:30:33.376431Z",
     "end_time": "2023-04-24T11:30:33.385406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fraction_total_exposed_A  fraction_total_exposed_C  \\\n",
      "0                      0.029018                  0.000000   \n",
      "1                      0.017972                  0.001284   \n",
      "2                      0.072165                  0.010309   \n",
      "3                      0.019608                  0.000000   \n",
      "4                      0.030000                  0.010000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.032479                  0.007692   \n",
      "25752                  0.033333                  0.000000   \n",
      "25753                  0.029138                  0.003497   \n",
      "25754                  0.035124                  0.004132   \n",
      "25755                  0.020067                  0.000000   \n",
      "\n",
      "       fraction_total_exposed_D  fraction_total_exposed_E  \\\n",
      "0                      0.037946                  0.089286   \n",
      "1                      0.046213                  0.055199   \n",
      "2                      0.037801                  0.054983   \n",
      "3                      0.058824                  0.078431   \n",
      "4                      0.050000                  0.035000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.056410                  0.050427   \n",
      "25752                  0.033333                  0.083333   \n",
      "25753                  0.048951                  0.066434   \n",
      "25754                  0.033058                  0.049587   \n",
      "25755                  0.063545                  0.073579   \n",
      "\n",
      "       fraction_total_exposed_F  fraction_total_exposed_G  \\\n",
      "0                      0.008929                  0.020089   \n",
      "1                      0.007702                  0.052632   \n",
      "2                      0.017182                  0.079038   \n",
      "3                      0.011765                  0.031373   \n",
      "4                      0.005000                  0.035000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.013675                  0.049573   \n",
      "25752                  0.008333                  0.037500   \n",
      "25753                  0.010490                  0.041958   \n",
      "25754                  0.006198                  0.041322   \n",
      "25755                  0.023411                  0.023411   \n",
      "\n",
      "       fraction_total_exposed_H  fraction_total_exposed_I  \\\n",
      "0                      0.013393                  0.004464   \n",
      "1                      0.017972                  0.012837   \n",
      "2                      0.027491                  0.010309   \n",
      "3                      0.007843                  0.019608   \n",
      "4                      0.005000                  0.015000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.027350                  0.016239   \n",
      "25752                  0.008333                  0.004167   \n",
      "25753                  0.011655                  0.008159   \n",
      "25754                  0.010331                  0.008264   \n",
      "25755                  0.010033                  0.033445   \n",
      "\n",
      "       fraction_total_exposed_K  fraction_total_exposed_L  \\\n",
      "0                      0.058036                  0.031250   \n",
      "1                      0.052632                  0.008986   \n",
      "2                      0.065292                  0.048110   \n",
      "3                      0.070588                  0.023529   \n",
      "4                      0.035000                  0.050000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.029915                  0.026496   \n",
      "25752                  0.083333                  0.029167   \n",
      "25753                  0.071096                  0.018648   \n",
      "25754                  0.045455                  0.018595   \n",
      "25755                  0.086957                  0.056856   \n",
      "\n",
      "       fraction_total_exposed_M  fraction_total_exposed_N  \\\n",
      "0                      0.011161                  0.040179   \n",
      "1                      0.008986                  0.019255   \n",
      "2                      0.020619                  0.020619   \n",
      "3                      0.015686                  0.035294   \n",
      "4                      0.015000                  0.055000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.006838                  0.034188   \n",
      "25752                  0.008333                  0.025000   \n",
      "25753                  0.005828                  0.022145   \n",
      "25754                  0.012397                  0.024793   \n",
      "25755                  0.010033                  0.033445   \n",
      "\n",
      "       fraction_total_exposed_P  fraction_total_exposed_Q  \\\n",
      "0                      0.026786                  0.026786   \n",
      "1                      0.023107                  0.025674   \n",
      "2                      0.096220                  0.030928   \n",
      "3                      0.015686                  0.011765   \n",
      "4                      0.040000                  0.085000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.044444                  0.028205   \n",
      "25752                  0.054167                  0.020833   \n",
      "25753                  0.038462                  0.026807   \n",
      "25754                  0.033058                  0.018595   \n",
      "25755                  0.053512                  0.023411   \n",
      "\n",
      "       fraction_total_exposed_R  fraction_total_exposed_S  \\\n",
      "0                      0.037946                  0.049107   \n",
      "1                      0.051348                  0.024390   \n",
      "2                      0.079038                  0.068729   \n",
      "3                      0.047059                  0.047059   \n",
      "4                      0.050000                  0.065000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.041880                  0.048718   \n",
      "25752                  0.033333                  0.058333   \n",
      "25753                  0.036131                  0.030303   \n",
      "25754                  0.043388                  0.020661   \n",
      "25755                  0.030100                  0.053512   \n",
      "\n",
      "       fraction_total_exposed_T  fraction_total_exposed_V  \\\n",
      "0                      0.037946                  0.022321   \n",
      "1                      0.030809                  0.006418   \n",
      "2                      0.030928                  0.030928   \n",
      "3                      0.019608                  0.023529   \n",
      "4                      0.055000                  0.025000   \n",
      "...                         ...                       ...   \n",
      "25751                  0.045299                  0.030769   \n",
      "25752                  0.004167                  0.004167   \n",
      "25753                  0.019814                  0.017483   \n",
      "25754                  0.016529                  0.018595   \n",
      "25755                  0.043478                  0.010033   \n",
      "\n",
      "       fraction_total_exposed_W  fraction_total_exposed_Y  \n",
      "0                      0.006696                  0.020089  \n",
      "1                      0.001284                  0.008986  \n",
      "2                      0.003436                  0.024055  \n",
      "3                      0.003922                  0.031373  \n",
      "4                      0.000000                  0.010000  \n",
      "...                         ...                       ...  \n",
      "25751                  0.008547                  0.009402  \n",
      "25752                  0.004167                  0.008333  \n",
      "25753                  0.001166                  0.004662  \n",
      "25754                  0.002066                  0.008264  \n",
      "25755                  0.000000                  0.026756  \n",
      "\n",
      "[25756 rows x 20 columns]\n",
      "finished /df_1_all.xlsx\n"
     ]
    }
   ],
   "source": [
    "##Sample code for editing and making new dataframes###\n",
    "in_dir='Input_data/Save_files/'\n",
    "# files=os.listdir(in_dir)\n",
    "file='/df_1_all.xlsx'\n",
    "# for file in files:\n",
    "filepath=in_dir+file\n",
    "df= pd.read_excel(filepath, header=0)\n",
    "df=df.loc[df['Abundance']!=0]\n",
    "to_drop = df.filter(like='total_exposed_')\n",
    "# print(to_drop)\n",
    "df= df.drop(columns=to_drop).copy()\n",
    "df.to_excel(filepath,index=False)\n",
    "print('finished', file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T17:47:45.626500Z",
     "end_time": "2023-04-25T17:49:07.176119Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Run RFE and Scorer on each file in a given directory -- Outputs feat importance and score summaries for RFR##\n",
    "in_dir='Input_data/Save_files/Abund_Filters/'\n",
    "files=os.listdir(in_dir)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "for file in files:\n",
    "    filepath=in_dir+file\n",
    "    df = pd.read_excel(filepath, header=0)\n",
    "    identifier=file[:-5]\n",
    "    labels_df= df['Abundance'].copy()\n",
    "    id_col= df['NPUNID'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    label_abund=np.log2(label_abund)\n",
    "    # df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID','Abundance_Controls'])\n",
    "    # df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID'])\n",
    "    df=df.drop(columns='Abundance_Controls')\n",
    "    df=df.drop(columns=['Abundance','NPUNID','BatchID','Unnamed: 0'])\n",
    "    step = 3\n",
    "    selector = RFE(model, n_features_to_select=15, step=step)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df = df[feat_list].copy()\n",
    "    model.fit(df,labels_df)\n",
    "    tmp2,tmp3=scorer(df, label_abund, model, identifier, 10)\n",
    "    summary_tmp.append(tmp2)\n",
    "    feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_AbundFilters_log2.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_AbundFilters_log2.xlsx', index=False)\n",
    "print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T21:07:40.194273Z",
     "end_time": "2023-04-25T21:40:28.872999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_Zeros_removed_CA.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_Zeros_removed_CA.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T13:10:39.179711Z",
     "end_time": "2023-04-25T13:10:39.319855Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2=RFECV_plot_yb(df,label_abund,5,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m df_filepath\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput_data/Save_files/df_1_all.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mid\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m04232023\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_excel(df_filepath, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      4\u001B[0m labels_df\u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundance\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m      5\u001B[0m id_col\u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNPUNID\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcopy()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "id='04232023'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "labels_df= df['Abundance'].copy()\n",
    "id_col= df['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels_df)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "print('here')\n",
    "df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID','Abundance_Controls'])\n",
    "\n",
    "selector = RFE(model, n_features_to_select=50, step=3)\n",
    "print('start')\n",
    "selector = selector.fit(df, label_abund)\n",
    "print('fit complete')\n",
    "selector.support_\n",
    "ranking = selector.ranking_\n",
    "feat_list = selector.get_feature_names_out()\n",
    "df = df[feat_list]\n",
    "df_out=pd.concat([df, id_col,labels_df],axis=1)\n",
    "df_out.to_excel(\"Input_data/Save_files/df_1_all_RFE50_RFR.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Ran successfully\n"
     ]
    }
   ],
   "source": [
    "# Standard Pipeline###\n",
    "\n",
    "\n",
    "# Data to record#\n",
    "#MSE,Pearson,R2,number of features => Scorer\n",
    "#Feature importance/Features used=> Scorer, but send out separate df for those\n",
    "\n",
    "#Editable Variables\n",
    "#list of test filters\n",
    "rfecv_ = True  #True_runs RFECV\n",
    "rfe_ = False     #True runs Recursive feature elimination\n",
    "abund_controls = False # True keeps the serum as an input feature\n",
    "splits = 10     #number of splits for cross validation across QC methods and feature selection methods\n",
    "# scorings=['r2','neg_mean_squared_error','mean_absolute_error']\n",
    "# RFE_Feats = 40\n",
    "model = RandomForestRegressor(n_estimators=80)\n",
    "\n",
    "df_filepath='Input_data/Save_files/df_1_all_RFE50_RFR.xlsx'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "labels_df= df['Abundance'].copy()\n",
    "id_col= df['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels_df)\n",
    "NPIDs=np.ravel(id_col)\n",
    "id='RFR_RFECV_100%'\n",
    "# df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID'])\n",
    "df=df.drop(columns=['Abundance','NPUNID'],axis=1)\n",
    "# if abund_controls == False:\n",
    "#     df.drop(columns=['Abundance_Controls'], inplace=True)\n",
    "\n",
    "# model=XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, objective='reg:squarederror')\n",
    "summary_tmp=[]\n",
    "# for z in scorings:\n",
    "    #Run PCA to seee how data differentiates#\n",
    "PCA_plot(df,NPIDs,id)\n",
    "#use recursive feature elimination with Random Forest Regression as the estimator to select top 45 important features\n",
    "if rfe_ == True:\n",
    "    step = 2\n",
    "    estimator = RandomForestRegressor(n_estimators=100)\n",
    "    selector = RFE(estimator, n_features_to_select=RFE_Feats, step=step)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    ranking = selector.ranking_\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df = df[feat_list]\n",
    "    df_out=pd.concat([df, NPIDs,labels_df],axis=1)\n",
    "    df_out.to_excel(\"Input_data/Save_files/df_RFE40_\"+id+\".xlsx\")\n",
    "\n",
    "#run Recursive feature elimination with cross validation\n",
    "if rfecv_ == True:\n",
    "    df = RFECV_plot(df,label_abund,model,id,folds=splits,step=2)\n",
    "    df_out=pd.concat([df, NPIDs,labels_df],axis=1)\n",
    "    df_out.to_excel(\"Input_data/Save_files/df_RFECV(50)_\"+id+\".xlsx\")\n",
    "#Quality control\n",
    "scram_score(df, label_abund, model, id, 0.2)\n",
    "# feat_drop(df, label_abund, model, id, 0.2)\n",
    "feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\n",
    "tmp2=scorer(df, label_abund, model, id, 10)\n",
    "zeros=(raw_MS_data['Abundance']==0).sum()\n",
    "percent_zeros=zeros/raw_MS_data.shape[0]\n",
    "tmp2['TotalZeros']=zeros\n",
    "tmp2['Percent_zeros']=percent_zeros\n",
    "summary_tmp.append(tmp2)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "summary.to_excel('Output_data/'+id+'.xlsx', index=False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "1.586079417413907e-05"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filepath='Input_data/Save_files/df_1_no0.xlsx'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "Min_Control=df['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "Min_Control"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T14:55:12.066868Z",
     "end_time": "2023-04-26T14:55:17.920561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-26T14:41:00.568599Z",
     "end_time": "2023-04-26T14:46:32.897627Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n",
      "C:\\Users\\kmp95\\AppData\\Local\\Temp\\ipykernel_24100\\2291417116.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  eval_df = eval_df.append({'Abund Thresh': i,\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Output_data/AbundThresholdingRFC2.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Input \u001B[1;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 52>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;66;03m# Append a new row to the eval_df DataFrame with the evaluation metrics for this iteration\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     eval_df \u001B[38;5;241m=\u001B[39m eval_df\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbund Thresh\u001B[39m\u001B[38;5;124m'\u001B[39m: i,\n\u001B[0;32m     46\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mF1\u001B[39m\u001B[38;5;124m'\u001B[39m: f1,\n\u001B[0;32m     47\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAUROC\u001B[39m\u001B[38;5;124m'\u001B[39m: auroc,\n\u001B[0;32m     48\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m: accuracy,\n\u001B[0;32m     49\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrecision\u001B[39m\u001B[38;5;124m'\u001B[39m: precision,\n\u001B[0;32m     50\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecall\u001B[39m\u001B[38;5;124m'\u001B[39m: recall}, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 52\u001B[0m \u001B[43meval_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOutput_data/AbundThresholdingRFC2.xlsx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001B[0m, in \u001B[0;36mNDFrame.to_excel\u001B[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001B[0m\n\u001B[0;32m   2332\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mformats\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexcel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExcelFormatter\n\u001B[0;32m   2334\u001B[0m formatter \u001B[38;5;241m=\u001B[39m ExcelFormatter(\n\u001B[0;32m   2335\u001B[0m     df,\n\u001B[0;32m   2336\u001B[0m     na_rep\u001B[38;5;241m=\u001B[39mna_rep,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2343\u001B[0m     inf_rep\u001B[38;5;241m=\u001B[39minf_rep,\n\u001B[0;32m   2344\u001B[0m )\n\u001B[1;32m-> 2345\u001B[0m \u001B[43mformatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexcel_writer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2347\u001B[0m \u001B[43m    \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstartrow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstartrow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstartcol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstartcol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfreeze_panes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfreeze_panes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2353\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:888\u001B[0m, in \u001B[0;36mExcelFormatter.write\u001B[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001B[0m\n\u001B[0;32m    884\u001B[0m     need_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    885\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    886\u001B[0m     \u001B[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001B[39;00m\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001B[39;00m\n\u001B[1;32m--> 888\u001B[0m     writer \u001B[38;5;241m=\u001B[39m \u001B[43mExcelWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[abstract]\u001B[39;49;00m\n\u001B[0;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    891\u001B[0m     need_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:191\u001B[0m, in \u001B[0;36mXlsxWriter.__init__\u001B[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAppend mode is not supported with xlsxwriter!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 191\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatetime_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatetime_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_sheet_exists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_sheet_exists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbook \u001B[38;5;241m=\u001B[39m Workbook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mengine_kwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1106\u001B[0m, in \u001B[0;36mExcelWriter.__init__\u001B[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m IOHandles(\n\u001B[0;32m   1103\u001B[0m     cast(IO[\u001B[38;5;28mbytes\u001B[39m], path), compression\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m}\n\u001B[0;32m   1104\u001B[0m )\n\u001B[0;32m   1105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, ExcelWriter):\n\u001B[1;32m-> 1106\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1109\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msheets: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcur_sheet \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    790\u001B[0m             handle,\n\u001B[0;32m    791\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    794\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    795\u001B[0m         )\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'Output_data/AbundThresholdingRFC2.xlsx'"
     ]
    }
   ],
   "source": [
    "### Running Binary Classification systems and seeing what abund threshold is the best for performance##\n",
    "\n",
    "abund_thresh=[-2,-1,-0.5,0.25,0.5,0.75,1,2,3,4]\n",
    "df_filepath='Input_data/Save_files/df_1_no0.xlsx'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "Min_Control=df['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df['Abundance_Controls'].replace(0,Min_Control,inplace=True)\n",
    "df['Enrich']= np.log2(df['Abundance']/df['Abundance_Controls'])\n",
    "# df = df.replace(np.inf,10)\n",
    "model=RandomForestClassifier()\n",
    "# id='RFR_AFilter_'+str(i)+'NoCon'\n",
    "# Create an empty pandas DataFrame to store the evaluation metrics\n",
    "eval_df = pd.DataFrame(columns=['Abund Thresh', 'F1', 'AUROC', 'Accuracy', 'Precision', 'Recall'])\n",
    "df=df.drop(columns=['Entry', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num','Raw_FileID','BatchID'])\n",
    "df=df.drop(columns=['Abundance_Controls','Abundance'])\n",
    "\n",
    "# Iterate through multiple iterations of model training and testing\n",
    "for i in abund_thresh:\n",
    "    df_a=df.copy()\n",
    "    df_a['binary_target']= df_a['Enrich'].apply(lambda t: 1 if t>=i else 0)\n",
    "    labels_df = df_a['binary_target'].copy()\n",
    "    # id_col= df_a['NPUNID'].copy()\n",
    "    label_binary=np.ravel(labels_df)\n",
    "    df_a=df_a.drop(columns=['NPUNID','binary_target','Enrich']).copy()\n",
    "\n",
    "    step = 2\n",
    "    RFE_Feats=20\n",
    "    selector = RFE(model, n_features_to_select=RFE_Feats, step=step)\n",
    "    selector = selector.fit(df_a, label_binary)\n",
    "    selector.support_\n",
    "    ranking = selector.ranking_\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df_a = df_a[feat_list].copy()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_a, label_binary, test_size=0.3, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auroc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "\n",
    "    # Append a new row to the eval_df DataFrame with the evaluation metrics for this iteration\n",
    "    eval_df = eval_df.append({'Abund Thresh': i,\n",
    "                              'F1': f1,\n",
    "                              'AUROC': auroc,\n",
    "                              'Accuracy': accuracy,\n",
    "                              'Precision': precision,\n",
    "                              'Recall': recall}, ignore_index=True)\n",
    "\n",
    "eval_df.to_excel('Output_data/AbundThresholdingRFC2.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.04243641, 0.04714033, 0.04240516, 0.04129702, 0.05267255,\n       0.05224468, 0.05554752, 0.0344671 , 0.05503526, 0.05674049,\n       0.04156461, 0.04837206, 0.03950628, 0.06814819, 0.0418631 ,\n       0.04528183, 0.05187392, 0.06923995, 0.06937306, 0.04479048])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T15:12:22.748818Z",
     "end_time": "2023-04-26T15:12:22.775551Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFJCAYAAABKLF7JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVeUlEQVR4nO3df0xd9f3H8de5vyiXuoymVQpewxoGFjqUkHRo9ldlLk00MV1M7oxp5tDNmizNfqSSRUbZbAqJ2Wwqc2WLrjrTP4zTLTH9B6fRP5ZsREYdwXX2TpaWqTBYqbuXe7nc+/2j6f1qQe7tvQfu+16ej78uB8/p53y83Cf33MM5TjqdTgsAABSVp9gDAAAABBkAABMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBggK/YA5iampIk1dbWZh4jd8xbfpi3/DBv+WHe8lduc1dbW/uZ3+MdMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwoOg3lwCAlXjnZqTZ6fw3sGWblqq3ujcgYI0RZAA2zU4r0f9o3qsHugckgowSwiFrAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwADu9gSgLDk+n7znJvLfALdvxDojyADK06V5JY715b06t2/EeuOQNQAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAA7JeGCSZTGpwcFDT09PyeDz6zne+I6/Xq8HBQTmOo1AopK6uLnk8Hg0PD2t4eFher1f79u1Te3v7euwDAAAlL2uQR0dHtbS0pMcff1xnzpzRqVOntLS0pHA4rJaWFg0NDWlkZESNjY06ffq0+vv7tbi4qJ6eHrW2tsrv96/HfgAAUNKyHrLevn27UqmUUqmUotGofD6fIpGImpubJUltbW06c+aM3nvvPTU1Ncnv9ysYDKqmpkaTk5NrvgMAAJSDrO+QN23apOnpaX3ve9/T/Py8uru7NTExIcdxJEmVlZWKRqOKRqMKBoOZ9a4sz6a2tnbFx8gd85Yf5i0/6zVvc+cjShSwvuMp7BSZQEWFql3cV55v+dsoc5c1yK+++qpuueUW3XfffZqZmdFPfvITJZPJzPdjsZiqqqoUDAa1sLCwbHk2U1NTki5P+JXHyB3zlh/mLT/rOW/eeLyg9dOpVEHrJ+Jx1/aV51v+ym3uVvvlIuuvkFdiK0mbN2/W0tKS6uvrNT4+LunyZ8w7d+5UQ0ODJiYmlEgkFI1GdeHCBYVCIZd2AQCA8pb1HfJdd92lX/ziF/rxj3+sZDKpb3zjG9qxY4dOnDihZDKpuro6dXR0yOPxaO/evert7VUqlVI4HFYgEFiPfQAAoOTl9Bny97///WXL+/qW32e0s7NTnZ2d7owMAIANhAuDAABgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYkPV+yACwETk+n7znJgrbyJZtWqre6s6AUPYIMgCs5NK8Esf6CtpEoHtAIsjIEYesAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMMBX7AEAKE/euRlpdjrv9Z3kooujAewjyADWxuy0Ev2P5r16xcFeFwcD2MchawAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgADeXAIA14vh88p6b0Nz5iLzx+LVvYMs2LVVvdX9gMIkgA8BauTSvxLE+JfJcPdA9IBHkDYND1gAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADcvqzp5dfflkjIyNKJpP62te+pubmZg0ODspxHIVCIXV1dcnj8Wh4eFjDw8Pyer3at2+f2tvb13r8AACUhaxBHh8f19///nf99Kc/VSKR0B/+8AedPHlS4XBYLS0tGhoa0sjIiBobG3X69Gn19/drcXFRPT09am1tld/vX4/9AACgpGUN8tjYmG666SY98cQTisViuv/++/Xaa6+publZktTW1qaxsTF5PB41NTXJ7/fL7/erpqZGk5OTamhoWPOdAACg1GUN8vz8vGZmZtTd3a2PPvpIAwMDSqfTchxHklRZWaloNKpoNKpgMJhZ78rybGpra1d8jNwxb/lh3vKT67zNnY/kfYUqSXI8hZ3iUuz13dhGoKJC1TxPN8zPatYgX3fddaqrq5PP51Ntba0CgYD+85//ZL4fi8VUVVWlYDCohYWFZcuzmZqaknR5wq88Ru6Yt/wwb/m5lnnL69rNn5BOpUp6fTe2kYjHN/zztNx+Vlf75SLrr28333yz/vrXvyqdTmt2dlYLCwvatWuXxsfHJUmjo6PauXOnGhoaNDExoUQioWg0qgsXLigUCrm3FwAAlLGs75Db29s1MTGhH/3oR0qlUurq6tL111+vEydOKJlMqq6uTh0dHfJ4PNq7d696e3uVSqUUDocVCATWYx8AACh5Of3Z0/33379sWV9f37JlnZ2d6uzsLHxUAABsMFwYBAAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAY4Cv2AAAAK3N8PnnPTeS/gS3btFS91b0BYU0RZACw6tK8Esf68l490D0gEeSSwSFrAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAdx+EVgD3rkZaXY6/w1wH1tgwyHIwFqYnVai/9G8V+c+tsDGQ5ABLPNZ7/Dnzkfkjcdz2oaTXHR7WEBZI8gwh8O9BnzGO/zENWyi4mCve+MBNoCcgnzx4kV1d3frsccek9fr1eDgoBzHUSgUUldXlzwej4aHhzU8PCyv16t9+/apvb19rceOcsXhXgAbUNYgJ5NJDQ0NKRAISJJOnjypcDislpYWDQ0NaWRkRI2NjTp9+rT6+/u1uLionp4etba2yu/3r/kOAOXI8fnkPTeR/wY4SgCUnKxBfv755/XVr35Vr7zyiiQpEomoublZktTW1qaxsTF5PB41NTXJ7/fL7/erpqZGk5OTamhoWNPBAyvJJWarfhZqIWaX5pU41pf36hwlAErPqkF+44039LnPfU633nprJsiS5DiOJKmyslLRaFTRaFTBYDDz/SvLc1FbW7viY+Su3OZt7nzkmj6rvJrzv48V//nqn1+utv3NvU+quqW1gBG4sA+ewi4REKioUHUBz4tCxy8Vvg+lvr6FMRT6PLCi3F7jPsuqQX799dclSe+8847ef/99PfXUU7p48WLm+7FYTFVVVQoGg1pYWFi2PBdTU1OSLk/4lcfIXTnOW65n8X6WdCpV0PqLS0v68K3XCtpGoWcYF7oPiXi8oOdFof8PpML3odTXtzCGQp8HFpTba9xqv1ysGuS+vv8/ZHb48GE99NBDev755zU+Pq6WlhaNjo5q165damho0KlTp5RIJJRMJnXhwgWFQiH39gBYTwUeLpY4wxjAtbvmP3vav3+/Tpw4oWQyqbq6OnV0dMjj8Wjv3r3q7e1VKpVSOBzOnAQGAACyyznIhw8fzjz+5DvnKzo7O9XZ2enKoAAA2Gi4uQQAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAG6/CJShQm9Owb2MgfVHkIFyVODVxrjSGLD+OGQNAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgNsvAkCZKvS+2NqyTUvVW90bEFZFkAGgXBV4X+xA94BEkNcNh6wBADCAIAMAYACHrOE679yMNDud9/pOctHF0QBAaSDIcN/stBL9j+a9esXBXhcHAwClgUPWAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAN9q30wmk3r66ac1PT2txcVFff3rX9eNN96owcFBOY6jUCikrq4ueTweDQ8Pa3h4WF6vV/v27VN7e/t67QMAACVv1SC/9dZbuu666/Td735Xly5d0qFDh1RfX69wOKyWlhYNDQ1pZGREjY2NOn36tPr7+7W4uKienh61trbK7/ev134AAFDSVg3ybbfdpo6OjszXXq9XkUhEzc3NkqS2tjaNjY3J4/GoqalJfr9ffr9fNTU1mpycVENDw9qOHgCAMrHqZ8ibNm1SZWWlYrGYfvaznykcDkuSHMeRJFVWVioajSoajSoYDGbWu7IcAADkZtV3yJI0MzOjJ554Qnfeeae+8pWv6Le//W3me7FYTFVVVQoGg1pYWFi2PBe1tbUrPkburM3b3PmIEgWs73gKO9ew2OtbGEOx17cwhmKvb2EMha4fqKhQtYHXF2uvcWtl1SD/97//1ZEjR/Stb31LX/rSlyRJ9fX1Gh8fV0tLi0ZHR7Vr1y41NDTo1KlTSiQSSiaTunDhgkKhUE4DmJqaknR5wq88Ru4szps3Hi9o/XQqVdLrWxhDsde3MIZir29hDIWun4jHi/76YvE1rhCr/XKxapBffvllffzxx3rppZf00ksvSZK++c1v6tlnn1UymVRdXZ06Ojrk8Xi0d+9e9fb2KpVKKRwOKxAIuLsXAACUsVWD/MADD+iBBx5Ytryvr2/Zss7OTnV2dro3MgAANhAuDAIAgAEEGQAAAwgyAAAGEGQAAAzI+nfI2Hi8czPS7HTe6zvJRRdHAwAbA0HGcrPTSvQ/mvfqFQd7XRwMAGwMHLIGAMAAggwAgAEEGQAAA/gMGQCwIsfnk/fcRP4b2LJNS9Vb3RtQmSPIAICVXZpX4tjySyXnKtA9IBHknHHIGgAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAX7EHAHd552ak2emCtuEkF10aDQAgVwS53MxOK9H/aEGbqDjY69JgAAC54pA1AAAGEGQAAAzgkDUAYE04Pp+85yYK2saleFSqCLo0ItsIMgBgbVyaV+JYX0GbCPQ+Kd24w53xGMchawAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAP4O2RjrvXmEHPnI/LG45mvuTEEAJQmgmzNNd4cInHV19wYAgBKE4esAQAwgCADAGAAQQYAwACCDACAAZzU5bJrPUv6apwlDQAbE0F22zWeJX01zpIGgI2JQ9YAABhAkAEAMMDVQ9apVEq//vWvNTk5Kb/fr4cfflg1NTVu/hNrjs+AAcCOJUnecxP5b2DLNi1Vb3VtPGvJ1SD/5S9/0eLioo4cOaKzZ8/queee06FDh9z8J9YenwEDgBnp+YtK/Dz/19VA94C0EYP87rvv6tZbb5UkNTY26ty5c25uPqtC391KvMMFgHLi+Hwl8w7bSafTabc29stf/lJf/vKX1dbWJkk6cOCAnnrqKXm9Xrf+CQAAypKrJ3VVVlYqFotlvk6n08QYAIAcuBrkpqYmjY6OSpLOnj2rm266yc3NAwBQtlw9ZH3lLOt//etfSqfTeuSRR1RXV+fW5gEAKFuuBhkAAOSHC4MAAGAAQQYAwAATN5f485//rD/96U86ePCgpMsnhP3mN7+R1+tVa2ur7r333iKP0K50Oq2HH35Y27dvl3T577/vu+++Io/KrnK4mlyxHDp0SMFgUJJ0/fXX65FHHinyiGz7xz/+oRdeeEGHDx/WBx98oMHBQTmOo1AopK6uLnk8vB9aySfnLRKJaGBgIPP6duedd+r2228v8gjXTtGD/Oyzz2psbEz19fWZZb/61a/0gx/8QDfccIP6+/sViUS0Y8eO4g3SsA8//FBf+MIX1N3dXeyhlISyuJpcESQSCUnS4cOHizuQEvH73/9eb775pjZt2iRJOnnypMLhsFpaWjQ0NKSRkRHt3r27yKO05+p5++c//6m77rpLd999d5FHtj6K/itaU1OTHnzwwczX0WhUyWRSNTU1chxHt9xyi/72t78VcYS2RSIRzc3Nqa+vT0ePHtXU1FSxh2Rasa8mV6omJycVj8f1+OOPq6+vT2fPni32kEy74YYb9MMf/jDzdSQSUXNzsySpra1NZ86cKdbQTFtp3t5++2319vbq6aef/tR1LsrRur1D/uMf/6hXX331U8sOHDig22+/XePj45llsVhMlZWVma83bdqkjz76aL2GadpKc9jV1aV77rlHt912m959910dP35cR48eLdII7YvFYpnDrpLk8Xi0tLTEBWyyqKio0N1336077rhD//73v3X06FE9+eSTzNtn6OjoWPa65TiOpMsXUIpGo8UYlnlXz1tDQ4PuuOMO7dixQ7/73e/04osvav/+/UUc4dpatyDv2bNHe/bsyfrfXX21r4WFhU+9gG5kK81hPB7PvCjefPPNmp2dVTqdzvzw49O4mlx+tm/fnjlqVVtbq82bN2tubk5bt5bGRfuL7ZM/j7FYTFVVVUUcTenYvXt3Zq52796tZ555psgjWltFP2R9tWAwKJ/Ppw8++EDpdFpjY2PauXNnsYdl1osvvph51/z+++9r69atxHgVXE0uP6+//rqee+45SdLs7KxisZiqq6uLPKrSUV9fnzkSODo6ymtajo4cOaL33ntPkvTOO++U/blERT+payUPPfSQjh8/rlQqpdbWVn3xi18s9pDMuueee3T8+HG9/fbb8nq9nPmaxe7du3XmzBk99thjmavJIbs9e/ZocHBQPT09chxHBw4c4MjCNdi/f79OnDihZDKpuro6dXR0FHtIJeHBBx/UM888I5/Pp89//vP69re/XewhrSmu1AUAgAHmDlkDALAREWQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAAD/g96vs7NmEpQJAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['Enrich'],bins=25)\n",
    "# plt.xlim(-2,2)\n",
    "\n",
    "plt.savefig('Output_data/Enrich_Hist.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T15:01:44.423032Z",
     "end_time": "2023-04-26T15:01:44.563100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "      Length    Mass  frac_aa_A  frac_aa_C  frac_aa_D  frac_aa_E  frac_aa_F  \\\n0        291   31570   0.082474   0.061856   0.044674   0.054983   0.020619   \n1        255   28405   0.094118   0.015686   0.066667   0.090196   0.035294   \n2        145   15859   0.103448   0.013793   0.055172   0.068966   0.068966   \n3        225   24805   0.093333   0.013333   0.106667   0.093333   0.022222   \n4       1495  165853   0.065552   0.016054   0.037458   0.061538   0.046154   \n...      ...     ...        ...        ...        ...        ...        ...   \n8259     175   19988   0.085714   0.005714   0.068571   0.085714   0.045714   \n8260     444   50244   0.047297   0.024775   0.067568   0.056306   0.038288   \n8261     432   47638   0.092593   0.020833   0.057870   0.064815   0.025463   \n8262     240   27498   0.058333   0.016667   0.045833   0.091667   0.041667   \n8263     299   34209   0.036789   0.020067   0.070234   0.073579   0.050167   \n\n      frac_aa_G  frac_aa_H  frac_aa_I  ...  Dh_core  Dh_functionalized  \\\n0      0.099656   0.027491   0.013746  ...      105                105   \n1      0.074510   0.019608   0.050980  ...      149                229   \n2      0.075862   0.034483   0.006897  ...      105                105   \n3      0.066667   0.008889   0.040000  ...      149                229   \n4      0.058863   0.023411   0.054181  ...      680                680   \n...         ...        ...        ...  ...      ...                ...   \n8259   0.074286   0.034286   0.017143  ...      149                226   \n8260   0.083333   0.024775   0.063063  ...      230                230   \n8261   0.083333   0.027778   0.069444  ...      221                221   \n8262   0.050000   0.016667   0.029167  ...      441                441   \n8263   0.030100   0.013378   0.076923  ...      230                230   \n\n      Shaken  Centrifuged  ProteinID  NP_incubation Concentration (mg/mL)  \\\n0          0            0          1                                  3.2   \n1          1            0          1                                  5.0   \n2          0            0          1                                  3.2   \n3          1            0          1                                  5.0   \n4          1            1          2                                125.0   \n...      ...          ...        ...                                  ...   \n8259       1            0          1                                  5.0   \n8260       1            0          1                                  3.2   \n8261       1            1          1                                  4.0   \n8262       1            1          2                                200.0   \n8263       1            0          1                                  3.2   \n\n      Incubation Concentration (mg/ml)  Incubation Time (minutes)  \\\n0                                  4.0                       1440   \n1                                 40.0                         30   \n2                                 40.0                       1440   \n3                                 40.0                         30   \n4                                  0.2                         60   \n...                                ...                        ...   \n8259                               4.0                         30   \n8260                               4.0                         30   \n8261                               4.0                         30   \n8262                               0.2                         60   \n8263                              40.0                         30   \n\n      Temperature     Enrich  \n0              25  10.000000  \n1              25  10.000000  \n2              25  -0.580601  \n3              25  10.000000  \n4              25  -0.250075  \n...           ...        ...  \n8259           25  10.000000  \n8260           25   4.407132  \n8261           25  10.000000  \n8262           25   3.316236  \n8263           25  10.000000  \n\n[8264 rows x 94 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>Mass</th>\n      <th>frac_aa_A</th>\n      <th>frac_aa_C</th>\n      <th>frac_aa_D</th>\n      <th>frac_aa_E</th>\n      <th>frac_aa_F</th>\n      <th>frac_aa_G</th>\n      <th>frac_aa_H</th>\n      <th>frac_aa_I</th>\n      <th>...</th>\n      <th>Dh_core</th>\n      <th>Dh_functionalized</th>\n      <th>Shaken</th>\n      <th>Centrifuged</th>\n      <th>ProteinID</th>\n      <th>NP_incubation Concentration (mg/mL)</th>\n      <th>Incubation Concentration (mg/ml)</th>\n      <th>Incubation Time (minutes)</th>\n      <th>Temperature</th>\n      <th>Enrich</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>291</td>\n      <td>31570</td>\n      <td>0.082474</td>\n      <td>0.061856</td>\n      <td>0.044674</td>\n      <td>0.054983</td>\n      <td>0.020619</td>\n      <td>0.099656</td>\n      <td>0.027491</td>\n      <td>0.013746</td>\n      <td>...</td>\n      <td>105</td>\n      <td>105</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>1440</td>\n      <td>25</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>255</td>\n      <td>28405</td>\n      <td>0.094118</td>\n      <td>0.015686</td>\n      <td>0.066667</td>\n      <td>0.090196</td>\n      <td>0.035294</td>\n      <td>0.074510</td>\n      <td>0.019608</td>\n      <td>0.050980</td>\n      <td>...</td>\n      <td>149</td>\n      <td>229</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40.0</td>\n      <td>30</td>\n      <td>25</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>145</td>\n      <td>15859</td>\n      <td>0.103448</td>\n      <td>0.013793</td>\n      <td>0.055172</td>\n      <td>0.068966</td>\n      <td>0.068966</td>\n      <td>0.075862</td>\n      <td>0.034483</td>\n      <td>0.006897</td>\n      <td>...</td>\n      <td>105</td>\n      <td>105</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.2</td>\n      <td>40.0</td>\n      <td>1440</td>\n      <td>25</td>\n      <td>-0.580601</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>225</td>\n      <td>24805</td>\n      <td>0.093333</td>\n      <td>0.013333</td>\n      <td>0.106667</td>\n      <td>0.093333</td>\n      <td>0.022222</td>\n      <td>0.066667</td>\n      <td>0.008889</td>\n      <td>0.040000</td>\n      <td>...</td>\n      <td>149</td>\n      <td>229</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40.0</td>\n      <td>30</td>\n      <td>25</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1495</td>\n      <td>165853</td>\n      <td>0.065552</td>\n      <td>0.016054</td>\n      <td>0.037458</td>\n      <td>0.061538</td>\n      <td>0.046154</td>\n      <td>0.058863</td>\n      <td>0.023411</td>\n      <td>0.054181</td>\n      <td>...</td>\n      <td>680</td>\n      <td>680</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>125.0</td>\n      <td>0.2</td>\n      <td>60</td>\n      <td>25</td>\n      <td>-0.250075</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8259</th>\n      <td>175</td>\n      <td>19988</td>\n      <td>0.085714</td>\n      <td>0.005714</td>\n      <td>0.068571</td>\n      <td>0.085714</td>\n      <td>0.045714</td>\n      <td>0.074286</td>\n      <td>0.034286</td>\n      <td>0.017143</td>\n      <td>...</td>\n      <td>149</td>\n      <td>226</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>30</td>\n      <td>25</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>8260</th>\n      <td>444</td>\n      <td>50244</td>\n      <td>0.047297</td>\n      <td>0.024775</td>\n      <td>0.067568</td>\n      <td>0.056306</td>\n      <td>0.038288</td>\n      <td>0.083333</td>\n      <td>0.024775</td>\n      <td>0.063063</td>\n      <td>...</td>\n      <td>230</td>\n      <td>230</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>30</td>\n      <td>25</td>\n      <td>4.407132</td>\n    </tr>\n    <tr>\n      <th>8261</th>\n      <td>432</td>\n      <td>47638</td>\n      <td>0.092593</td>\n      <td>0.020833</td>\n      <td>0.057870</td>\n      <td>0.064815</td>\n      <td>0.025463</td>\n      <td>0.083333</td>\n      <td>0.027778</td>\n      <td>0.069444</td>\n      <td>...</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>30</td>\n      <td>25</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>8262</th>\n      <td>240</td>\n      <td>27498</td>\n      <td>0.058333</td>\n      <td>0.016667</td>\n      <td>0.045833</td>\n      <td>0.091667</td>\n      <td>0.041667</td>\n      <td>0.050000</td>\n      <td>0.016667</td>\n      <td>0.029167</td>\n      <td>...</td>\n      <td>441</td>\n      <td>441</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>200.0</td>\n      <td>0.2</td>\n      <td>60</td>\n      <td>25</td>\n      <td>3.316236</td>\n    </tr>\n    <tr>\n      <th>8263</th>\n      <td>299</td>\n      <td>34209</td>\n      <td>0.036789</td>\n      <td>0.020067</td>\n      <td>0.070234</td>\n      <td>0.073579</td>\n      <td>0.050167</td>\n      <td>0.030100</td>\n      <td>0.013378</td>\n      <td>0.076923</td>\n      <td>...</td>\n      <td>230</td>\n      <td>230</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.2</td>\n      <td>40.0</td>\n      <td>30</td>\n      <td>25</td>\n      <td>10.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8264 rows × 94 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T14:17:13.534167Z",
     "end_time": "2023-04-26T14:17:13.552118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Filtering Abundance to see if i stick to higher abundance I get better performance##\n",
    "rfecv_ = False  #True_runs RFECV\n",
    "rfe_ = True     #True runs Recursive feature elimination\n",
    "abund_controls = False # True keeps the serum as an input feature\n",
    "splits = 10     #number of splits for cross validation across QC methods and feature selection methods\n",
    "\n",
    "df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "id='04232023'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "labels_df= df['Abundance'].copy()\n",
    "id_col= df['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels_df)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "print('here')\n",
    "df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID','Abundance_Controls'])\n",
    "\n",
    "df_filepath = 'Input_data/Save_files/df_1_all.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "df_a=df_a.drop(columns=['Entry', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID'])\n",
    "# scorings=['r2','neg_mean_squared_error','neg_mean_absolute_error']\n",
    "RFE_Feats = 15\n",
    "import math\n",
    "\n",
    "start = 0.0001\n",
    "stop = 1\n",
    "num_points = 15\n",
    "\n",
    "# Calculate the common difference between consecutive terms in the series\n",
    "common_diff = (math.log(stop) - math.log(start)) / (num_points - 1)\n",
    "\n",
    "# Generate the logarithmic series as a list\n",
    "Abund_filter = [start * math.exp(i * common_diff) for i in range(num_points)]\n",
    "model = RandomForestRegressor(n_estimators=80)\n",
    "summary_tmp=[]\n",
    "for i in Abund_filter:\n",
    "    df= df_a[df_a['Abundance']>=i]\n",
    "    id='RFR_AFilter_'+str(i)+'NoCon'\n",
    "    labels_df= df['Abundance'].copy()\n",
    "    id_col= df['NPUNID'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    df.drop(columns=['Abundance','NPUNID'],inplace=True)\n",
    "    if abund_controls == False:\n",
    "        df.drop(columns=['Abundance_Controls'], inplace=True)\n",
    "    #run Recursive feature elimination with cross validation\n",
    "    if rfecv_ == True:\n",
    "        df = RFECV_plot(df,label_abund,model,id,folds=splits,step=2,scoring=z)\n",
    "        # df_out=pd.concat([df, NPIDs,label_abund_df],axis=1)\n",
    "        # df_out.to_excel(\"Input_data/Save_files/df_RFECV(40)_\"+id+\".xlsx\")\n",
    "    #Run Recursive feature elimination to remove down to RFE_Feats\n",
    "    if rfe_ == True:\n",
    "        step = 2\n",
    "        selector = RFE(model, n_features_to_select=RFE_Feats, step=step)\n",
    "        selector = selector.fit(df, label_abund)\n",
    "        selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        feat_list = selector.get_feature_names_out()\n",
    "        df = df[feat_list]\n",
    "        # df_out=pd.concat([df, NPIDs,label_abund_df],axis=1)\n",
    "        # df_out.to_excel(\"Input_data/Save_files/df_RFE40_\"+id+\".xlsx\")\n",
    "    tmp2=scorer(df, label_abund, model, id, 10)\n",
    "    tmp2['Abundance Filter']=i\n",
    "\n",
    "    summary_tmp.append(tmp2)\n",
    "\n",
    "    summary=pd.concat(summary_tmp,axis=0)\n",
    "summary.to_excel('Output_data/'+id+'.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# df=df_a[df_a['Abundance']>=0.01]\n",
    "# df_a['Abundance']=np.log10(df_a['Abundance']+1)\n",
    "df['Abundance']=np.log2(df['Abundance']+1)\n",
    "plt.hist(df['Abundance'],bins=25)\n",
    "plt.xlim(-2,2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Editable Variables\n",
    "#list of test filters\n",
    "zerosperrow = 0.3\n",
    "multi_files = True  #set to false if you just want to set one  prot_abund_file\n",
    "rfecv_ = True  #True_runs RFECV\n",
    "rfe_ = False     #True runs Recursive feature elimination\n",
    "abund_controls = True # True keeps the serum as an input feature\n",
    "splits = 10     #number of splits for cross validation across QC methods and feature selection methods\n",
    "in_dir = \"Input_data/Proteomic data/Abundance2/\"\n",
    "prot_abund_file = 'Input_data/Proteomic data/Abundance2/Norm_Intensity _all20230403.xlsx'\n",
    "NP_filepath = 'Input_data/NPs/NP_Database.xlsx'\n",
    "controls_file = 'Input_data/Proteomic data/controls_combined.xlsx'\n",
    "uniprot_filepath = 'Input_data/BioPython_data/Combined_biopyCalcs.xlsx'\n",
    "NSPfilePath = 'Input_data/NetSurfP_data/Combined.xlsx'\n",
    "df_filepath='Input_data/Save_files/df_whole_Con_drop_30%zeros.xlsx'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "scorings=['r2','neg_mean_squared_error','neg_mean_absolute_error']\n",
    "RFE_Feats = 40\n",
    "model = RandomForestRegressor(n_estimators=80)\n",
    "# model=XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, objective='reg:squarederror')\n",
    "summary_tmp=[]\n",
    "for z in scorings:\n",
    "    df=pd.read_excel('Input_data/Save_files/df_whole_noCon_drop30%zeros.xlsx')\n",
    "    labels_df= df['label_abund_df'].copy()\n",
    "    id_col= df['NPIDs'].copy()\n",
    "    labels=np.ravel(labels_df)\n",
    "    df.drop(columns=['Abundance','NPUNID'],inplace=True)\n",
    "    # label_abund_df.to_excel(\"Input_data/Save_files/label_abund\"+id+\".xlsx\",index=False)\n",
    "    # Run PCA to seee how data differentiates#\n",
    "    # PCA_plot(df,label_abund,id)\n",
    "\n",
    "\n",
    "    #run Recursive feature elimination with cross validation\n",
    "    if rfecv_ == True:\n",
    "        df = RFECV_plot(df,label_abund,model,id,folds=splits,step=2,scoring=z)\n",
    "        df_out=pd.concat([df, NPIDs,label_abund_df],axis=1)\n",
    "        df_out.to_excel(\"Input_data/Save_files/df_RFECV(40)_\"+id+\".xlsx\")\n",
    "\n",
    "    #use recursive feature elimination with Random Forest Regression as the estimator to select top 45 important features\n",
    "    if rfe_ == True:\n",
    "        step = 2\n",
    "        estimator = RandomForestRegressor(n_estimators=100)\n",
    "        selector = RFE(estimator, n_features_to_select=RFE_Feats, step=step)\n",
    "        selector = selector.fit(df, label_abund)\n",
    "        selector.support_\n",
    "        ranking = selector.ranking_\n",
    "        feat_list = selector.get_feature_names_out()\n",
    "        df = df[feat_list]\n",
    "        df_out=pd.concat([df, NPIDs,label_abund_df],axis=1)\n",
    "        df_out.to_excel(\"Input_data/Save_files/df_RFE40_\"+id+\".xlsx\")\n",
    "\n",
    "    #Quality control\n",
    "    v\n",
    "# summary.to_excel('Output_data/'+id+'.xlsx', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-23T16:59:29.834063Z",
     "end_time": "2023-04-23T16:59:33.056219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 17)\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "##Testing Each NP independently## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "# df_filepath = 'Input_data/Save_files/df_1_all_RFE15_RFR.xlsx'\n",
    "# df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[1,20,19,16,7,31,34,43,44]\n",
    "NPUNID_list=[2]\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "\n",
    "#Create filter to for dropping abundance values below\n",
    "start = 0.0001\n",
    "stop = 1\n",
    "num_points = 15\n",
    "\n",
    "# Calculate the common difference between consecutive terms in the series\n",
    "common_diff = (math.log(stop) - math.log(start)) / (num_points - 1)\n",
    "\n",
    "# Generate the logarithmic series as a list\n",
    "Abund_filter = [start * math.exp(i * common_diff) for i in range(num_points)]\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "# df_a=df_a.drop(columns=['Abundance','NPUNID'],axis=1).copy()\n",
    "# df_a=RFECV_plot(df_a,label_abund,model,'a',folds=10,step=1)\n",
    "# df_a=pd.concat([df_a,labels,id_col],axis=1)\n",
    "print(df_a.shape)\n",
    "# Loop through each ID in the list\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "for i in Abund_filter:\n",
    "    df_a= df_a[df_a['Abundance']>=i].copy()\n",
    "    for id in id_list:\n",
    "        df=df_a.copy()\n",
    "        # Remove the row with the current ID from the dataframe\n",
    "        removed_row = df.loc[df['NPUNID'] == id].copy()\n",
    "        df = df.loc[df['NPUNID'] != id].copy()\n",
    "\n",
    "        # Split the remaining data into features and target\n",
    "        X_train = df.drop(['Abundance', 'NPUNID'], axis=1)\n",
    "        y_train = df['Abundance']\n",
    "\n",
    "        # Fit a random forest regression model to the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Use the trained model to predict on the removed ID\n",
    "        X_test = removed_row.drop(['Abundance', 'NPUNID'], axis=1)\n",
    "        y_true = removed_row['Abundance']\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate the Accuracy scores and add it to the list\n",
    "        pearson, _ = pearsonr(y_true, y_pred)\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        pearson_scores.append(pearson)\n",
    "        r2_scores.append(r2)\n",
    "        mse.append(mse_score)\n",
    "        print(id)\n",
    "        tmp=pd.DataFrame({'Abundandce Filter': i,\n",
    "                                  'NPUNID':id,\n",
    "                                  'MSE':mse_score,\n",
    "                                  'R2':r2,\n",
    "                                  'Pearson':pearson},index=[0])\n",
    "        eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/AbundThresholdingRFR_NP(2).xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Feature Elimination with Correlated Features ran successfully\n",
      "(21016, 28)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 28, got 50",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 37>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     35\u001B[0m X_test \u001B[38;5;241m=\u001B[39m removed_row\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundance\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNPUNID\u001B[39m\u001B[38;5;124m'\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     36\u001B[0m y_true \u001B[38;5;241m=\u001B[39m removed_row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundance\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 37\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Calculate the Accuracy scores and add it to the list\u001B[39;00m\n\u001B[0;32m     39\u001B[0m pearson, _ \u001B[38;5;241m=\u001B[39m pearsonr(y_true, y_pred)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1114\u001B[0m, in \u001B[0;36mXGBModel.predict\u001B[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001B[0m\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_can_use_inplace_predict():\n\u001B[0;32m   1113\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1114\u001B[0m         predts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_booster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace_predict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1116\u001B[0m \u001B[43m            \u001B[49m\u001B[43miteration_range\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miteration_range\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1117\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpredict_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmargin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput_margin\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalue\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1118\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmissing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmissing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1119\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbase_margin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_margin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1120\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalidate_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1122\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m _is_cupy_array(predts):\n\u001B[0;32m   1123\u001B[0m             \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcupy\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=import-error\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2268\u001B[0m, in \u001B[0;36mBooster.inplace_predict\u001B[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001B[0m\n\u001B[0;32m   2264\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   2265\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`shape` attribute is required when `validate_features` is True.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2266\u001B[0m         )\n\u001B[0;32m   2267\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_features() \u001B[38;5;241m!=\u001B[39m data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m-> 2268\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2269\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature shape mismatch, expected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_features()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2270\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2271\u001B[0m         )\n\u001B[0;32m   2273\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m   2274\u001B[0m     _array_interface,\n\u001B[0;32m   2275\u001B[0m     _is_cudf_df,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2278\u001B[0m     _transform_pandas_df,\n\u001B[0;32m   2279\u001B[0m )\n\u001B[0;32m   2281\u001B[0m enable_categorical \u001B[38;5;241m=\u001B[39m _has_categorical(\u001B[38;5;28mself\u001B[39m, data)\n",
      "\u001B[1;31mValueError\u001B[0m: Feature shape mismatch, expected: 28, got 50"
     ]
    }
   ],
   "source": [
    "##Drop BALF Samples and then Predict on them and see how well it goes\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_1_all_RFE50_RFR.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "labels= df_a['Abundance'].copy()\n",
    "id_col= df_a['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[1,20,19,16,7,31,34,43,44]\n",
    "NPUNID_list=[7,8,9,10,11,12,13,14,15,16]\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "\n",
    "removed_row = df_a.loc[df_a['NPUNID'].isin(NPUNID_list)].copy()\n",
    "df_a = df_a.loc[~df_a['NPUNID'].isin(NPUNID_list)].copy()\n",
    "y_train=df_a['Abundance'].copy()\n",
    "label_abund=np.ravel(y_train)\n",
    "model=XGBRegressor(n_estimators=100)\n",
    "df_a=df_a.drop(columns=['Abundance','NPUNID'],axis=1).copy()\n",
    "df_a=RFECV_plot(df_a,label_abund,model,'a',folds=5,step=2)\n",
    "print(df_a.shape)\n",
    "# Loop through each ID in the list\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# Split the remaining data into features and target\n",
    "X_train = df_a\n",
    "\n",
    "\n",
    "# Fit a random forest regression model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict on the removed ID\n",
    "X_test = removed_row[X_train.columns]\n",
    "y_true = removed_row['Abundance']\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the Accuracy scores and add it to the list\n",
    "pearson, _ = pearsonr(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "pearson_scores.append(pearson)\n",
    "r2_scores.append(r2)\n",
    "mse.append(mse_score)\n",
    "print(id)\n",
    "tmp=pd.DataFrame({'Abundandce Filter': i,\n",
    "                          'NPUNID':id,\n",
    "                          'MSE':mse_score,\n",
    "                          'R2':r2,\n",
    "                          'Pearson':pearson},index=[0])\n",
    "eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/PredictonBALFSamples.xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in function id>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     11\u001B[0m mse\u001B[38;5;241m.\u001B[39mappend(mse_score)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mid\u001B[39m)\n\u001B[1;32m---> 13\u001B[0m tmp\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundandce Filter\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[43mi\u001B[49m,\n\u001B[0;32m     14\u001B[0m                           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNPUNID\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28mid\u001B[39m,\n\u001B[0;32m     15\u001B[0m                           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMSE\u001B[39m\u001B[38;5;124m'\u001B[39m:mse_score,\n\u001B[0;32m     16\u001B[0m                           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mR2\u001B[39m\u001B[38;5;124m'\u001B[39m:r2,\n\u001B[0;32m     17\u001B[0m                           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPearson\u001B[39m\u001B[38;5;124m'\u001B[39m:pearson},index\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     18\u001B[0m eval_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([eval_df,tmp],ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     20\u001B[0m eval_df\u001B[38;5;241m.\u001B[39mto_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutput_data/PredictonBALFSamples.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)\n",
    "y_true = removed_row['Abundance']\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the Accuracy scores and add it to the list\n",
    "pearson, _ = pearsonr(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "pearson_scores.append(pearson)\n",
    "r2_scores.append(r2)\n",
    "mse.append(mse_score)\n",
    "print(id)\n",
    "tmp=pd.DataFrame({'Abundandce Filter': i,\n",
    "                          'NPUNID':id,\n",
    "                          'MSE':mse_score,\n",
    "                          'R2':r2,\n",
    "                          'Pearson':pearson},index=[0])\n",
    "eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/PredictonBALFSamples.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T13:20:14.801208Z",
     "end_time": "2023-04-26T13:20:16.226685Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_test=removed_row[X_train.columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T13:20:50.015780Z",
     "end_time": "2023-04-26T13:20:50.034205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       Length  frac_aa_C  frac_aa_I  frac_aa_L  frac_aa_N  frac_aa_R  \\\n105       388   0.038660   0.018041   0.108247   0.036082   0.038660   \n127       345   0.040580   0.017391   0.098551   0.049275   0.037681   \n238       313   0.057508   0.025559   0.124601   0.025559   0.076677   \n250       151   0.019868   0.026490   0.086093   0.052980   0.033113   \n342       733   0.009550   0.068213   0.084584   0.040928   0.040928   \n...       ...        ...        ...        ...        ...        ...   \n25563     248   0.008065   0.040323   0.096774   0.028226   0.052419   \n25659     296   0.003378   0.040541   0.081081   0.013514   0.084459   \n25669     376   0.005319   0.074468   0.082447   0.023936   0.066489   \n25675     968   0.015496   0.047521   0.095041   0.037190   0.055785   \n25713     469   0.014925   0.046908   0.100213   0.038380   0.074627   \n\n       frac_aa_V  molecular_weight  secondary_structure_fraction_disordered  \\\n105     0.072165        42712.3186                                 0.208763   \n127     0.104348        37325.2167                                 0.226087   \n238     0.047923        34271.3821                                 0.172524   \n250     0.092715        16929.8755                                 0.225166   \n342     0.053206        84786.8869                                 0.256480   \n...          ...               ...                                      ...   \n25563   0.048387        27705.7129                                 0.177419   \n25659   0.081081        33509.1996                                 0.341216   \n25669   0.066489        42613.2137                                 0.196809   \n25675   0.071281       106907.3156                                 0.231405   \n25713   0.038380        51605.8075                                 0.191898   \n\n       fraction_exposed_nonpolar_exposed  ...  Ligand_BSA  Ligand_PEG  \\\n105                             0.418239  ...           1           0   \n127                             0.480427  ...           1           0   \n238                             0.472000  ...           1           0   \n250                             0.306122  ...           1           0   \n342                             0.209091  ...           1           0   \n...                                  ...  ...         ...         ...   \n25563                           0.258503  ...           1           0   \n25659                           0.363248  ...           1           0   \n25669                           0.270115  ...           1           0   \n25675                           0.325203  ...           1           0   \n25713                           0.374696  ...           1           0   \n\n       Surface_Ligand  Dtem  Dh_core  Dh_functionalized  Centrifuged  \\\n105                 1   100      230                230            0   \n127                 1   100      230                230            0   \n238                 1   100      230                230            0   \n250                 1   100      230                230            0   \n342                 1   100      230                230            0   \n...               ...   ...      ...                ...          ...   \n25563               1   100      230                230            0   \n25659               1   100      230                230            0   \n25669               1   100      230                230            0   \n25675               1   100      230                230            0   \n25713               1   100      230                230            0   \n\n       NP_incubation Concentration (mg/mL)  Incubation Concentration (mg/ml)  \\\n105                                   25.0                               0.2   \n127                                   25.0                               0.2   \n238                                   25.0                               0.2   \n250                                   25.0                               0.2   \n342                                   25.0                               0.2   \n...                                    ...                               ...   \n25563                                 25.0                               0.2   \n25659                                 25.0                               0.2   \n25669                                 25.0                               0.2   \n25675                                 25.0                               0.2   \n25713                                 25.0                               0.2   \n\n       Incubation Time (minutes)  \n105                           60  \n127                           60  \n238                           60  \n250                           60  \n342                           60  \n...                          ...  \n25563                         60  \n25659                         60  \n25669                         60  \n25675                         60  \n25713                         60  \n\n[474 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>frac_aa_C</th>\n      <th>frac_aa_I</th>\n      <th>frac_aa_L</th>\n      <th>frac_aa_N</th>\n      <th>frac_aa_R</th>\n      <th>frac_aa_V</th>\n      <th>molecular_weight</th>\n      <th>secondary_structure_fraction_disordered</th>\n      <th>fraction_exposed_nonpolar_exposed</th>\n      <th>...</th>\n      <th>Ligand_BSA</th>\n      <th>Ligand_PEG</th>\n      <th>Surface_Ligand</th>\n      <th>Dtem</th>\n      <th>Dh_core</th>\n      <th>Dh_functionalized</th>\n      <th>Centrifuged</th>\n      <th>NP_incubation Concentration (mg/mL)</th>\n      <th>Incubation Concentration (mg/ml)</th>\n      <th>Incubation Time (minutes)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105</th>\n      <td>388</td>\n      <td>0.038660</td>\n      <td>0.018041</td>\n      <td>0.108247</td>\n      <td>0.036082</td>\n      <td>0.038660</td>\n      <td>0.072165</td>\n      <td>42712.3186</td>\n      <td>0.208763</td>\n      <td>0.418239</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>345</td>\n      <td>0.040580</td>\n      <td>0.017391</td>\n      <td>0.098551</td>\n      <td>0.049275</td>\n      <td>0.037681</td>\n      <td>0.104348</td>\n      <td>37325.2167</td>\n      <td>0.226087</td>\n      <td>0.480427</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>313</td>\n      <td>0.057508</td>\n      <td>0.025559</td>\n      <td>0.124601</td>\n      <td>0.025559</td>\n      <td>0.076677</td>\n      <td>0.047923</td>\n      <td>34271.3821</td>\n      <td>0.172524</td>\n      <td>0.472000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>151</td>\n      <td>0.019868</td>\n      <td>0.026490</td>\n      <td>0.086093</td>\n      <td>0.052980</td>\n      <td>0.033113</td>\n      <td>0.092715</td>\n      <td>16929.8755</td>\n      <td>0.225166</td>\n      <td>0.306122</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>733</td>\n      <td>0.009550</td>\n      <td>0.068213</td>\n      <td>0.084584</td>\n      <td>0.040928</td>\n      <td>0.040928</td>\n      <td>0.053206</td>\n      <td>84786.8869</td>\n      <td>0.256480</td>\n      <td>0.209091</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25563</th>\n      <td>248</td>\n      <td>0.008065</td>\n      <td>0.040323</td>\n      <td>0.096774</td>\n      <td>0.028226</td>\n      <td>0.052419</td>\n      <td>0.048387</td>\n      <td>27705.7129</td>\n      <td>0.177419</td>\n      <td>0.258503</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>25659</th>\n      <td>296</td>\n      <td>0.003378</td>\n      <td>0.040541</td>\n      <td>0.081081</td>\n      <td>0.013514</td>\n      <td>0.084459</td>\n      <td>0.081081</td>\n      <td>33509.1996</td>\n      <td>0.341216</td>\n      <td>0.363248</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>25669</th>\n      <td>376</td>\n      <td>0.005319</td>\n      <td>0.074468</td>\n      <td>0.082447</td>\n      <td>0.023936</td>\n      <td>0.066489</td>\n      <td>0.066489</td>\n      <td>42613.2137</td>\n      <td>0.196809</td>\n      <td>0.270115</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>25675</th>\n      <td>968</td>\n      <td>0.015496</td>\n      <td>0.047521</td>\n      <td>0.095041</td>\n      <td>0.037190</td>\n      <td>0.055785</td>\n      <td>0.071281</td>\n      <td>106907.3156</td>\n      <td>0.231405</td>\n      <td>0.325203</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>25713</th>\n      <td>469</td>\n      <td>0.014925</td>\n      <td>0.046908</td>\n      <td>0.100213</td>\n      <td>0.038380</td>\n      <td>0.074627</td>\n      <td>0.038380</td>\n      <td>51605.8075</td>\n      <td>0.191898</td>\n      <td>0.374696</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>230</td>\n      <td>230</td>\n      <td>0</td>\n      <td>25.0</td>\n      <td>0.2</td>\n      <td>60</td>\n    </tr>\n  </tbody>\n</table>\n<p>474 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T13:21:01.536599Z",
     "end_time": "2023-04-26T13:21:01.586078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Feature Elimination with Correlated Features ran successfully\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m df_a\u001B[38;5;241m=\u001B[39mdf_a\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundance\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNPUNID\u001B[39m\u001B[38;5;124m'\u001B[39m],axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     11\u001B[0m df_a\u001B[38;5;241m=\u001B[39mRFECV_plot(df_a,label_abund,model,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m,folds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m scram_score(\u001B[43mdf\u001B[49m, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m     13\u001B[0m feat_drop(df, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##Run Quality Control on df to get a look at important features and such##\n",
    "df_filepath = 'Input_data/Save_files/df_1_all_RFE50_RFR.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "labels= df_a['Abundance'].copy()\n",
    "id_col= df_a['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels)\n",
    "\n",
    "\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "df_a=df_a.drop(columns=['Abundance','NPUNID'],axis=1).copy()\n",
    "df_a=RFECV_plot(df_a,label_abund,model,'b',folds=5,step=2)\n",
    "scram_score(df, label_abund, model, id, 0.2)\n",
    "feat_drop(df, label_abund, model, id, 0.2)\n",
    "# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\n",
    "tmp2=scorer(df, label_abund, model, id, 10)\n",
    "zeros=(raw_MS_data['Abundance']==0).sum()\n",
    "percent_zeros=zeros/raw_MS_data.shape[0]\n",
    "tmp2['TotalZeros']=zeros\n",
    "tmp2['Percent_zeros']=percent_zeros\n",
    "summary_tmp.append(tmp2)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\PycharmProjects\\PC_ML_using_NSP\\helper_functions_KP.py:89: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(feats, rotation=90)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scramble Scoring ran successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\PycharmProjects\\PC_ML_using_NSP\\helper_functions_KP.py:151: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(feats, rotation=90)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feat drop ran successfully\n",
      "Scorer ran successfully\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'summary_tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m tmp2\u001B[38;5;241m=\u001B[39mscorer(df_a, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# zeros=(raw_MS_data['Abundance']==0).sum()\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# percent_zeros=zeros/raw_MS_data.shape[0]\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# tmp2['TotalZeros']=zeros\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# tmp2['Percent_zeros']=percent_zeros\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[43msummary_tmp\u001B[49m\u001B[38;5;241m.\u001B[39mappend(tmp2)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# lasso_feature_selection(df, label_abund, id)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m summary\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mconcat(summary_tmp,axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'summary_tmp' is not defined"
     ]
    }
   ],
   "source": [
    "id='a'\n",
    "scram_score(df_a, label_abund, model, id, 0.2)\n",
    "feat_drop(df_a, label_abund, model, id, 0.2)\n",
    "# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\n",
    "tmp2=scorer(df_a, label_abund, model, id, 10)\n",
    "# zeros=(raw_MS_data['Abundance']==0).sum()\n",
    "# percent_zeros=zeros/raw_MS_data.shape[0]\n",
    "# tmp2['TotalZeros']=zeros\n",
    "# tmp2['Percent_zeros']=percent_zeros\n",
    "summary_tmp.append(tmp2)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "   pearson_mean  pearson_std   R2_mean    R2_std  MSE_mean   MSE_std  \\\n0      0.954583     0.024072  0.908116  0.045036  0.273689  0.147636   \n\n   Number of Features ID                                Feature Importances  \\\n0                  26  a  [0.04056696604843621, 0.042609126157557534, 0....   \n\n                                            Features  \n0  [Length, frac_aa_C, frac_aa_I, frac_aa_R, mole...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pearson_mean</th>\n      <th>pearson_std</th>\n      <th>R2_mean</th>\n      <th>R2_std</th>\n      <th>MSE_mean</th>\n      <th>MSE_std</th>\n      <th>Number of Features</th>\n      <th>ID</th>\n      <th>Feature Importances</th>\n      <th>Features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.954583</td>\n      <td>0.024072</td>\n      <td>0.908116</td>\n      <td>0.045036</td>\n      <td>0.273689</td>\n      <td>0.147636</td>\n      <td>26</td>\n      <td>a</td>\n      <td>[0.04056696604843621, 0.042609126157557534, 0....</td>\n      <td>[Length, frac_aa_C, frac_aa_I, frac_aa_R, mole...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T07:04:45.699325Z",
     "end_time": "2023-04-24T07:04:45.741362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run Histogram of each Feature###\n",
    "# Get total number of rows\n",
    "df=df_a\n",
    "total_count = len(df)\n",
    "df = df.rename(columns=lambda x: x.replace('/', ''))\n",
    "# Loop over each column of the dataframe\n",
    "for col in df.columns:\n",
    "    # Create a histogram of the current column, with bins=10\n",
    "    data=df[col]\n",
    "    plt.hist(data, weights=np.ones_like(data) / len(data))\n",
    "\n",
    "    # Set the title of the histogram to the column name and percent of total population\n",
    "    plt.title(str(col))\n",
    "    plt.savefig('Output_data/{}.png'.format(str(col)))\n",
    "    plt.close()\n",
    "    # Show the histogram\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

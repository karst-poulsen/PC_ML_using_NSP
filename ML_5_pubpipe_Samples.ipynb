{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import _gradient_boosting\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from helper_functions_KP import *\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NormBALFsamples.xlsx', 'Norm_Intensity _all20230403.xlsx']\n"
     ]
    }
   ],
   "source": [
    "#Editable Variables\n",
    "multi_files=True #set to false if you just want to set one  prot_abund_file\n",
    "in_dir=\"Input_data/Proteomic data/Abundance2/\"\n",
    "prot_abund_file='Input_data/Proteomic data/Abundance2/Norm_Intensity _all20230403.xlsx'\n",
    "NP_filepath='Input_data/NPs/NP_Database.xlsx'\n",
    "controls_file='Input_data/Proteomic data/controls_combined.xlsx'\n",
    "uniprot_filepath='Input_data/BioPython_data/Combined_biopyCalcs.xlsx'\n",
    "NSPfilePath='Input_data/NetSurfP_data/Combined.xlsx'\n",
    "model=RandomForestRegressor(n_estimators=150)\n",
    "# take files in_dir and combine then into one pandas df (raw_MS_data) ###USE when combining multiple datasets####\n",
    "files = os.listdir(in_dir)\n",
    "print(files)\n",
    "if multi_files == True:\n",
    "    for i,f in enumerate(files):\n",
    "        print(i)\n",
    "        if i==0:\n",
    "            raw_MS_data=pd.read_excel(in_dir+f,header=0)\n",
    "            # print(raw_MS_data)\n",
    "            raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'],var_name='Sample_num', value_name='Abundance')\n",
    "            print('BALF',raw_MS_data.shape)\n",
    "        else:\n",
    "            print(i)\n",
    "            temp = pd.read_excel(in_dir+f,header=0)\n",
    "            temp = pd.melt(temp, id_vars=['Entry'],var_name='Sample_num', value_name='Abundance')\n",
    "            print('Bovine',temp.shape)\n",
    "            # print(temp)\n",
    "            # print(temp)\n",
    "            raw_MS_data2=pd.concat([raw_MS_data,temp])\n",
    "            print('merge',raw_MS_data2.shape)\n",
    "            # print('did it')\n",
    "else:\n",
    "    raw_MS_data2=pd.read_excel(prot_abund_file,header=0)\n",
    "# raw_MS_data2\n",
    "# melt the df to make it an accession number, NPUNID, Abundance dataset\n",
    "# raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'],var_name='Sample_num', value_name='Abundance')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Instructions for the pipeline Requires two inputs for training: - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration) - NetsurfP and Biopython data that has been precalculated - X characteristics to predict\n",
    "pipeline Take mass spec spreadsheet Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration Merge with Proteome data to get file that has Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence Calculate protein features using biopython Merge with NSP data to get all protein features\n",
    "Split into X and Y dataset with Entries as labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape beofre dropping rows (474, 14)\n",
      "shape after dropping rows (220, 14)\n",
      "shape beofre dropping rows (2860, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\AppData\\Local\\Temp\\ipykernel_16852\\2279316902.py:115: MatplotlibDeprecationWarning: Auto-removal of grids by pcolor() and pcolormesh() is deprecated since 3.5 and will be removed two minor releases later; please call grid(False) first.\n",
      "  plt.colorbar()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    161\u001B[0m plt\u001B[38;5;241m.\u001B[39mclose(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    163\u001B[0m \u001B[38;5;66;03m#Quality control\u001B[39;00m\n\u001B[1;32m--> 164\u001B[0m \u001B[43mscorer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_abund\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    165\u001B[0m scram_score(df, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m    166\u001B[0m feat_drop(df, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\PC_ML_using_NSP\\helper_functions_KP.py:195\u001B[0m, in \u001B[0;36mscorer\u001B[1;34m(df, label, model, identifier, folds)\u001B[0m\n\u001B[0;32m    193\u001B[0m r2 \u001B[38;5;241m=\u001B[39m r2_score(y_test, y_pred)\n\u001B[0;32m    194\u001B[0m mse_score \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, y_pred)\n\u001B[1;32m--> 195\u001B[0m acc_score \u001B[38;5;241m=\u001B[39m \u001B[43maccuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mround\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;66;03m# Append the scores for this fold to the lists\u001B[39;00m\n\u001B[0;32m    197\u001B[0m pearson_scores\u001B[38;5;241m.\u001B[39mappend(pearson)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001B[0m, in \u001B[0;36maccuracy_score\u001B[1;34m(y_true, y_pred, normalize, sample_weight)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;124;03m\"\"\"Accuracy classification score.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m \n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;124;03m0.5\u001B[39;00m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;66;03m# Compute accuracy for each possible representation\u001B[39;00m\n\u001B[1;32m--> 211\u001B[0m y_type, y_true, y_pred \u001B[38;5;241m=\u001B[39m \u001B[43m_check_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultilabel\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001B[0m, in \u001B[0;36m_check_targets\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m     90\u001B[0m     y_type \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(y_type) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 93\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClassification metrics can\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt handle a mix of \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m targets\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     95\u001B[0m             type_true, type_pred\n\u001B[0;32m     96\u001B[0m         )\n\u001B[0;32m     97\u001B[0m     )\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001B[39;00m\n\u001B[0;32m    100\u001B[0m y_type \u001B[38;5;241m=\u001B[39m y_type\u001B[38;5;241m.\u001B[39mpop()\n",
      "\u001B[1;31mValueError\u001B[0m: Classification metrics can't handle a mix of continuous and multiclass targets"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Editable Variables\n",
    "#list of test filters\n",
    "zerosperrow = [0.9, 0.5, 0.3]\n",
    "for z in zerosperrow:\n",
    "    multi_files = True  #set to false if you just want to set one  prot_abund_file\n",
    "    in_dir = \"Input_data/Proteomic data/Abundance2/\"\n",
    "    prot_abund_file = 'Input_data/Proteomic data/Abundance2/Norm_Intensity _all20230403.xlsx'\n",
    "    NP_filepath = 'Input_data/NPs/NP_Database.xlsx'\n",
    "    controls_file = 'Input_data/Proteomic data/controls_combined.xlsx'\n",
    "    uniprot_filepath = 'Input_data/BioPython_data/Combined_biopyCalcs.xlsx'\n",
    "    NSPfilePath = 'Input_data/NetSurfP_data/Combined.xlsx'\n",
    "    id = 'all_NoCon_RFE40_droprows' + str(z) + 'zeros'\n",
    "    RFE_Feats = 40\n",
    "    model = RandomForestRegressor(n_estimators=150)\n",
    "    # take files in_dir and combine then into one pandas df (raw_MS_data) ###USE when combining multiple datasets####\n",
    "    # melt the df to make it an accession number, NPUNID, Abundance dataset before combining\n",
    "    files = os.listdir(in_dir)\n",
    "    if multi_files == True:\n",
    "        for i, f in enumerate(files):\n",
    "            if i == 0:\n",
    "                raw_MS_data = pd.read_excel(in_dir + f, header=0)\n",
    "                cols = raw_MS_data.shape[1]\n",
    "                cutoff = int(z * cols)\n",
    "                print('shape beofre dropping rows', raw_MS_data.shape)\n",
    "                raw_MS_data = raw_MS_data.drop(raw_MS_data[(raw_MS_data == 0).sum(axis=1) >= cutoff].index)\n",
    "                print('shape after dropping rows', raw_MS_data.shape)\n",
    "                # print(raw_MS_data)\n",
    "                raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "\n",
    "            else:\n",
    "\n",
    "                temp = pd.read_excel(in_dir + f, header=0)\n",
    "                cols = temp.shape[1]\n",
    "                cutoff = int(z * cols)\n",
    "                print('shape beofre dropping rows', raw_MS_data.shape)\n",
    "                temp = temp.drop(temp[(temp == 0).sum(axis=1) >= cutoff].index)\n",
    "                print('shape after dropping rows', raw_MS_data.shape)\n",
    "                temp = pd.melt(temp, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "\n",
    "                raw_MS_data = pd.concat([raw_MS_data, temp])\n",
    "\n",
    "    else:\n",
    "        raw_MS_data = pd.read_excel(prot_abund_file, header=0)\n",
    "        cols = raw_MS_data.shape[1]\n",
    "        cutoff = int(z * cols)\n",
    "        print('shape beofre dropping rows', raw_MS_data.shape)\n",
    "        raw_MS_data = raw_MS_data.drop(raw_MS_data[(raw_MS_data == 0).sum(axis=1) >= cutoff].index)\n",
    "        print('shape after dropping rows', raw_MS_data.shape)\n",
    "        raw_MS_data = pd.melt(raw_MS_data, id_vars=['Entry'], var_name='Sample_num', value_name='Abundance')\n",
    "    #remove prots that were added due to merge\n",
    "    raw_MS_data = raw_MS_data.dropna()\n",
    "    ###Bring in controls (MS data for serums)##\n",
    "    controls = pd.read_excel(controls_file, header=0)\n",
    "    MS_data_controls = pd.merge(raw_MS_data, controls, how='left', on='Entry')\n",
    "    ###Bring in Uniprot_data,NSPdata and NP data##\n",
    "    uniprot_dat = pd.read_excel(uniprot_filepath, header=0)\n",
    "    NSP_data = pd.read_excel(NSPfilePath)\n",
    "    ###Bring in NP data and merge to get complete NP dataset###\n",
    "    NPUNdata = pd.read_excel(NP_filepath, header=0, sheet_name='NPUNID')\n",
    "    NPprop = pd.read_excel(NP_filepath, header=0, sheet_name='NP_Props')\n",
    "    NPdata = pd.merge(NPUNdata, NPprop, how=\"left\", on='NPID')\n",
    "    NPdata.dropna(inplace=True)\n",
    "    #calculate Enrichment\n",
    "    #####MAYBE add binning here to keep negative results and improve capapbilities######\n",
    "    # MS_data_controls['Enrichment']= np.log2(MS_data_controls['Abundance']/MS_data_controls['Abundance_Controls'])\n",
    "    # MS_data=MS_data_controls.drop(columns=['Abundance','Abundance_Controls'])\n",
    "    #keep abundance Controls\n",
    "    # MS_data=MS_data_controls.drop(columns=['Abundance'])\n",
    "    raw_prop_data = pd.merge(MS_data_controls, uniprot_dat.drop_duplicates(subset=['Entry']), how='left', on='Entry')\n",
    "    Protein_data_complete = pd.merge(raw_prop_data, NSP_data.drop_duplicates(subset=['Entry']), how='left',\n",
    "                                     on='Entry')  #merges netsurfp features and biopython features\n",
    "    Protein_data_complete.fillna(0, inplace=True)\n",
    "    #creates new column called asa_sum_normalized which is the asa_sum value divide by the mass of the protein\n",
    "    for df in [Protein_data_complete]:\n",
    "        for col in ['asa_sum']:\n",
    "            df[col + '_normalized'] = df[col] / df['Mass']\n",
    "\n",
    "    data_complete = pd.merge(Protein_data_complete, NPdata, how='inner', on='Sample_num')\n",
    "    data_complete.drop(columns=['notes', 'Notes', 'NPUNID'], inplace=True)\n",
    "    data_complete.fillna(0, inplace=True)\n",
    "    data_complete = data_complete.replace([-np.inf], '-12')\n",
    "    data_complete = data_complete.replace([np.inf], '12')\n",
    "    #create ordinal variables\n",
    "    # data_complete2=pd.get_dummies(data_complete, columns=['Core Material','Surface_Ligand'])\n",
    "    le = LabelEncoder()\n",
    "    data_complete['Core Material'] = le.fit_transform(data_complete['Core Material'])\n",
    "    data_complete['Surface_Ligand'] = le.fit_transform(data_complete['Surface_Ligand'])\n",
    "\n",
    "    #set labels (what we are trying to predict) as Enrichment column\n",
    "    # labels=data_complete['Enrichment'].copy()\n",
    "    label_abund = np.ravel(data_complete['Abundance'].copy())\n",
    "    label_abund_df = pd.DataFrame(label_abund)\n",
    "    # label_enrich=np.ravel(data_complete['Enrichment'].copy())\n",
    "    #make it one dimenisional\n",
    "    #drop qualitative, not neccessary, and label columns\n",
    "    #create df without bonus NSP columns (remove total_exposed) There are too sets of features total_exposed and exposed_exposed\n",
    "    to_drop = data_complete.filter(like='total_exposed_')\n",
    "    data_complete.drop(columns=to_drop, inplace=True)\n",
    "    df = data_complete.drop(\n",
    "        ['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5',\n",
    "         'Raw_FileID'], axis=1)\n",
    "    df.drop(columns=['Abundance_Controls'], inplace=True)\n",
    "\n",
    "    # df.to_excel(\"Input_data/Save_files/df_\"+id+\".xlsx\")\n",
    "    # label_abund_df.to_excel(\"Input_data/Save_files/label_abund\"+id+\".xlsx\",index=False)\n",
    "\n",
    "    #Run PCA to seee how data differentiates#\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(df)\n",
    "    pca = PCA(n_components=5)\n",
    "    x_pca = pca.fit_transform(X_std)\n",
    "    plt.scatter(x_pca[:, 0], x_pca[:, 1], c=label_abund, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.savefig('Output_data/PCA' + id + '.png')\n",
    "    plt.close('all')\n",
    "    #use recursive feature elimination with Random Forest Regression as the estimator to select top 45 important features\n",
    "    step = 2\n",
    "    estimator = RandomForestRegressor(n_estimators=100)\n",
    "    selector = RFE(estimator, n_features_to_select=RFE_Feats, step=step)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    ranking = selector.ranking_\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df = df[feat_list]\n",
    "\n",
    "    #run Recursive feature elimination with cross validation\n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    id2 = 'dropped_controlAbundance'\n",
    "    step = 2\n",
    "    min_feats = 5\n",
    "    cv = KFold(n_splits=10)\n",
    "    estimator = RandomForestRegressor(n_estimators=100)\n",
    "    # estimator=Lasso(alpha=.05)\n",
    "    selector = RFECV(estimator=estimator, cv=cv, scoring='r2', min_features_to_select=min_feats, step=step)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    feat_list2 = selector.get_feature_names_out()\n",
    "    selected_features = df.columns[selector.support_]\n",
    "    df = df[feat_list2]\n",
    "    # df.to_excel(\"Input_data/Save_files/df_RFECV\"+id+id2+\".xlsx\")\n",
    "    # rfecv_df=pd.DataFrame(selector.cv_results_)\n",
    "    # rfecv_df.to_excel(\"Output_data/RFECV_results\"+id+id2+\".xlsx\")\n",
    "    # label_abund_df.to_excel(\"Input_data/Save_files/label_abund_all.xlsx\")\n",
    "    n_scores = len(selector.cv_results_[\"mean_test_score\"])\n",
    "    plt.close('all')\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Mean test accuracy\")\n",
    "    x = range(1, n_scores + 1)\n",
    "    y = selector.cv_results_[\"mean_test_score\"]\n",
    "    err = selector.cv_results_[\"std_test_score\"]\n",
    "    plt.plot(x, y, 'k-')\n",
    "    plt.fill_between(x, y - err, y + err)\n",
    "    plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "    plt.savefig('Output_data/RFECV' + id + '.png')\n",
    "    plt.close('all')\n",
    "\n",
    "    #Quality control\n",
    "    scorer(df, label_abund, model, id, 10)\n",
    "    scram_score(df, label_abund, model, id, 0.2)\n",
    "    feat_drop(df, label_abund, model, id, 0.2)\n",
    "print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['accuracy',\n 'adjusted_mutual_info_score',\n 'adjusted_rand_score',\n 'average_precision',\n 'balanced_accuracy',\n 'completeness_score',\n 'explained_variance',\n 'f1',\n 'f1_macro',\n 'f1_micro',\n 'f1_samples',\n 'f1_weighted',\n 'fowlkes_mallows_score',\n 'homogeneity_score',\n 'jaccard',\n 'jaccard_macro',\n 'jaccard_micro',\n 'jaccard_samples',\n 'jaccard_weighted',\n 'matthews_corrcoef',\n 'max_error',\n 'mutual_info_score',\n 'neg_brier_score',\n 'neg_log_loss',\n 'neg_mean_absolute_error',\n 'neg_mean_absolute_percentage_error',\n 'neg_mean_gamma_deviance',\n 'neg_mean_poisson_deviance',\n 'neg_mean_squared_error',\n 'neg_mean_squared_log_error',\n 'neg_median_absolute_error',\n 'neg_root_mean_squared_error',\n 'normalized_mutual_info_score',\n 'precision',\n 'precision_macro',\n 'precision_micro',\n 'precision_samples',\n 'precision_weighted',\n 'r2',\n 'rand_score',\n 'recall',\n 'recall_macro',\n 'recall_micro',\n 'recall_samples',\n 'recall_weighted',\n 'roc_auc',\n 'roc_auc_ovo',\n 'roc_auc_ovo_weighted',\n 'roc_auc_ovr',\n 'roc_auc_ovr_weighted',\n 'top_k_accuracy',\n 'v_measure_score']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.get_scorer_names()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
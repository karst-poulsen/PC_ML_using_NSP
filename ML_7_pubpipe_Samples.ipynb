{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T04:19:03.246040Z",
     "end_time": "2023-05-03T04:19:03.269060Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import _gradient_boosting\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from helper_functions_pipe_testing import *\n",
    "from sklearn.metrics import  f1_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from imblearn.over_sampling import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from helper_functions_KP import *\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Instructions for the pipeline Requires two inputs for training: - Mass spec data with corresponding NP surface characteristics and experimental conditions (time, concentration) - NetsurfP and Biopython data that has been precalculated - X characteristics to predict\n",
    "pipeline Take mass spec spreadsheet Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration Merge with Proteome data to get file that has Accession,Enrichment,Dh,TEM,Zp,BET,Composition,Ligand,Shape,IncubationTime,IncubationConcentration,Mass,Length,Sequence Calculate protein features using biopython Merge with NSP data to get all protein features\n",
    "Split into X and Y dataset with Entries as labels\n",
    "In this pipeline (look at synth dataset and generate validation and prediction datasets out of original dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-27T21:34:28.059404Z",
     "end_time": "2023-04-27T21:34:52.488300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Sample code for loading saved DF and dropping appropriate columns before running### Also For running RFECV and saving the reduced df\n",
    "df_filepath='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "id='04232023'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "to_drop = df.filter(like='total_exposed_')\n",
    "df=df.drop(columns=to_drop.columns).copy()\n",
    "df.to_excel(\"Input_data/Save_files/df_2_Synth.xlsx\")\n",
    "# labels_df= df['Abundance'].copy()\n",
    "# id_col= df['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels_df)\n",
    "# model=RandomForestRegressor(n_estimators=100)\n",
    "# splits=10\n",
    "# scoring='neg_mean_squared_error'\n",
    "# df=df.drop(columns=['Entry', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID'])\n",
    "# import math\n",
    "#\n",
    "# start = 0.0001\n",
    "# stop = 1\n",
    "# num_points = 10\n",
    "# # Calculate the common difference between consecutive terms in the series\n",
    "# common_diff = (math.log(stop) - math.log(start)) / (num_points - 1)\n",
    "# # Generate the logarithmic series as a list\n",
    "# Abund_filter = [start * math.exp(i * common_diff) for i in range(num_points)]\n",
    "# # model = RandomForestRegressor(n_estimators=80)\n",
    "# # summary_tmp=[]\n",
    "# for i in Abund_filter:\n",
    "#     df_out= df[df['Abundance']>=i].copy()\n",
    "# df = RFECV_plot(df,label_abund,model,id,folds=splits,step=2,scoring=scoring)\n",
    "\n",
    "    # df_out.to_excel(\"Input_data/Save_files/Abund_Filters/df_1_all\"+str(i)+\".xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Tests to perform#\n",
    "##For RFR and RFC##\n",
    "#RFECV control abundance and no control abundance\n",
    "#RFE Curve -> performance curve relative to number of features selected#\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Feature Elimination with Correlated Features ran successfully\n",
      "Scorer ran successfully\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Run RFECV on synth database to see what features it sees as important and give the highest accuracy##\n",
    "in_dir='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "\n",
    "df = pd.read_excel(in_dir, header=0)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "#Drop zero values#\n",
    "Min_Control=df['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "ids=['CA']\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "for identifier in ids:\n",
    "    df = pd.read_excel(in_dir, header=0)\n",
    "    df=df[df['Abundance']>=Min_Control]\n",
    "    labels_df= df['Abundance'].copy()\n",
    "    id_col= df['NPUNID'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    label_abund=np.log2(label_abund)\n",
    "    # df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID','Abundance_Controls'])\n",
    "    # df=df.drop(columns=['Entry', 'Abundance', 'Sequence', 'NPID', 'Ligands', 'Protein Source', 'Sample_num', 'Unnamed: 5','Raw_FileID','NPUNID'])\n",
    "    if identifier=='NoCA':\n",
    "        df=df.drop(columns='Abundance_Controls')\n",
    "    df=df.drop(columns=['Abundance','NPUNID','NPID','Entry','Sequence','Sample_num', 'Raw_FileID','Ligands'])\n",
    "    step = 1\n",
    "    selector = RFE(model, n_features_to_select=75, step=step)\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df = df[feat_list].copy()\n",
    "\n",
    "\n",
    "    min_feats = 1\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    selector = RFECV(estimator=model, cv=cv, min_features_to_select=min_feats,\n",
    "                     step=step,scoring='neg_mean_squared_error')\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    feat_list2 = selector.get_feature_names_out()\n",
    "    selected_features = df.columns[selector.support_]\n",
    "    df = df[feat_list2]\n",
    "    # df.to_excel(\"Input_data/Save_files/df_RFECV\"+id+id2+\".xlsx\")\n",
    "    rfecv_df=pd.DataFrame(selector.cv_results_)\n",
    "    rfecv_df.to_excel(\"Output_data/RFECV_resultsRFR\"+identifier+\".xlsx\",index=False)\n",
    "    df=RFECV_plot(df,label_abund,model,identifier,5,1)\n",
    "    tmp2,tmp3=scorer(df, label_abund, model, identifier, 10)\n",
    "    summary_tmp.append(tmp2)\n",
    "    feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFECV_log2_synth_RFR.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFECV_log2_synth_RFR.xlsx', index=False)\n",
    "print('done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T14:58:53.486046Z",
     "end_time": "2023-05-03T15:26:16.423149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Run RFE to different numbers of features and see how the score changes with each variation # test with and without Control abundance##\n",
    "in_dir='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "\n",
    "df = pd.read_excel(in_dir, header=0)\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "#Drop zero values#\n",
    "Min_Control=df['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df=df[df['Abundance']>=Min_Control]\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "featnums=np.arange(75,1,-1).tolist()\n",
    "ids=['CA','NoCA']\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "\n",
    "for identifier in ids:\n",
    "    df = pd.read_excel(in_dir, header=0)\n",
    "    df=df[df['Abundance']>=Min_Control]\n",
    "    if identifier=='NoCA':\n",
    "        df=df.drop(columns='Abundance_Controls')\n",
    "\n",
    "\n",
    "    labels_df= df['Abundance'].copy()\n",
    "    id_col= df['NPUNID'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    label_abund=np.log2(label_abund)\n",
    "    df=df.drop(columns=['Abundance','NPUNID','Entry','Sequence','Sample_num', 'Raw_FileID','Ligands','NPID'])\n",
    "    for n_feats in featnums:\n",
    "        identity=identifier+str(n_feats)\n",
    "        step = 1\n",
    "        selector = RFE(model, n_features_to_select=n_feats, step=step)\n",
    "        selector = selector.fit(df, label_abund)\n",
    "        feat_list = selector.get_feature_names_out()\n",
    "        df = df[feat_list].copy()\n",
    "        tmp2,tmp3=scorer(df, label_abund, model, identity, 10)\n",
    "        summary_tmp.append(tmp2)\n",
    "        feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFEs_log2.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFEs_log2.xlsx', index=False)\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T08:19:40.947114Z",
     "end_time": "2023-05-03T09:52:35.526838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Output_data/Feats_RFR_AbundThresh.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 54>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m feats[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[0;32m     53\u001B[0m     feat_summary\u001B[38;5;241m=\u001B[39mfeat_summary\u001B[38;5;241m.\u001B[39mmerge(d, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeatures\u001B[39m\u001B[38;5;124m'\u001B[39m,how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mouter\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 54\u001B[0m \u001B[43mfeat_summary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mOutput_data/Feats_RFR_AbundThresh.xlsx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m summary\u001B[38;5;241m.\u001B[39mto_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOutput_data/Scores_RFR_AbundThresh.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2345\u001B[0m, in \u001B[0;36mNDFrame.to_excel\u001B[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001B[0m\n\u001B[0;32m   2332\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mformats\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexcel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExcelFormatter\n\u001B[0;32m   2334\u001B[0m formatter \u001B[38;5;241m=\u001B[39m ExcelFormatter(\n\u001B[0;32m   2335\u001B[0m     df,\n\u001B[0;32m   2336\u001B[0m     na_rep\u001B[38;5;241m=\u001B[39mna_rep,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2343\u001B[0m     inf_rep\u001B[38;5;241m=\u001B[39minf_rep,\n\u001B[0;32m   2344\u001B[0m )\n\u001B[1;32m-> 2345\u001B[0m \u001B[43mformatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexcel_writer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2347\u001B[0m \u001B[43m    \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstartrow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstartrow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstartcol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstartcol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfreeze_panes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfreeze_panes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2353\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\excel.py:888\u001B[0m, in \u001B[0;36mExcelFormatter.write\u001B[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001B[0m\n\u001B[0;32m    884\u001B[0m     need_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    885\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    886\u001B[0m     \u001B[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001B[39;00m\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001B[39;00m\n\u001B[1;32m--> 888\u001B[0m     writer \u001B[38;5;241m=\u001B[39m \u001B[43mExcelWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[abstract]\u001B[39;49;00m\n\u001B[0;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    891\u001B[0m     need_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:191\u001B[0m, in \u001B[0;36mXlsxWriter.__init__\u001B[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAppend mode is not supported with xlsxwriter!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 191\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatetime_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatetime_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    196\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mif_sheet_exists\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mif_sheet_exists\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbook \u001B[38;5;241m=\u001B[39m Workbook(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mengine_kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1106\u001B[0m, in \u001B[0;36mExcelWriter.__init__\u001B[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m IOHandles(\n\u001B[0;32m   1103\u001B[0m     cast(IO[\u001B[38;5;28mbytes\u001B[39m], path), compression\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mNone\u001B[39;00m}\n\u001B[0;32m   1104\u001B[0m )\n\u001B[0;32m   1105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, ExcelWriter):\n\u001B[1;32m-> 1106\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1109\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msheets: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcur_sheet \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    790\u001B[0m             handle,\n\u001B[0;32m    791\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    794\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    795\u001B[0m         )\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'Output_data/Feats_RFR_AbundThresh.xlsx'"
     ]
    }
   ],
   "source": [
    "### Running Binary Classification systems and seeing what abund threshold is the best for performance##\n",
    "\n",
    "abund_thresh=[-2,-1,-0.5,0.25,0.5,0.75,1,2,3,4]\n",
    "df_filepath='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df = pd.read_excel(df_filepath, header=0)\n",
    "Min_Control=df['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df['Abundance_Controls'].replace(0,Min_Control,inplace=True)\n",
    "df['Enrich']= np.log2(df['Abundance']/df['Abundance_Controls'])\n",
    "# df = df.replace(np.inf,10)\n",
    "model=RandomForestClassifier()\n",
    "# id='RFR_AFilter_'+str(i)+'NoCon'\n",
    "# Create an empty pandas DataFrame to store the evaluation metrics\n",
    "# eval_df = pd.DataFrame(columns=['Abund Thresh', 'F1', 'AUROC', 'Accuracy', 'Precision', 'Recall'])\n",
    "df=df.drop(columns=['Abundance','Entry','Sequence','Sample_num', 'Raw_FileID','NPID','Ligands'])\n",
    "# df=df.drop(columns=['Abundance_Controls'])\n",
    "summary_tmp=[]\n",
    "feats =[]\n",
    "# Iterate through multiple iterations of model training and testing\n",
    "for i in abund_thresh:\n",
    "    identifier='thresh_CA_'+str(i)\n",
    "    df_a=df.copy()\n",
    "    df_a['binary_target']= df_a['Enrich'].apply(lambda t: 1 if t>=i else 0)\n",
    "    labels_df = df_a['binary_target'].copy()\n",
    "    # id_col= df_a['NPUNID'].copy()\n",
    "    label_binary=np.ravel(labels_df)\n",
    "    df_a=df_a.drop(columns=['NPUNID','binary_target','Enrich']).copy()\n",
    "\n",
    "    step = 2\n",
    "    RFE_Feats=20\n",
    "    selector = RFE(model, n_features_to_select=RFE_Feats, step=step)\n",
    "    selector = selector.fit(df_a, label_binary)\n",
    "    selector.support_\n",
    "    ranking = selector.ranking_\n",
    "    feat_list = selector.get_feature_names_out()\n",
    "    df_a = df_a[feat_list].copy()\n",
    "\n",
    "    # x_train, x_test, y_train, y_test = train_test_split(df_a, label_binary, test_size=0.3, random_state=42)\n",
    "    # model.fit(x_train, y_train)\n",
    "    # y_pred = model.predict(x_test)\n",
    "    # f1 = f1_score(y_test, y_pred)\n",
    "    # auroc = roc_auc_score(y_test, y_pred)\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # precision = precision_score(y_test, y_pred)\n",
    "    # recall = recall_score(y_test, y_pred)\n",
    "    score_tmp, feat_tmp=scorer_RFC(df_a,label_binary,model,identifier,10)\n",
    "    # Append a new row to the eval_df DataFrame with the evaluation metrics for this iteration\n",
    "    summary_tmp.append(score_tmp)\n",
    "    feats.append(feat_tmp)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFR_AbundThresh_CA.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFR_AbundThresh_CA.xlsx', index=False)\n",
    "print('done')\n",
    "#\n",
    "#     tmp = pd.DataFrame({'Abund Thresh': i,\n",
    "#                               'F1': f1,\n",
    "#                               'AUROC': auroc,\n",
    "#                               'Accuracy': accuracy,\n",
    "#                               'Precision': precision,\n",
    "#                               'Recall': recall}, index=[0])\n",
    "#\n",
    "#     eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "#\n",
    "# eval_df.to_excel('Output_data/AbundThresholdingRFC2.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T17:58:22.880087Z",
     "end_time": "2023-05-02T18:09:57.614807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T06:44:25.074597Z",
     "end_time": "2023-05-03T07:23:30.476005Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "Scorer ran successfully\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Run RFE to different numbers of features and see how the score changes with each variation # test with and without Control abundance##\n",
    "in_dir='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "# df = df.replace(np.inf,10)\n",
    "model=RandomForestClassifier()\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "# featnums=[75,60,50,40,30,25,20,18,15,12,10,8,5,4,3,2]\n",
    "featnums=np.arange(75,1,-1).tolist()\n",
    "ids=['CA','NoCA']\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "df_a=df.copy()\n",
    "thresh=1\n",
    "\n",
    "\n",
    "for identifier in ids:\n",
    "    #Drop zero values#\n",
    "    df = pd.read_excel(in_dir, header=0)\n",
    "    # Min_Abund=df['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    # df=df[df['Abundance']>=Min_Abund]\n",
    "\n",
    "    #replace 0s in abundance controls\n",
    "    Min_Control=df['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    df['Abundance_Controls'].replace(0,Min_Control,inplace=True)\n",
    "\n",
    "    #calculate enrichment and then convert into binary target based on Enrich threshold (thresh)\n",
    "    df['Enrich']= np.log2(df['Abundance']/df['Abundance_Controls'])\n",
    "    df['binary_target']= df['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "    if identifier=='NoCA':\n",
    "        df=df.drop(columns='Abundance_Controls')\n",
    "    labels_df = df['binary_target'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    df=df.drop(columns=['Abundance','NPUNID','Entry','Sequence','Sample_num', 'Raw_FileID','Ligands','Enrich','binary_target','NPID'])\n",
    "    for n_feats in featnums:\n",
    "        identity=identifier+str(n_feats)\n",
    "        step = 1\n",
    "        selector = RFE(model, n_features_to_select=n_feats, step=step)\n",
    "        selector = selector.fit(df, label_abund)\n",
    "        feat_list = selector.get_feature_names_out()\n",
    "        df = df[feat_list].copy()\n",
    "        tmp2,tmp3=scorer_RFC(df, label_abund, model, identity, 10)\n",
    "        summary_tmp.append(tmp2)\n",
    "        feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFEs_RFC.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFEs_RFC.xlsx', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scorer ran successfully\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "##Run RFECV for classification test with and without Control abundance##\n",
    "in_dir='Input_data/Save_files/df_2_Synth.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "#Drop zero values#\n",
    "\n",
    "# df = df.replace(np.inf,10)\n",
    "model=RandomForestClassifier()\n",
    "# df_filepath='Input_data/Save_files/df_1_all.xlsx'\n",
    "# featnums=[75,60,50,40,30,25,20,18,15,12,10,8,5,4,3,2]\n",
    "featnums=np.arange(75,5,-1).tolist()\n",
    "ids=['CA']\n",
    "summary_tmp=[]\n",
    "feats=[]\n",
    "df_a=df.copy()\n",
    "thresh=1\n",
    "\n",
    "\n",
    "for identifier in ids:\n",
    "    df = pd.read_excel(in_dir, header=0)\n",
    "    #drop zeros\n",
    "    # Min_Control=df['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    # df=df[df['Abundance']>=Min_Control]\n",
    "    #\n",
    "\n",
    "    Min_Abund=df['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    df['Abundance_Controls'].replace(0,Min_Abund,inplace=True)\n",
    "    df['Enrich']= np.log2(df['Abundance']/df['Abundance_Controls'])\n",
    "    df['binary_target']= df['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "    if identifier=='NoCA':\n",
    "        df=df.drop(columns='Abundance_Controls')\n",
    "    labels_df = df['binary_target'].copy()\n",
    "    label_abund=np.ravel(labels_df)\n",
    "    df=df.drop(columns=['Abundance','NPUNID','Entry','Sequence','Sample_num', 'Raw_FileID','Ligands','Enrich','binary_target','NPID'])\n",
    "\n",
    "    identity=identifier\n",
    "    step = 1\n",
    "\n",
    "    min_feats = 1\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    selector = RFECV(estimator=model, cv=cv, min_features_to_select=min_feats,\n",
    "                     step=step, scoring='f1')\n",
    "    selector = selector.fit(df, label_abund)\n",
    "    selector.support_\n",
    "    feat_list2 = selector.get_feature_names_out()\n",
    "    selected_features = df.columns[selector.support_]\n",
    "    df = df[feat_list2]\n",
    "    # df.to_excel(\"Input_data/Save_files/df_RFECV\"+id+id2+\".xlsx\")\n",
    "    rfecv_df=pd.DataFrame(selector.cv_results_)\n",
    "    rfecv_df.to_excel(\"Output_data/RFECV_resultsRFC\"+identifier+\".xlsx\",index=False)\n",
    "    tmp2,tmp3=scorer_RFC(df, label_abund, model, identity, 10)\n",
    "    summary_tmp.append(tmp2)\n",
    "    feats.append(tmp3)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)\n",
    "feat_summary=feats[0]\n",
    "for d in feats[1:]:\n",
    "    feat_summary=feat_summary.merge(d, on='Features',how='outer')\n",
    "feat_summary.to_excel('Output_data/Feats_RFEcv_RFC.xlsx', index=False)\n",
    "summary.to_excel('Output_data/Scores_RFEcv_RFC.xlsx', index=False)\n",
    "print('done')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:07:37.518647Z",
     "end_time": "2023-05-03T22:19:41.414288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T18:44:18.643047Z",
     "end_time": "2023-05-03T18:45:13.880193Z"
    }
   },
   "outputs": [],
   "source": [
    "##Testing Each NP independently--RFR ## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[1,20,19,16,7,31,34,43,44]\n",
    "NPUNID_list=df_a['NPUNID'].unique().tolist()\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Loop through each ID in the list\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFR=['Abundance_Controls','Length','frac_aa_A','frac_aa_D','frac_aa_F','frac_aa_N','fraction_exposed_polar_total','rsa_std','fraction_exposed_exposed_C','fraction_exposed_exposed_E','fraction_exposed_exposed_H','nsp_secondary_structure_coil',\t'nsp_secondary_structure_sheet','Zeta Potential','Dh_functionalized','NP_incubation Concentration (mg/mL)','Incubation Concentration (mg/ml)']\n",
    "\n",
    "Min_Control=df_a['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a= df_a[df_a['Abundance']>=Min_Control].copy()\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df=df_a.copy()\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df[feat_list_RFR].copy()\n",
    "    X_test = removed_row[feat_list_RFR].copy()\n",
    "    y_train = np.ravel(df['Abundance'])\n",
    "    y_train = np.log2(y_train)\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "    X_test = removed_row[X_train.columns]\n",
    "    y_true = removed_row['Abundance']\n",
    "    y_true= np.ravel(y_true)\n",
    "    y_true= np.log2(y_true)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    pearson_scores.append(pearson)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mse_score)\n",
    "    # plot the scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.set_xlabel('True Abundance Value log2')\n",
    "    ax.set_ylabel('Predicted Abundance log2')\n",
    "\n",
    "\n",
    "    # add the metrics box to the plot\n",
    "    box_text = f\"MSE: {mse_score:.2f}\\nR2: {r2:.2f}\\nPearson: {pearson:.2f}\"\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.65, 0.95, box_text, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "    plt.savefig('Output_data/NPtest_synth_' + str(NPID) + '.png', bbox_inches='tight')\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'Abundandce Filter': i,\n",
    "                              'NPUNID':NPID,\n",
    "                              'MSE':mse_score,\n",
    "                              'R2':r2,\n",
    "                              'Pearson':pearson},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/AbundThresholdingRFR_NP(2).xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##External Validation--RFR## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[1,20,19,16,7,31,34,43,44]\n",
    "prediction_filepath ='Input_data/Save_files/df_4_HS.xlsx'\n",
    "df_pred = pd.read_excel(prediction_filepath, header=0)\n",
    "NPUNID_list=df_pred['NPUNID'].unique().tolist()\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFR=['Abundance_Controls','Length','frac_aa_A','frac_aa_D','frac_aa_F','frac_aa_N','fraction_exposed_polar_total','rsa_std','fraction_exposed_exposed_C','fraction_exposed_exposed_E','fraction_exposed_exposed_H','nsp_secondary_structure_coil',\t'nsp_secondary_structure_sheet','Zeta Potential','Dh_functionalized','NP_incubation Concentration (mg/mL)','Incubation Concentration (mg/ml)']\n",
    "\n",
    "Min_Control=df_a['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a= df_a[df_a['Abundance']>=Min_Control].copy()\n",
    "Min_Control=df_pred['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_pred= df_pred[df_pred['Abundance']>=Min_Control].copy()\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df_b=df_pred[df_pred['NPUNID']==NPID].copy()\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df_a[feat_list_RFR].copy()\n",
    "    X_test = df_b[feat_list_RFR].copy()\n",
    "    y_train = np.ravel(df_a['Abundance'])\n",
    "    y_train = np.log2(y_train)\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "\n",
    "    y_true = df_b['Abundance']\n",
    "    y_true= np.ravel(y_true)\n",
    "    y_true= np.log2(y_true)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    pearson_scores.append(pearson)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mse_score)\n",
    "    # plot the scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.set_xlabel('True Abundance Value log2')\n",
    "    ax.set_ylabel('Predicted Abundance log2')\n",
    "\n",
    "\n",
    "    # add the metrics box to the plot\n",
    "    box_text = f\"MSE: {mse_score:.2f}\\nR2: {r2:.2f}\\nPearson: {pearson:.2f}\"\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.65, 0.95, box_text, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "    plt.savefig('Output_data/NPtest_HS_' + str(NPID) + '.png', bbox_inches='tight')\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'Abundandce Filter': Min_Control,\n",
    "                              'NPUNID':NPID,\n",
    "                              'MSE':mse_score,\n",
    "                              'R2':r2,\n",
    "                              'Pearson':pearson},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/PredictingHS_Samples.xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T23:22:23.787940Z",
     "end_time": "2023-05-03T23:22:56.235015Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "       Entry  Sample_num  Abundance  Abundance_Controls  \\\n0     Q3SWW8          46   0.000000            0.004931   \n1     P13213          31   0.000000            0.000000   \n2     Q2KJF1          46   0.119162            0.802977   \n3     P10103          39   0.000000            0.000000   \n4     P13135          49   0.004763            0.000000   \n...      ...         ...        ...                 ...   \n7557  P01252          37   0.000000            0.000000   \n7558  P81644          32   0.133251            0.004621   \n7559  P02070          40   0.004355            0.000583   \n7560  Q3MHL7          32   0.002787            0.000000   \n7561  Q0VCX1          33   0.031326            0.000000   \n\n                                               Sequence  Length    Mass  \\\n0     MLAPRGATFLLLHLALQPWLGAGAQATPQVFDLLPSASQRLNPSVL...     961  105974   \n1     MRAWIFFLLCLAGRALAAPQQEALPDETEVVEETVAEVAEVPVGAN...     303   34613   \n2     MSAWAALLLLWGLSLSPVTEQATFFDPRPSLWAEAGSPLAPWADVT...     503   53554   \n3     MGKGDPKKPRGKMSSYAFFVQTCREEHKKKHPDASVNFSEFSKKCS...     215   24908   \n4     MFLVNSFLKGGGGGGGGGGLGGGLGNVLGGLISGAGGGGGGGGGGG...     263   27931   \n...                                                 ...     ...     ...   \n7557  MSDAAVDTSSEITTKDLKEKKEVVEEAENGREAPANGNANEENGEQ...     110   12072   \n7558  MKLLALTVLLLTICGLEGALVRRQAEESNLQSLVSQYFQTVADYGK...     100   11202   \n7559  MLTAEEKAAVTAFWGKVKVDEVGGEALGRLLVVYPWTQRFFESFGD...     145   15954   \n7560  MAAVKTLNPKAEVARAQAALAVNISAARGLQDVLRTNLGPKGTMKM...     531   57956   \n7561  MWCIVLFSLVAWVYAEPTMYGEILSPNYPQVYPNEVEKSWDIEVPA...     689   76609   \n\n      frac_aa_A  frac_aa_C  frac_aa_D  ...  Dtem  Dh_core  Dh_functionalized  \\\n0      0.050989   0.048907   0.114464  ...   244      229                291   \n1      0.062706   0.049505   0.075908  ...   200      221                221   \n2      0.109344   0.019881   0.039761  ...   244      229                291   \n3      0.088372   0.013953   0.088372  ...    98      149                271   \n4      0.064639   0.007605   0.057034  ...   200      221                266   \n...         ...        ...        ...  ...   ...      ...                ...   \n7557   0.109091   0.000000   0.163636  ...   182      229                316   \n7558   0.090000   0.010000   0.040000  ...   200      221                221   \n7559   0.110345   0.006897   0.062069  ...   182      229                218   \n7560   0.101695   0.015066   0.064030  ...   200      221                221   \n7561   0.046444   0.040639   0.050798  ...    82      149                149   \n\n      Shaken  Centrifuged  ProteinID  NP_incubation Concentration (mg/mL)  \\\n0          1            0          1                                  5.0   \n1          1            1          1                                  4.0   \n2          1            0          1                                  5.0   \n3          1            0          1                                  5.0   \n4          1            1          1                                  2.4   \n...      ...          ...        ...                                  ...   \n7557       1            0          1                                  5.0   \n7558       1            1          1                                  4.0   \n7559       1            0          1                                  5.0   \n7560       1            1          1                                  4.0   \n7561       1            0          1                                  5.0   \n\n      Incubation Concentration (mg/ml)  Incubation Time (minutes)  Temperature  \n0                                   40                         30           25  \n1                                    4                         30           25  \n2                                   40                         30           25  \n3                                   40                         30           25  \n4                                   40                         30           25  \n...                                ...                        ...          ...  \n7557                                40                         30           25  \n7558                                40                         30           25  \n7559                                40                         30           25  \n7560                                40                         30           25  \n7561                                 4                         30           25  \n\n[7562 rows x 101 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entry</th>\n      <th>Sample_num</th>\n      <th>Abundance</th>\n      <th>Abundance_Controls</th>\n      <th>Sequence</th>\n      <th>Length</th>\n      <th>Mass</th>\n      <th>frac_aa_A</th>\n      <th>frac_aa_C</th>\n      <th>frac_aa_D</th>\n      <th>...</th>\n      <th>Dtem</th>\n      <th>Dh_core</th>\n      <th>Dh_functionalized</th>\n      <th>Shaken</th>\n      <th>Centrifuged</th>\n      <th>ProteinID</th>\n      <th>NP_incubation Concentration (mg/mL)</th>\n      <th>Incubation Concentration (mg/ml)</th>\n      <th>Incubation Time (minutes)</th>\n      <th>Temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q3SWW8</td>\n      <td>46</td>\n      <td>0.000000</td>\n      <td>0.004931</td>\n      <td>MLAPRGATFLLLHLALQPWLGAGAQATPQVFDLLPSASQRLNPSVL...</td>\n      <td>961</td>\n      <td>105974</td>\n      <td>0.050989</td>\n      <td>0.048907</td>\n      <td>0.114464</td>\n      <td>...</td>\n      <td>244</td>\n      <td>229</td>\n      <td>291</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P13213</td>\n      <td>31</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>MRAWIFFLLCLAGRALAAPQQEALPDETEVVEETVAEVAEVPVGAN...</td>\n      <td>303</td>\n      <td>34613</td>\n      <td>0.062706</td>\n      <td>0.049505</td>\n      <td>0.075908</td>\n      <td>...</td>\n      <td>200</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q2KJF1</td>\n      <td>46</td>\n      <td>0.119162</td>\n      <td>0.802977</td>\n      <td>MSAWAALLLLWGLSLSPVTEQATFFDPRPSLWAEAGSPLAPWADVT...</td>\n      <td>503</td>\n      <td>53554</td>\n      <td>0.109344</td>\n      <td>0.019881</td>\n      <td>0.039761</td>\n      <td>...</td>\n      <td>244</td>\n      <td>229</td>\n      <td>291</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P10103</td>\n      <td>39</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>MGKGDPKKPRGKMSSYAFFVQTCREEHKKKHPDASVNFSEFSKKCS...</td>\n      <td>215</td>\n      <td>24908</td>\n      <td>0.088372</td>\n      <td>0.013953</td>\n      <td>0.088372</td>\n      <td>...</td>\n      <td>98</td>\n      <td>149</td>\n      <td>271</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P13135</td>\n      <td>49</td>\n      <td>0.004763</td>\n      <td>0.000000</td>\n      <td>MFLVNSFLKGGGGGGGGGGLGGGLGNVLGGLISGAGGGGGGGGGGG...</td>\n      <td>263</td>\n      <td>27931</td>\n      <td>0.064639</td>\n      <td>0.007605</td>\n      <td>0.057034</td>\n      <td>...</td>\n      <td>200</td>\n      <td>221</td>\n      <td>266</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2.4</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7557</th>\n      <td>P01252</td>\n      <td>37</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>MSDAAVDTSSEITTKDLKEKKEVVEEAENGREAPANGNANEENGEQ...</td>\n      <td>110</td>\n      <td>12072</td>\n      <td>0.109091</td>\n      <td>0.000000</td>\n      <td>0.163636</td>\n      <td>...</td>\n      <td>182</td>\n      <td>229</td>\n      <td>316</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7558</th>\n      <td>P81644</td>\n      <td>32</td>\n      <td>0.133251</td>\n      <td>0.004621</td>\n      <td>MKLLALTVLLLTICGLEGALVRRQAEESNLQSLVSQYFQTVADYGK...</td>\n      <td>100</td>\n      <td>11202</td>\n      <td>0.090000</td>\n      <td>0.010000</td>\n      <td>0.040000</td>\n      <td>...</td>\n      <td>200</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7559</th>\n      <td>P02070</td>\n      <td>40</td>\n      <td>0.004355</td>\n      <td>0.000583</td>\n      <td>MLTAEEKAAVTAFWGKVKVDEVGGEALGRLLVVYPWTQRFFESFGD...</td>\n      <td>145</td>\n      <td>15954</td>\n      <td>0.110345</td>\n      <td>0.006897</td>\n      <td>0.062069</td>\n      <td>...</td>\n      <td>182</td>\n      <td>229</td>\n      <td>218</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7560</th>\n      <td>Q3MHL7</td>\n      <td>32</td>\n      <td>0.002787</td>\n      <td>0.000000</td>\n      <td>MAAVKTLNPKAEVARAQAALAVNISAARGLQDVLRTNLGPKGTMKM...</td>\n      <td>531</td>\n      <td>57956</td>\n      <td>0.101695</td>\n      <td>0.015066</td>\n      <td>0.064030</td>\n      <td>...</td>\n      <td>200</td>\n      <td>221</td>\n      <td>221</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>40</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7561</th>\n      <td>Q0VCX1</td>\n      <td>33</td>\n      <td>0.031326</td>\n      <td>0.000000</td>\n      <td>MWCIVLFSLVAWVYAEPTMYGEILSPNYPQVYPNEVEKSWDIEVPA...</td>\n      <td>689</td>\n      <td>76609</td>\n      <td>0.046444</td>\n      <td>0.040639</td>\n      <td>0.050798</td>\n      <td>...</td>\n      <td>82</td>\n      <td>149</td>\n      <td>149</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.0</td>\n      <td>4</td>\n      <td>30</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n<p>7562 rows × 101 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "df_a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T06:18:40.517578Z",
     "end_time": "2023-05-04T06:18:51.116440Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouls\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "##External Validation--RFC## Which ones are hard to predict and which ones are easy?\n",
    "#easy to hard NPUNID 1,20,19,16,7,31,34,34\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "# labels= df_a['Abundance'].copy()\n",
    "# id_col= df_a['NPUNID'].copy()\n",
    "# label_abund=np.ravel(labels)\n",
    "\n",
    "# NPUNID_list=[2,16,7,8,9,10,11,12]\n",
    "prediction_filepath ='Input_data/Save_files/df_4_HS.xlsx'\n",
    "df_pred = pd.read_excel(prediction_filepath, header=0)\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "\n",
    "Min_Abund=df_a['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a['Abundance_Controls'].replace(0,Min_Abund,inplace=True)\n",
    "df_a['Enrich']= np.log2(df_a['Abundance']/df_a['Abundance_Controls'])\n",
    "df_a['binary_target']= df_a['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "labels_df = df_a['binary_target'].copy()\n",
    "label_abund=np.ravel(labels_df)\n",
    "\n",
    "\n",
    "NPUNID_list=df_pred['NPUNID'].unique().tolist()\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "# f1 = []\n",
    "# auroc = []\n",
    "# accuracy = []\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "eval_df = pd.DataFrame(columns=['NPUNID', 'f1', 'AUROC', 'Accuracy','precision','recall'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFR=['Zeta Potential','Dh_functionalized','secondary_structure_fraction_sheet','Surface_Ligand','fraction_buried','Dtem','isoelectric_point','frac_aa_R','fraction_exposed_exposed_P','Incubation Concentration (mg/ml)','fraction_exposed_exposed_K','frac_aa_C','frac_aa_I','frac_aa_A','flexibility_min','molecular_weight']\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df_b=df_pred[df_pred['NPUNID']==NPID].copy()\n",
    "    Min_Abund=df_pred['Abundance_Controls'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "    df_b['Abundance_Controls'].replace(0,Min_Abund,inplace=True)\n",
    "    df_b['Enrich']= np.log2(df_b['Abundance']/df_b['Abundance_Controls'])\n",
    "    df_b['binary_target']= df_b['Enrich'].apply(lambda t: 1 if t>=thresh else 0)\n",
    "    labels_df = df_b['binary_target'].copy()\n",
    "    label_target=np.ravel(labels_df)\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df_a[feat_list_RFR].copy()\n",
    "    X_test = df_b[feat_list_RFR].copy()\n",
    "    y_train = label_abund\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "\n",
    "    y_true = label_target\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'NPUNID':NPID,'f1':f1,'AUROC':auroc,'Accuracy':accuracy,'precision':precision,'recall':recall},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/Predicting_HS_Samples_RFC.xlsx', index=False)\n",
    "# out=pd.DataFrame(list(zip(NPUNID_list,Abund_filter,pearson_scores,r2_scores,mse)), columns=['NPUNID','Abundance Filter','Pearson', 'R2', 'MSE'])\n",
    "# out.to_excel('Output_data/PredictingEachNP_RFECV.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T06:31:57.683690Z",
     "end_time": "2023-05-04T06:32:18.412163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.46      , 0.61      , 0.53      , 0.04      , 0.1       ,\n       0.77      , 0.02      , 0.99      , 0.02      , 1.        ,\n       0.02      , 0.03      , 0.98      , 0.24      , 0.9       ,\n       0.21      , 0.26      , 0.        , 0.92      , 0.97      ,\n       0.53      , 0.05      , 0.21      , 0.94      , 0.09      ,\n       0.63      , 0.25666667, 0.8       , 0.95      , 0.        ,\n       0.06      , 0.02      , 0.62      , 0.73      , 0.31      ,\n       0.04      , 0.42      , 0.91      , 0.01      , 0.42      ,\n       0.58      , 0.12      , 0.        , 0.        , 0.07      ,\n       0.13      , 0.45      , 0.16      , 0.        , 0.15      ,\n       0.        , 0.38      , 0.01      , 0.27      , 0.        ,\n       0.95      , 0.91      , 0.28      , 0.06      , 0.7       ,\n       0.045     , 0.65      , 0.03      , 0.91      , 0.        ,\n       0.77      , 0.08      , 0.        , 0.13      , 0.23      ,\n       0.91      , 0.94      , 0.05      , 0.33      , 0.1       ,\n       0.        , 0.9       , 1.        , 0.28      , 0.        ,\n       1.        , 0.59      , 1.        , 0.85      , 0.        ,\n       0.98      , 0.33      , 0.23      , 0.12      , 0.07      ,\n       0.28      , 0.        , 0.24      , 0.02      , 0.94      ,\n       0.1       , 0.73      , 0.21      , 0.02      , 0.18      ,\n       0.39      , 0.41      , 0.17      , 0.6       , 0.57      ,\n       0.19      , 0.31666667, 0.39      , 0.74      , 0.64      ,\n       0.43      , 0.74      , 0.        , 0.06      , 0.43      ,\n       1.        , 0.27      , 0.49      , 1.        , 0.07      ,\n       0.24      , 0.01      , 0.47      , 0.38      , 0.98      ,\n       0.3       , 0.28      , 0.62      , 0.03      , 0.43      ,\n       0.39666667, 0.15      , 0.02      , 0.03      , 0.03      ,\n       0.85      , 0.37666667, 0.95      , 0.98      , 0.12      ,\n       0.16      , 0.04      , 0.08      , 0.28      , 1.        ,\n       0.8       , 0.77      , 0.1       , 0.18      , 0.02      ,\n       0.57      , 0.06      , 0.02      , 0.97      , 0.06      ,\n       0.01      , 0.03      , 0.87      , 1.        , 0.89      ,\n       0.11      , 0.27      , 0.12      , 0.01      , 0.02      ,\n       0.4       , 0.04      , 0.98      , 0.99      , 0.02      ,\n       0.47      , 0.15      , 0.03      , 0.01      , 0.02      ,\n       0.01      , 0.46      , 0.02      , 0.43      , 0.99      ,\n       0.01      , 0.99      , 0.87      , 0.96      , 0.22      ,\n       0.98      , 0.97      , 0.66      , 0.97      , 0.49      ,\n       0.76      , 0.87      , 0.13      , 0.78      , 0.30166667,\n       0.98      , 0.29      , 0.01      , 0.99      , 0.87      ,\n       0.06      , 0.93      , 0.01      , 0.21      , 0.75      ,\n       0.01      , 0.95      , 0.3       , 0.18      , 0.79      ,\n       0.98      , 0.92      , 0.65      , 1.        , 0.7       ,\n       0.4       , 0.44      , 0.19      , 0.        , 0.78      ,\n       0.13      , 0.39666667, 0.08      , 0.15      , 0.76      ,\n       0.09      , 0.02      , 0.16      , 0.02      , 0.18      ,\n       0.15      , 0.7       , 0.8       , 0.33      , 0.2       ,\n       0.02      , 0.27      , 0.44      , 0.26      , 0.25      ,\n       0.02      , 0.22      , 0.08      , 0.78      , 0.07      ,\n       0.53      , 0.1       , 0.04      , 0.12      , 0.76      ,\n       0.23      , 0.66      , 0.2       , 0.02      , 0.25      ,\n       0.17      , 0.07      , 0.01      , 0.02      , 1.        ,\n       0.06      , 0.67      , 0.07      , 0.99      , 0.32      ,\n       0.75      , 0.81      , 0.45      , 0.92      , 0.3       ,\n       0.08      , 0.03      , 0.93      , 0.05      , 0.62      ,\n       0.        , 0.03      , 1.        , 0.67      , 0.21      ,\n       0.83      , 0.03      , 0.97      , 0.3       , 0.30333333,\n       0.25      , 0.37      , 0.32      , 0.53      , 0.33      ,\n       0.56      , 0.55      , 0.88      , 0.1       , 0.1       ,\n       0.96      , 0.56      , 0.67      , 0.52      , 0.07      ,\n       0.98      , 0.8       , 0.44      , 0.97      , 0.46      ,\n       0.69      , 0.01      , 0.73      , 0.62      , 0.54      ,\n       0.03      , 0.02      , 0.97333333, 0.49      , 0.        ,\n       0.59      , 0.26      , 0.89      , 1.        , 0.98      ,\n       0.93      , 0.11      , 0.31      , 0.45      , 0.67      ,\n       0.36      , 0.01      , 0.56      , 0.02      , 0.06      ,\n       0.15      , 0.39      , 0.03      , 0.39      , 0.92      ,\n       0.35      , 0.94      , 0.75      , 0.        , 0.26      ,\n       0.72      , 0.97      , 0.02      , 0.36      , 0.83      ,\n       0.96      , 0.03      , 0.26      , 0.93      , 0.33      ,\n       1.        , 0.29      , 0.04      , 0.73      , 0.        ,\n       0.97      , 0.14      , 0.47      , 0.86      , 0.        ,\n       1.        , 0.075     , 0.06      , 0.28      , 0.88      ,\n       0.17      , 0.45      , 0.        , 0.14      , 0.32      ,\n       0.98      , 0.85      , 0.28      , 0.39      , 0.02      ,\n       0.97      , 0.37666667, 0.91      , 0.89      , 0.73      ,\n       1.        , 0.07      , 0.59      , 0.9       , 0.12      ,\n       0.1       , 0.05      , 0.215     , 0.14      , 0.        ,\n       0.58      , 0.08      , 0.13      , 0.6       , 0.4       ,\n       0.28      , 0.08      , 0.13      , 0.74      , 0.39      ,\n       0.42      , 0.48      , 0.        , 0.03      , 0.01      ,\n       0.3       , 0.67      , 0.11      , 0.03      , 0.63      ,\n       0.29      , 0.24      , 0.96      , 0.29      , 0.65      ,\n       0.05      , 0.05      , 0.        , 0.11      , 0.        ,\n       0.1       , 0.01      , 0.02      , 0.86      , 0.        ,\n       0.11      , 0.07      , 0.1       , 0.45      , 0.94      ,\n       0.07      , 0.03      , 0.42      , 0.95      , 1.        ,\n       0.02      , 0.63      , 0.77      , 0.03      , 0.99      ,\n       0.05      , 0.03      , 0.54      , 0.2       , 0.89      ,\n       0.33      , 0.09      , 0.06      , 1.        , 0.02      ,\n       0.45      , 0.29      , 0.79      , 0.88      , 0.98      ,\n       0.84      , 0.11      , 0.99      , 0.3       , 0.01      ,\n       0.96      , 0.06      , 0.95      , 0.93      , 0.98      ,\n       0.08      , 0.09      , 0.36      , 0.255     , 0.        ,\n       0.19      , 0.83      , 0.26666667, 0.99      , 0.        ,\n       0.11      , 0.435     , 0.        , 1.        , 0.85      ,\n       0.27      , 0.01      , 0.06      , 0.81      , 0.        ,\n       0.        , 0.32      , 0.02      , 0.01      , 0.07      ,\n       0.01      , 0.21      , 0.07      , 1.        , 0.85      ,\n       0.93      , 0.09      , 0.        , 0.29      , 0.01      ,\n       0.23      , 0.16      , 0.63      , 0.37      , 0.25      ,\n       0.05      , 0.03      , 0.21      , 0.04      , 0.01      ,\n       0.71      , 0.07      , 0.70416667, 0.33      , 0.31      ,\n       0.44      , 0.07      , 0.98      , 0.23      , 0.95      ,\n       0.07      , 0.76      , 0.45      , 0.2       , 0.16      ,\n       0.76      , 0.27666667, 0.87      , 0.41      , 0.35833333,\n       1.        , 0.96      , 1.        , 0.08      , 0.23      ,\n       0.03      , 0.85      , 0.67      , 0.02      , 0.33      ,\n       0.04      , 0.91      , 0.1       , 1.        , 0.28      ,\n       0.2       , 0.025     , 0.16      , 1.        , 0.11      ,\n       0.85      , 0.34      , 0.82      , 0.07333333, 0.13      ,\n       0.02      , 0.03      , 0.36      , 0.26      , 0.97      ,\n       0.18      , 0.65      , 0.03      , 0.59      , 0.85      ,\n       0.21      , 0.28333333, 1.        ])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T06:21:26.998828Z",
     "end_time": "2023-05-04T06:21:27.022449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##External Validation on RFC Methods#\n",
    "##External Validation--RFR## Which ones are hard to predict and which ones are easy?\n",
    "df_filepath = 'Input_data/Save_files/df_2_Synth.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "\n",
    "\n",
    "NPUNID_list=[2,16,7,8,9,10,11,12]\n",
    "prediction_filepath ='Input_data/Save_files/df_1_all.xlsx'\n",
    "df_pred = pd.read_excel(prediction_filepath, header=0)\n",
    "\n",
    "id_list=NPUNID_list\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "pearson_scores = []\n",
    "r2_scores = []\n",
    "mse = []\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "eval_df = pd.DataFrame(columns=['Abundandce Filter', 'NPUNID', 'MSE', 'R2', 'Pearson'])\n",
    "# for i in Abund_filter:\n",
    "feat_list_RFR=['Abundance_Controls','Length','frac_aa_A','frac_aa_D','frac_aa_F','frac_aa_N','fraction_exposed_polar_total','rsa_std','fraction_exposed_exposed_C','fraction_exposed_exposed_E','fraction_exposed_exposed_H','nsp_secondary_structure_coil',\t'nsp_secondary_structure_sheet','Zeta Potential','Dh_functionalized','NP_incubation Concentration (mg/mL)','Incubation Concentration (mg/ml)']\n",
    "\n",
    "Min_Control=df_a['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_a= df_a[df_a['Abundance']>=Min_Control].copy()\n",
    "Min_Control=df_pred['Abundance'].drop_duplicates().nsmallest(2).iloc[-1]\n",
    "df_pred= df_pred[df_pred['Abundance']>=Min_Control].copy()\n",
    "\n",
    "for NPID in id_list:\n",
    "    print(NPID)\n",
    "    df_b=df_pred[df_pred['NPUNID']==NPID].copy()\n",
    "    # Remove the row with the current ID from the dataframe\n",
    "\n",
    "    # Split the remaining data into features and target\n",
    "    X_train = df_a[feat_list_RFR].copy()\n",
    "    X_test = df_b[feat_list_RFR].copy()\n",
    "    y_train = np.ravel(df_a['Abundance'])\n",
    "    y_train = np.log2(y_train)\n",
    "\n",
    "\n",
    "    # Fit a random forest regression model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Use the trained model to predict on the removed ID\n",
    "\n",
    "    y_true = df_b['Abundance']\n",
    "    y_true= np.ravel(y_true)\n",
    "    y_true= np.log2(y_true)\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate the Accuracy scores and add it to the list\n",
    "    pearson, _ = pearsonr(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse_score = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    pearson_scores.append(pearson)\n",
    "    r2_scores.append(r2)\n",
    "    mse.append(mse_score)\n",
    "    # plot the scatter plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['figure.dpi'] = 300\n",
    "    ax.scatter(y_true, y_pred)\n",
    "    ax.set_xlabel('True Abundance Value log2')\n",
    "    ax.set_ylabel('Predicted Abundance log2')\n",
    "\n",
    "\n",
    "    # add the metrics box to the plot\n",
    "    box_text = f\"MSE: {mse_score:.2f}\\nR2: {r2:.2f}\\nPearson: {pearson:.2f}\"\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax.text(0.65, 0.95, box_text, transform=ax.transAxes, fontsize=14,verticalalignment='top', bbox=props)\n",
    "    plt.savefig('Output_data/NPtest_HS_' + str(NPID) + '.png', bbox_inches='tight')\n",
    "    # print(id)\n",
    "    tmp=pd.DataFrame({'Abundandce Filter': Min_Control,\n",
    "                              'NPUNID':NPID,\n",
    "                              'MSE':mse_score,\n",
    "                              'R2':r2,\n",
    "                              'Pearson':pearson},index=[0])\n",
    "    eval_df = pd.concat([eval_df,tmp],ignore_index=True,axis=0)\n",
    "\n",
    "eval_df.to_excel('Output_data/PredictingBALF_FBS_Samples.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Feature Elimination with Correlated Features ran successfully\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m df_a\u001B[38;5;241m=\u001B[39mdf_a\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbundance\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNPUNID\u001B[39m\u001B[38;5;124m'\u001B[39m],axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     11\u001B[0m df_a\u001B[38;5;241m=\u001B[39mRFECV_plot(df_a,label_abund,model,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m,folds\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m scram_score(\u001B[43mdf\u001B[49m, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m     13\u001B[0m feat_drop(df, label_abund, model, \u001B[38;5;28mid\u001B[39m, \u001B[38;5;241m0.2\u001B[39m)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "##Run Quality Control on df to get a look at important features and such##\n",
    "df_filepath = 'Input_data/Save_files/df_1_all_RFE50_RFR.xlsx'\n",
    "df_a = pd.read_excel(df_filepath, header=0)\n",
    "labels= df_a['Abundance'].copy()\n",
    "id_col= df_a['NPUNID'].copy()\n",
    "label_abund=np.ravel(labels)\n",
    "\n",
    "\n",
    "# Initialize a list to hold MSE scores for each removed ID\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "df_a=df_a.drop(columns=['Abundance','NPUNID'],axis=1).copy()\n",
    "df_a=RFECV_plot(df_a,label_abund,model,'b',folds=5,step=2)\n",
    "scram_score(df, label_abund, model, id, 0.2)\n",
    "feat_drop(df, label_abund, model, id, 0.2)\n",
    "# feat_drop_multifold(df, label_abund, model, id, 0.2, folds=splits)\n",
    "tmp2=scorer(df, label_abund, model, id, 10)\n",
    "zeros=(raw_MS_data['Abundance']==0).sum()\n",
    "percent_zeros=zeros/raw_MS_data.shape[0]\n",
    "tmp2['TotalZeros']=zeros\n",
    "tmp2['Percent_zeros']=percent_zeros\n",
    "summary_tmp.append(tmp2)\n",
    "# lasso_feature_selection(df, label_abund, id)\n",
    "summary=pd.concat(summary_tmp,axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Run Histogram of each Feature###\n",
    "# Get total number of rows\n",
    "df=df_a\n",
    "total_count = len(df)\n",
    "df = df.rename(columns=lambda x: x.replace('/', ''))\n",
    "# Loop over each column of the dataframe\n",
    "for col in df.columns:\n",
    "    # Create a histogram of the current column, with bins=10\n",
    "    data=df[col]\n",
    "    plt.hist(data, weights=np.ones_like(data) / len(data))\n",
    "\n",
    "    # Set the title of the histogram to the column name and percent of total population\n",
    "    plt.title(str(col))\n",
    "    plt.savefig('Output_data/{}.png'.format(str(col)))\n",
    "    plt.close()\n",
    "    # Show the histogram\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

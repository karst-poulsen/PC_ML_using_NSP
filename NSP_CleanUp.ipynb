{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Code for processing NSP3 output for Bovine Proteome\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import hashlib\n",
    "from NSP_functions import *\n",
    "\n",
    "direct2= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/Bovine_clean_results/Cleaner_results/'\n",
    "direct3= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/Bovine_clean_results/Proc_results/'\n",
    "files = [f for f in listdir(direct2) if isfile(join(direct2,f)) ]\n",
    "descript= 'proc_results'\n",
    "# print(files)\n",
    "# for i in range(len(files)):\n",
    "for i in range(1):\n",
    "    filename=direct2+files[i]\n",
    "    unique_lines= set()\n",
    "    # print('check2')\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader= csv.reader(csvfile,delimiter=' ', quotechar='|')\n",
    "        for row in reader:\n",
    "            x=row[0]\n",
    "            y=x[4:10]\n",
    "            hashval=hashlib.md5(y.rstrip().encode('utf-8')).hexdigest()\n",
    "            if hashval not in unique_lines:\n",
    "                unique_lines.add(y)\n",
    "    uniqueIds=list(unique_lines)\n",
    "    # print(uniqueIds[1:])\n",
    "    raw_netsurfp_data = pd.read_csv(filename)\n",
    "    raw_netsurfp_data.columns = raw_netsurfp_data.columns.str.strip()\n",
    "    processed_data = netsurfp_2_data_processing(uniqueIds[1:], raw_netsurfp_data)\n",
    "    processed_data.to_excel(direct3+descript+str(i)+'.xlsx')\n",
    "    print(i,'out of ', len(files))\n",
    "                # print(y)\n",
    "                # file1.write(x+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Combine all processed files into one complete proteome file for Bovine Proteome\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/Bovine_clean_results/Proc_results/'\n",
    "\n",
    "file_list = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "excl_list =[]\n",
    "\n",
    "for file in file_list:\n",
    "    excl_list.append(pd.read_excel(file))\n",
    "excl_merged=pd.DataFrame()\n",
    "\n",
    "for excl_file in excl_list:\n",
    "    excl_merged= pd.concat([excl_merged,excl_file] , ignore_index=True)\n",
    "\n",
    "excl_merged.to_excel(path+'combined_processed_results2.xlsx', index= False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Code for processing NSP3 output for Mouse Proteome\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import hashlib\n",
    "\n",
    "direct2= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/Mouse_clean_results/Cleaner/'\n",
    "direct3= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/Mouse_clean_results/Proc_results/'\n",
    "files = [f for f in listdir(direct2) if isfile(join(direct2,f)) ]\n",
    "descript= 'proc_results'\n",
    "# print(files)\n",
    "# for i in range(len(files)):\n",
    "for i in range(1):\n",
    "    filename=direct2+files[i]\n",
    "    unique_lines= set()\n",
    "    # print('check2')\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader= csv.reader(csvfile,delimiter=' ', quotechar='|')\n",
    "        for row in reader:\n",
    "            x=row[0]\n",
    "            y=x[4:10]\n",
    "            hashval=hashlib.md5(y.rstrip().encode('utf-8')).hexdigest()\n",
    "            if hashval not in unique_lines:\n",
    "                unique_lines.add(y)\n",
    "    uniqueIds=list(unique_lines)\n",
    "    # print(uniqueIds[1:])\n",
    "    raw_netsurfp_data = pd.read_csv(filename)\n",
    "    raw_netsurfp_data.columns = raw_netsurfp_data.columns.str.strip()\n",
    "    processed_data = netsurfp_2_data_processing(uniqueIds[1:], raw_netsurfp_data)\n",
    "    processed_data.to_excel(direct3+descript+str(i)+'.xlsx')\n",
    "    # processed_data.to_excel(direct3+'aaaaa'+str(i)+'.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Combine all processed files into one complete proteome file for mouse Proteome\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/Mouse_clean_results/Proc_results/'\n",
    "\n",
    "file_list = glob.glob(path + \"/*.xlsx\")\n",
    "\n",
    "excl_list =[]\n",
    "\n",
    "for file in file_list:\n",
    "    excl_list.append(pd.read_excel(file))\n",
    "excl_merged=pd.DataFrame()\n",
    "\n",
    "for excl_file in excl_list:\n",
    "    excl_merged= pd.concat([excl_merged,excl_file] , ignore_index=True)\n",
    "\n",
    "excl_merged.to_excel(path+'combined_processed_results.xlsx', index= False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# file1=open('results0_test.csv','r')\n",
    "# file2=open('results0_clean.csv', 'w')\n",
    "direct1= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/MissingProts/Results/'\n",
    "direct2= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/MissingProts/Results/Cleaner/'\n",
    "files = [f for f in listdir(direct1) if isfile(join(direct1,f)) ]\n",
    "for i in range(len(files)):\n",
    "    file1=open(direct1+files[i],'r')\n",
    "    file2=open(direct2+'results'+str(i)+'.csv.','w')\n",
    "    for line in file1:\n",
    "#     print(line.count(','))\n",
    "        y=line.rfind(',')\n",
    "        # print(y)\n",
    "        # print(len(line))\n",
    "        if y+2==len(line):\n",
    "            line=line[::-1]\n",
    "            line=line.replace(',','',1)\n",
    "            line=line[::-1]\n",
    "            # print(line)\n",
    "        while line.count(',')>20:\n",
    "            line=line.replace(',','',1)\n",
    "            # print(line.count(','))\n",
    "        file2.write(line)\n",
    "    file1.close()\n",
    "    file2.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'seq', 'n', 'rsa', 'asa', 'q3', 'p[q3_H]', 'p[q3_E]', 'p[q3_C]',\n",
      "       'q8', 'p[q8_G]', 'p[q8_H]', 'p[q8_I]', 'p[q8_B]', 'p[q8_E]', 'p[q8_S]',\n",
      "       'p[q8_T]', 'p[q8_C]', 'phi', 'psi', 'disorder'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmp95\\PycharmProjects\\PC_ML_using NetSurfP\\NSP_functions.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered.loc[:, 'class assignment'] = np.where(filtered.loc[:, 'rsa'] > 0.25, 'E', 'B')\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U1444'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUFuncTypeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 15>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     41\u001B[0m raw_netsurfp_data\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m raw_netsurfp_data\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(raw_netsurfp_data\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[1;32m---> 43\u001B[0m processed_data \u001B[38;5;241m=\u001B[39m \u001B[43mnetsurfp_2_data_processing\u001B[49m\u001B[43m(\u001B[49m\u001B[43muniqueIds\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mraw_netsurfp_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\PC_ML_using NetSurfP\\NSP_functions.py:290\u001B[0m, in \u001B[0;36mnetsurfp_2_data_processing\u001B[1;34m(unique_id_list, complete_netsurfp_df)\u001B[0m\n\u001B[0;32m    278\u001B[0m polar_exposed_frac_total \u001B[38;5;241m=\u001B[39m (total_aa \u001B[38;5;241m-\u001B[39m nonpolar_counts) \u001B[38;5;241m/\u001B[39m total_aa\n\u001B[0;32m    280\u001B[0m \u001B[38;5;66;03m# addes features calculated thus into collective dictionary, while also calculating a few metrics for rsa and reformatting the secondary structure features\u001B[39;00m\n\u001B[0;32m    281\u001B[0m data_to_update \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mentry\u001B[39m\u001B[38;5;124m'\u001B[39m: i, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfraction_exposed\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(frac_exposed, \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    282\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfraction_buried\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(frac_buried, \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    283\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfraction_exposed_nonpolar_total\u001B[39m\u001B[38;5;124m'\u001B[39m: nonpolar_exposed_frac_total,\n\u001B[0;32m    284\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfraction_exposed_nonpolar_exposed\u001B[39m\u001B[38;5;124m'\u001B[39m: nonpolar_exposed_frac_exposed,\n\u001B[0;32m    285\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfraction_exposed_polar_total\u001B[39m\u001B[38;5;124m'\u001B[39m: polar_exposed_frac_total,\n\u001B[0;32m    286\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfraction_exposed_polar_exposed\u001B[39m\u001B[38;5;124m'\u001B[39m: polar_exposed_frac_exposed,\n\u001B[0;32m    287\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrsa_mean\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrsa\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean(), \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    288\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrsa_median\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrsa\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmedian(), \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    289\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrsa_std\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(filtered[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrsa\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstd(), \u001B[38;5;241m3\u001B[39m),\n\u001B[1;32m--> 290\u001B[0m                   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masa_sum\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maround\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiltered\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43masa\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    291\u001B[0m                   \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39maa_exposed_frac_total, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39maa_exposed_frac_exposed,\n\u001B[0;32m    292\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnsp_secondary_structure_coil\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(\n\u001B[0;32m    293\u001B[0m                       np\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39mwhere(filtered\u001B[38;5;241m.\u001B[39mq3\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mcontains(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)) \u001B[38;5;241m/\u001B[39m filtered\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    294\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnsp_secondary_structure_sheet\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(\n\u001B[0;32m    295\u001B[0m                       np\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39mwhere(filtered\u001B[38;5;241m.\u001B[39mq3\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mcontains(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)) \u001B[38;5;241m/\u001B[39m filtered\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    296\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnsp_secondary_structure_helix\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(\n\u001B[0;32m    297\u001B[0m                       np\u001B[38;5;241m.\u001B[39msum(np\u001B[38;5;241m.\u001B[39mwhere(filtered\u001B[38;5;241m.\u001B[39mq3\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mcontains(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m'\u001B[39m), \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)) \u001B[38;5;241m/\u001B[39m filtered\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m3\u001B[39m),\n\u001B[0;32m    298\u001B[0m                   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnsp_disordered\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39maround(np\u001B[38;5;241m.\u001B[39msum(filtered\u001B[38;5;241m.\u001B[39mdisorder\u001B[38;5;241m.\u001B[39mto_numpy() \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m) \u001B[38;5;241m/\u001B[39m filtered\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    299\u001B[0m                                               \u001B[38;5;241m3\u001B[39m)}\n\u001B[0;32m    301\u001B[0m \u001B[38;5;66;03m# creates data frame from above dic\u001B[39;00m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass:\n",
      "File \u001B[1;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36maround\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3314\u001B[0m, in \u001B[0;36maround\u001B[1;34m(a, decimals, out)\u001B[0m\n\u001B[0;32m   3220\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_around_dispatcher)\n\u001B[0;32m   3221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maround\u001B[39m(a, decimals\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   3222\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3223\u001B[0m \u001B[38;5;124;03m    Evenly round to the given number of decimals.\u001B[39;00m\n\u001B[0;32m   3224\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3312\u001B[0m \n\u001B[0;32m   3313\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mround\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecimals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecimals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     52\u001B[0m bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, method, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bound \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001B[0m, in \u001B[0;36m_wrapit\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     wrap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(asarray(obj), method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wrap:\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, mu\u001B[38;5;241m.\u001B[39mndarray):\n",
      "\u001B[1;31mUFuncTypeError\u001B[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U1444'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "#Code for processing NSP3 output for missing datasets\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import hashlib\n",
    "from NSP_functions import *\n",
    "\n",
    "direct2= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/MissingProts/Results/Cleaner/'\n",
    "direct3= 'C:/Users/kmp95/OneDrive - Duke University/NSP3_Working_stuff/MissingProts/ProcResults/'\n",
    "files = [f for f in listdir(direct2) if isfile(join(direct2,f))]\n",
    "descript= 'proc_results'\n",
    "# print(files)\n",
    "for i in range(len(files)):\n",
    "# for i in range(1):\n",
    "    j=0\n",
    "    filename=direct2+files[i]\n",
    "    unique_lines= set()\n",
    "    # print('check2')\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        reader= csv.reader(csvfile,delimiter=' ', quotechar='|')\n",
    "        for row in reader:\n",
    "            j+=1\n",
    "            if j == 1:\n",
    "                continue\n",
    "            x=row[0]\n",
    "            # print(x)\n",
    "            y=x.split('_',1)[1]\n",
    "            # print(y)\n",
    "            y=y.split('_',1)[0]\n",
    "            # print(y)\n",
    "\n",
    "            hashval=hashlib.md5(y.rstrip().encode('utf-8')).hexdigest()\n",
    "            if hashval not in unique_lines:\n",
    "                unique_lines.add(y)\n",
    "    uniqueIds=list(unique_lines)\n",
    "    # print(uniqueIds[1:])\n",
    "    raw_netsurfp_data = pd.read_csv(filename)\n",
    "    # print(raw_netsurfp_data)\n",
    "    raw_netsurfp_data.columns = raw_netsurfp_data.columns.str.strip()\n",
    "    print(raw_netsurfp_data.columns)\n",
    "    processed_data = netsurfp_2_data_processing(uniqueIds[1:], raw_netsurfp_data)\n",
    "    # processed_data.to_excel(direct3+descript+str(i)+'.xlsx')\n",
    "    # print(i,'out of ', len(files))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}